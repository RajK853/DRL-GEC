cold_lr: 1.0E-3
warm_lr: 1.0E-5
dropout: 0.1
num_epochs: 20
cold_epochs: 2
patience: 1
batch_size: 128
accumulation_size: 2
num_workers: 4
data_limit: 2_000_000
keep_corrects: false
datasets: &datasets ["synthetic"]
label_path: "data/vocabs/labels.txt"
model_path: &model_path null
log_dir: "sl_results"
meta_data:
    base_model: *model_path
    datasets: *datasets
    description: "
    Pretraining
    Use Unknown label
    "
