{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "469c966d-81b5-4cd6-935a-25d77e8a4868",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2085486-38df-4b43-b092-f563f06c8ac9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rajk/Machine_Learning/DRL-GEC\n",
      "/home/rajk/Machine_Learning/DRL-GEC/notebooks\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "import src.envs\n",
    "from src.utils import load_text, apply_labels\n",
    "from src.models.seq2labels import PretrainedEncoder, Seq2Labels\n",
    "%cd notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e197391-3820-41b9-910d-5809a74ab6ef",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d75d2a72-c4bc-409f-8c26-287fcfccc531",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def greedy_action(policy, state, all_labels, verbose=True):\n",
    "    [logits] = policy([state])\n",
    "    top_logits, i = logits.topk(3)\n",
    "    top_logits = top_logits.cpu().numpy()\n",
    "    i = i.cpu().numpy()\n",
    "    dist = Categorical(logits=logits)\n",
    "    top_probs = dist.probs[torch.arange(len(state)).unsqueeze(1), i]\n",
    "    entropy = dist.entropy().cpu().numpy()\n",
    "    if verbose:\n",
    "        for a, e, label_logit_prob in zip(state, entropy, zip(all_labels[i], top_logits, top_probs)):\n",
    "            print(f\"Entropy: {e:4f} | Label: {a:15}  |\", \" -- \".join(f\"{lab} [{prob:3.2f}, {log:5.2f}]\" for (lab, log, prob) in zip(*label_logit_prob)))\n",
    "        print()\n",
    "    action = logits.argmax(axis=-1)\n",
    "    return action.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abb5a4c6-c668-4ef3-89d7-3c47b668bec4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_model(model_path, output_size):\n",
    "    model_name = \"roberta-base\"\n",
    "    encoder = PretrainedEncoder(model_name, local_files_only=True).to(device)\n",
    "    policy = Seq2Labels(encoder_model=encoder, num_labels=output_size).to(device)\n",
    "    policy.load_state_dict(torch.load(model_path))\n",
    "    policy.eval()\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e4dde0-c3f4-448b-82c0-56c5cfd76c06",
   "metadata": {},
   "source": [
    "# Load Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "359d9b7a-79b0-4ad0-9c64-47d85aee5b52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of data in wi+locness: 24734\n",
      "Number of data without correct sentences: 15413\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"wi_locness_gec_lev_dist-v1\", new_step_api=True, correct_examples_percent=[0.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65ea936-90e4-490b-b640-c42caf641a1d",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbb5f929-496e-4094-b422-8bc706d9831d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "rl_model_path = os.path.abspath(\"pg_logs_new/finetune_rl_19_11_2022_13:25/model-last.pt\")\n",
    "sl_model_path = os.path.abspath(\"sl_logs/finetune_wi+locness_02:11:2022_23:06/model-best.pt\")\n",
    "rl_model = load_model(rl_model_path, output_size=len(env.labels))\n",
    "sl_model = load_model(sl_model_path, output_size=len(env.labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e90b34-f61b-454c-bbd4-aac2a0583fe3",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78177cae-217e-49fb-8ae4-bd375c24c8ae",
   "metadata": {},
   "source": [
    "# SL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09ab4c7e-5a4c-47ff-96cc-952eca185852",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajk/miniconda3/envs/drl-gec/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:133: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method should be an int or np.int64, actual type: <class 'list'>\u001b[0m\n",
      "  logger.warn(f\"{pre} should be an int or np.int64, actual type: {type(obs)}\")\n",
      "/home/rajk/miniconda3/envs/drl-gec/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:165: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 0.533590 | Label: $START           | $KEEP [0.92, 10.03] -- $APPEND_But [0.02,  6.12] -- $APPEND_And [0.01,  5.13]\n",
      "Entropy: 0.337851 | Label: he               | $TRANSFORM_CASE_CAPITAL [0.93, 11.58] -- $KEEP [0.06,  8.82] -- $REPLACE_He [0.00,  6.32]\n",
      "Entropy: 0.871657 | Label: said             | $APPEND_, [0.64, 10.05] -- $KEEP [0.32,  9.38] -- $REPLACE_, [0.01,  5.69]\n",
      "Entropy: 0.779609 | Label: in               | $KEEP [0.81,  9.01] -- $TRANSFORM_CASE_CAPITAL [0.10,  6.89] -- $DELETE [0.07,  6.58]\n",
      "Entropy: 0.595660 | Label: other            | $KEEP [0.87,  9.40] -- $DELETE [0.10,  7.21] -- $MERGE_SPACE [0.00,  4.15]\n",
      "Entropy: 0.896537 | Label: words            | $KEEP [0.64,  9.58] -- $APPEND_, [0.30,  8.84] -- $DELETE [0.05,  6.94]\n",
      "Entropy: 0.789471 | Label: that             | $KEEP [0.77,  9.21] -- $DELETE [0.17,  7.70] -- $REPLACE_, [0.03,  5.89]\n",
      "Entropy: 0.998475 | Label: the              | $DELETE [0.51,  8.31] -- $KEEP [0.45,  8.19] -- $UNKNOWN [0.01,  4.09]\n",
      "Entropy: 0.856027 | Label: more             | $KEEP [0.80,  8.93] -- $DELETE [0.13,  7.12] -- $UNKNOWN [0.02,  5.30]\n",
      "Entropy: 0.916357 | Label: fluoride         | $KEEP [0.84,  8.95] -- $UNKNOWN [0.08,  6.59] -- $APPEND_, [0.01,  4.84]\n",
      "Entropy: 1.235567 | Label: may              | $KEEP [0.68,  8.63] -- $REPLACE_might [0.20,  7.41] -- $REPLACE_could [0.02,  4.97]\n",
      "Entropy: 1.158607 | Label: create           | $KEEP [0.82,  9.16] -- $REPLACE_cause [0.04,  6.09] -- $APPEND_more [0.03,  5.80]\n",
      "Entropy: 0.891328 | Label: damage           | $KEEP [0.83,  9.16] -- $APPEND_to [0.10,  7.00] -- $UNKNOWN [0.01,  5.05]\n",
      "Entropy: 1.151927 | Label: in               | $APPEND_the [0.49, 10.52] -- $REPLACE_to [0.37, 10.24] -- $KEEP [0.10,  8.91]\n",
      "Entropy: 0.985000 | Label: human            | $KEEP [0.78,  8.64] -- $APPEND_'s [0.10,  6.57] -- $TRANSFORM_AGREEMENT_PLURAL [0.04,  5.71]\n",
      "Entropy: 0.821482 | Label: body             | $KEEP [0.83,  9.02] -- $TRANSFORM_VERB_VB_VBZ [0.08,  6.64] -- $DELETE [0.05,  6.17]\n",
      "Entropy: 0.582184 | Label: ,                | $KEEP [0.90,  9.33] -- $APPEND_and [0.04,  6.15] -- $APPEND_, [0.01,  4.95]\n",
      "Entropy: 1.006162 | Label: specifically     | $KEEP [0.82,  8.82] -- $APPEND_, [0.05,  6.00] -- $APPEND_to [0.04,  5.85]\n",
      "Entropy: 0.584729 | Label: the              | $KEEP [0.87,  9.66] -- $DELETE [0.06,  6.99] -- $REPLACE_to [0.05,  6.74]\n",
      "Entropy: 1.280136 | Label: bone             | $TRANSFORM_VERB_VB_VBZ [0.46,  9.23] -- $KEEP [0.35,  8.95] -- $TRANSFORM_AGREEMENT_PLURAL [0.14,  8.00]\n",
      "Entropy: 0.212481 | Label: .                | $KEEP [0.97,  9.51] -- $APPEND_\" [0.01,  4.93] -- $DELETE [0.01,  4.79]\n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 0  \n",
      "\u001b[37;1mRewards:\u001b[0m 0.000  \n",
      "\u001b[37;1mSource:\u001b[0m $START he said in other words that the more fluoride may create damage in human body , specifically the bone .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START he said in other words that the more fluoride may create damage in human body , specifically the bone .  \n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 1  \n",
      "\u001b[37;1mRewards:\u001b[0m 7.000  \n",
      "\u001b[37;1mSource:\u001b[0m $START \u001b[32;1mhe\u001b[0m [\u001b[31;1m$TRANSFORM_CASE_CAPITAL\u001b[0m] \u001b[32;1msaid\u001b[0m [\u001b[31;1m$APPEND_,\u001b[0m] in other words that \u001b[32;1mthe\u001b[0m [\u001b[31;1m$DELETE\u001b[0m] more fluoride may create damage \u001b[32;1min\u001b[0m [\u001b[31;1m$APPEND_the\u001b[0m] human body , specifically the \u001b[32;1mbone\u001b[0m [\u001b[31;1m$TRANSFORM_VERB_VB_VBZ\u001b[0m] .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START He said , in other words that more fluoride may create damage in the human body , specifically the bones .  \n",
      "\n",
      "Entropy: 0.280879 | Label: $START           | $KEEP [0.96, 10.68] -- $APPEND_But [0.01,  5.59] -- $APPEND_The [0.01,  5.44]\n",
      "Entropy: 0.498259 | Label: He               | $KEEP [0.93,  9.67] -- $REPLACE_He [0.02,  5.65] -- $APPEND_also [0.01,  5.23]\n",
      "Entropy: 0.807606 | Label: said             | $KEEP [0.81,  8.84] -- $TRANSFORM_VERB_VBN_VBZ [0.13,  7.04] -- $APPEND_that [0.01,  4.73]\n",
      "Entropy: 0.786212 | Label: ,                | $KEEP [0.74,  8.57] -- $DELETE [0.22,  7.35] -- $REPLACE_. [0.01,  3.98]\n",
      "Entropy: 0.880883 | Label: in               | $KEEP [0.71,  9.20] -- $TRANSFORM_CASE_CAPITAL [0.21,  8.00] -- $DELETE [0.07,  6.87]\n",
      "Entropy: 0.615040 | Label: other            | $KEEP [0.87,  9.33] -- $DELETE [0.10,  7.14] -- $MERGE_SPACE [0.01,  4.32]\n",
      "Entropy: 0.757378 | Label: words            | $APPEND_, [0.62, 10.58] -- $KEEP [0.36, 10.04] -- $DELETE [0.01,  6.47]\n",
      "Entropy: 0.885435 | Label: that             | $KEEP [0.78,  8.99] -- $REPLACE_, [0.11,  7.04] -- $DELETE [0.05,  6.23]\n",
      "Entropy: 1.014177 | Label: more             | $KEEP [0.72,  9.06] -- $DELETE [0.21,  7.84] -- $UNKNOWN [0.01,  5.18]\n",
      "Entropy: 0.809422 | Label: fluoride         | $KEEP [0.84,  9.47] -- $UNKNOWN [0.06,  6.81] -- $APPEND_, [0.05,  6.59]\n",
      "Entropy: 1.237387 | Label: may              | $KEEP [0.66,  8.70] -- $REPLACE_might [0.23,  7.66] -- $REPLACE_could [0.02,  5.22]\n",
      "Entropy: 1.136317 | Label: create           | $KEEP [0.81,  9.27] -- $REPLACE_cause [0.06,  6.71] -- $APPEND_more [0.01,  5.06]\n",
      "Entropy: 0.690814 | Label: damage           | $KEEP [0.90,  9.34] -- $APPEND_to [0.02,  5.61] -- $TRANSFORM_VERB_VB_VBZ [0.02,  5.47]\n",
      "Entropy: 0.924157 | Label: in               | $REPLACE_to [0.60, 10.17] -- $KEEP [0.35,  9.64] -- $REPLACE_on [0.03,  7.06]\n",
      "Entropy: 0.326816 | Label: the              | $KEEP [0.94,  9.77] -- $DELETE [0.03,  6.46] -- $UNKNOWN [0.01,  5.06]\n",
      "Entropy: 0.612387 | Label: human            | $KEEP [0.88,  9.19] -- $APPEND_'s [0.05,  6.41] -- $DELETE [0.02,  5.55]\n",
      "Entropy: 0.606782 | Label: body             | $KEEP [0.90,  9.21] -- $TRANSFORM_VERB_VB_VBZ [0.03,  5.96] -- $DELETE [0.02,  5.54]\n",
      "Entropy: 0.694875 | Label: ,                | $KEEP [0.87,  9.31] -- $APPEND_and [0.06,  6.65] -- $APPEND_, [0.01,  5.14]\n",
      "Entropy: 1.102868 | Label: specifically     | $KEEP [0.80,  8.81] -- $APPEND_to [0.05,  5.95] -- $APPEND_in [0.05,  5.94]\n",
      "Entropy: 0.732912 | Label: the              | $KEEP [0.82,  9.93] -- $REPLACE_to [0.08,  7.64] -- $DELETE [0.07,  7.54]\n",
      "Entropy: 0.596064 | Label: bones            | $KEEP [0.90,  8.77] -- $UNKNOWN [0.04,  5.56] -- $DELETE [0.02,  5.05]\n",
      "Entropy: 0.203664 | Label: .                | $KEEP [0.97,  9.59] -- $APPEND_\" [0.01,  5.40] -- $DELETE [0.00,  4.30]\n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 2  \n",
      "\u001b[37;1mRewards:\u001b[0m 3.000  \n",
      "\u001b[37;1mSource:\u001b[0m $START He said , in other \u001b[32;1mwords\u001b[0m [\u001b[31;1m$APPEND_,\u001b[0m] that more fluoride may create damage \u001b[32;1min\u001b[0m [\u001b[31;1m$REPLACE_to\u001b[0m] the human body , specifically the bones .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START He said , in other words , that more fluoride may create damage to the human body , specifically the bones .  \n",
      "\n",
      "Entropy: 0.233626 | Label: $START           | $KEEP [0.97, 10.99] -- $APPEND_But [0.01,  5.84] -- $APPEND_The [0.00,  5.69]\n",
      "Entropy: 0.512063 | Label: He               | $KEEP [0.92,  9.68] -- $APPEND_has [0.01,  5.49] -- $REPLACE_He [0.01,  5.48]\n",
      "Entropy: 0.774419 | Label: said             | $KEEP [0.78,  9.08] -- $TRANSFORM_VERB_VBN_VBZ [0.18,  7.60] -- $TRANSFORM_VERB_VBN_VB [0.01,  4.14]\n",
      "Entropy: 0.417338 | Label: ,                | $KEEP [0.91,  9.06] -- $DELETE [0.07,  6.44] -- $APPEND_, [0.01,  4.10]\n",
      "Entropy: 0.624958 | Label: in               | $KEEP [0.85,  9.34] -- $TRANSFORM_CASE_CAPITAL [0.08,  6.97] -- $DELETE [0.06,  6.66]\n",
      "Entropy: 0.517128 | Label: other            | $KEEP [0.90,  9.36] -- $DELETE [0.07,  6.87] -- $MERGE_SPACE [0.01,  4.49]\n",
      "Entropy: 0.474720 | Label: words            | $KEEP [0.91,  9.38] -- $DELETE [0.05,  6.55] -- $UNKNOWN [0.01,  4.59]\n",
      "Entropy: 0.451410 | Label: ,                | $KEEP [0.89,  9.44] -- $DELETE [0.09,  7.17] -- $UNKNOWN [0.00,  4.08]\n",
      "Entropy: 0.602944 | Label: that             | $KEEP [0.87,  8.91] -- $DELETE [0.10,  6.71] -- $APPEND_the [0.01,  4.05]\n",
      "Entropy: 1.011901 | Label: more             | $KEEP [0.73,  9.37] -- $DELETE [0.20,  8.10] -- $UNKNOWN [0.02,  5.84]\n",
      "Entropy: 0.819115 | Label: fluoride         | $KEEP [0.84,  9.56] -- $UNKNOWN [0.09,  7.37] -- $TRANSFORM_AGREEMENT_PLURAL [0.02,  5.60]\n",
      "Entropy: 1.238695 | Label: may              | $KEEP [0.63,  8.72] -- $REPLACE_might [0.27,  7.86] -- $REPLACE_could [0.02,  5.35]\n",
      "Entropy: 1.195832 | Label: create           | $KEEP [0.80,  9.11] -- $REPLACE_cause [0.07,  6.63] -- $REPLACE_do [0.01,  4.95]\n",
      "Entropy: 0.535847 | Label: damage           | $KEEP [0.93,  9.35] -- $TRANSFORM_VERB_VB_VBZ [0.01,  5.07] -- $APPEND_to [0.01,  4.96]\n",
      "Entropy: 0.487438 | Label: to               | $KEEP [0.91, 10.16] -- $REPLACE_for [0.02,  6.41] -- $REPLACE_in [0.02,  6.26]\n",
      "Entropy: 0.341052 | Label: the              | $KEEP [0.94,  9.70] -- $DELETE [0.04,  6.58] -- $UNKNOWN [0.01,  4.91]\n",
      "Entropy: 0.574298 | Label: human            | $KEEP [0.89,  9.23] -- $APPEND_'s [0.05,  6.34] -- $DELETE [0.02,  5.58]\n",
      "Entropy: 0.587794 | Label: body             | $KEEP [0.90,  9.22] -- $TRANSFORM_VERB_VB_VBZ [0.03,  5.94] -- $DELETE [0.02,  5.26]\n",
      "Entropy: 0.697921 | Label: ,                | $KEEP [0.86,  9.34] -- $APPEND_and [0.07,  6.81] -- $REPLACE_and [0.01,  5.26]\n",
      "Entropy: 0.888229 | Label: specifically     | $KEEP [0.86,  8.81] -- $APPEND_, [0.04,  5.77] -- $UNKNOWN [0.02,  4.98]\n",
      "Entropy: 0.680712 | Label: the              | $KEEP [0.84,  9.74] -- $DELETE [0.10,  7.59] -- $REPLACE_to [0.03,  6.54]\n",
      "Entropy: 0.584902 | Label: bones            | $KEEP [0.90,  8.79] -- $UNKNOWN [0.03,  5.52] -- $TRANSFORM_VERB_VBZ_VB [0.02,  4.77]\n",
      "Entropy: 0.195644 | Label: .                | $KEEP [0.97,  9.62] -- $APPEND_\" [0.01,  5.37] -- $DELETE [0.00,  4.19]\n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m \u001b[32;1m3\u001b[0m  \n",
      "\u001b[37;1mRewards:\u001b[0m 0.100  \n",
      "\u001b[37;1mSource:\u001b[0m $START He said , in other words , that more fluoride may create damage to the human body , specifically the bones .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START He said , in other words , that more fluoride may create damage to the human body , specifically the bones .  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajk/miniconda3/envs/drl-gec/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
      "  logger.deprecation(\n",
      "/home/rajk/miniconda3/envs/drl-gec/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:133: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method should be an int or np.int64, actual type: <class 'list'>\u001b[0m\n",
      "  logger.warn(f\"{pre} should be an int or np.int64, actual type: {type(obs)}\")\n",
      "/home/rajk/miniconda3/envs/drl-gec/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:165: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/home/rajk/miniconda3/envs/drl-gec/lib/python3.8/site-packages/gym/core.py:57: DeprecationWarning: \u001b[33mWARN: You are calling render method, but you didn't specified the argument render_mode at environment initialization. To maintain backward compatibility, the environment will render in human mode.\n",
      "If you want to render in human mode, initialize the environment in this way: gym.make('EnvName', render_mode='human') and don't call the render method.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n",
      "/home/rajk/miniconda3/envs/drl-gec/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:297: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "data_dict = dict(\n",
    "    text = \"he said in other words that the more fluoride may create damage in human body , specifically the bone .\",\n",
    "    references = [\n",
    "        \"He said in other words that the more fluoride may create damage in the human body , specifically the bone .\",\n",
    "        \"He said , in other words , that more fluoride may create damage in the human body , specifically the bone .\",\n",
    "        \"He said , in other words , that more fluoride may create damage to the human body , specifically the bones .\",\n",
    "        \"In other words , he said that more fluoride may damage the human body , specifically the bones .\"\n",
    "    ],\n",
    ")\n",
    "state = env.reset(data_dict=data_dict)\n",
    "done = False\n",
    "while not done:\n",
    "    action = greedy_action(sl_model, state, env.labels, verbose=True)\n",
    "    next_state, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    state = next_state\n",
    "    outputs = env.render()\n",
    "    for o in outputs:\n",
    "        print(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039e687c-e3cf-4ef2-987f-63898788dfe6",
   "metadata": {},
   "source": [
    "# RL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9c189a0-5eed-4b6a-af18-a43437147161",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 0.774663 | Label: $START           | $KEEP [0.85, 11.90] -- $APPEND_But [0.07,  9.39] -- $APPEND_And [0.02,  8.01]\n",
      "Entropy: 1.023935 | Label: he               | $TRANSFORM_CASE_CAPITAL [0.76, 11.36] -- $REPLACE_He [0.10,  9.33] -- $KEEP [0.07,  8.92]\n",
      "Entropy: 1.032397 | Label: said             | $KEEP [0.49,  9.64] -- $APPEND_, [0.45,  9.56] -- $DELETE [0.03,  6.80]\n",
      "Entropy: 0.962300 | Label: in               | $KEEP [0.78,  9.20] -- $DELETE [0.12,  7.29] -- $REPLACE_in [0.03,  5.85]\n",
      "Entropy: 0.680887 | Label: other            | $KEEP [0.84,  9.84] -- $DELETE [0.12,  7.86] -- $REPLACE_other [0.01,  5.24]\n",
      "Entropy: 0.877305 | Label: words            | $KEEP [0.63, 10.14] -- $APPEND_, [0.31,  9.43] -- $DELETE [0.04,  7.38]\n",
      "Entropy: 0.684049 | Label: that             | $KEEP [0.82, 10.51] -- $DELETE [0.13,  8.66] -- $APPEND_, [0.03,  7.05]\n",
      "Entropy: 1.173237 | Label: the              | $DELETE [0.65,  9.50] -- $KEEP [0.28,  8.67] -- $APPEND_more [0.00,  3.96]\n",
      "Entropy: 1.249199 | Label: more             | $KEEP [0.74, 10.38] -- $DELETE [0.15,  8.77] -- $APPEND_use [0.02,  6.91]\n",
      "Entropy: 0.588305 | Label: fluoride         | $KEEP [0.92, 10.13] -- $APPEND_, [0.02,  6.48] -- $DELETE [0.01,  5.42]\n",
      "Entropy: 1.084770 | Label: may              | $KEEP [0.76,  9.25] -- $REPLACE_might [0.12,  7.42] -- $DELETE [0.05,  6.49]\n",
      "Entropy: 0.978527 | Label: create           | $KEEP [0.85,  9.38] -- $DELETE [0.05,  6.55] -- $APPEND_more [0.03,  6.04]\n",
      "Entropy: 0.610641 | Label: damage           | $KEEP [0.91, 10.11] -- $APPEND_to [0.04,  7.06] -- $DELETE [0.01,  5.54]\n",
      "Entropy: 1.192837 | Label: in               | $APPEND_the [0.70, 10.61] -- $KEEP [0.10,  8.65] -- $REPLACE_to [0.08,  8.49]\n",
      "Entropy: 0.720330 | Label: human            | $KEEP [0.87,  9.20] -- $APPEND_'s [0.04,  6.23] -- $DELETE [0.02,  5.64]\n",
      "Entropy: 0.829795 | Label: body             | $KEEP [0.82,  9.90] -- $DELETE [0.08,  7.58] -- $TRANSFORM_VERB_VB_VBZ [0.07,  7.38]\n",
      "Entropy: 0.561844 | Label: ,                | $KEEP [0.90,  9.98] -- $APPEND_and [0.04,  6.73] -- $DELETE [0.03,  6.53]\n",
      "Entropy: 0.940458 | Label: specifically     | $KEEP [0.82,  9.79] -- $APPEND_, [0.06,  7.16] -- $APPEND_to [0.03,  6.53]\n",
      "Entropy: 0.597023 | Label: the              | $KEEP [0.88,  9.72] -- $DELETE [0.08,  7.30] -- $REPLACE_to [0.01,  5.11]\n",
      "Entropy: 1.295310 | Label: bone             | $KEEP [0.51,  9.85] -- $TRANSFORM_AGREEMENT_PLURAL [0.30,  9.32] -- $TRANSFORM_VERB_VB_VBZ [0.15,  8.64]\n",
      "Entropy: 0.214428 | Label: .                | $KEEP [0.97, 10.68] -- $DELETE [0.01,  6.30] -- $APPEND_\" [0.01,  5.78]\n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 0  \n",
      "\u001b[37;1mRewards:\u001b[0m 0.000  \n",
      "\u001b[37;1mSource:\u001b[0m $START he said in other words that the more fluoride may create damage in human body , specifically the bone .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START he said in other words that the more fluoride may create damage in human body , specifically the bone .  \n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 1  \n",
      "\u001b[37;1mRewards:\u001b[0m 4.000  \n",
      "\u001b[37;1mSource:\u001b[0m $START \u001b[32;1mhe\u001b[0m [\u001b[31;1m$TRANSFORM_CASE_CAPITAL\u001b[0m] said in other words that \u001b[32;1mthe\u001b[0m [\u001b[31;1m$DELETE\u001b[0m] more fluoride may create damage \u001b[32;1min\u001b[0m [\u001b[31;1m$APPEND_the\u001b[0m] human body , specifically the bone .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START He said in other words that more fluoride may create damage in the human body , specifically the bone .  \n",
      "\n",
      "Entropy: 0.147557 | Label: $START           | $KEEP [0.98, 13.22] -- $APPEND_But [0.01,  8.59] -- $APPEND_In [0.00,  6.62]\n",
      "Entropy: 0.527942 | Label: He               | $KEEP [0.92, 10.34] -- $APPEND_also [0.01,  6.20] -- $REPLACE_He [0.01,  6.09]\n",
      "Entropy: 0.882232 | Label: said             | $APPEND_, [0.63, 10.52] -- $KEEP [0.33,  9.87] -- $REPLACE_, [0.01,  6.45]\n",
      "Entropy: 0.984439 | Label: in               | $KEEP [0.79,  9.12] -- $DELETE [0.10,  7.02] -- $REPLACE_in [0.04,  6.18]\n",
      "Entropy: 0.731860 | Label: other            | $KEEP [0.84,  9.89] -- $DELETE [0.10,  7.75] -- $REPLACE_other [0.02,  5.89]\n",
      "Entropy: 0.903292 | Label: words            | $KEEP [0.51, 10.11] -- $APPEND_, [0.45,  9.99] -- $DELETE [0.03,  7.26]\n",
      "Entropy: 0.620638 | Label: that             | $KEEP [0.87, 10.43] -- $DELETE [0.05,  7.60] -- $APPEND_, [0.05,  7.53]\n",
      "Entropy: 1.123443 | Label: more             | $KEEP [0.60,  9.97] -- $DELETE [0.35,  9.42] -- $REPLACE_higher [0.01,  5.27]\n",
      "Entropy: 0.505170 | Label: fluoride         | $KEEP [0.93, 10.37] -- $APPEND_, [0.01,  6.16] -- $TRANSFORM_AGREEMENT_PLURAL [0.01,  5.72]\n",
      "Entropy: 1.253967 | Label: may              | $KEEP [0.64,  9.25] -- $REPLACE_might [0.24,  8.29] -- $DELETE [0.04,  6.36]\n",
      "Entropy: 1.082487 | Label: create           | $KEEP [0.84,  9.29] -- $DELETE [0.04,  6.28] -- $REPLACE_cause [0.02,  5.67]\n",
      "Entropy: 0.588249 | Label: damage           | $KEEP [0.93, 10.26] -- $APPEND_to [0.01,  5.90] -- $TRANSFORM_VERB_VB_VBZ [0.01,  5.14]\n",
      "Entropy: 1.602610 | Label: in               | $KEEP [0.44,  9.26] -- $REPLACE_to [0.30,  8.87] -- $APPEND_to [0.09,  7.70]\n",
      "Entropy: 0.373443 | Label: the              | $KEEP [0.94, 10.06] -- $DELETE [0.04,  6.85] -- $APPEND_the [0.01,  4.98]\n",
      "Entropy: 0.554350 | Label: human            | $KEEP [0.90,  9.69] -- $DELETE [0.04,  6.57] -- $APPEND_'s [0.04,  6.50]\n",
      "Entropy: 0.515002 | Label: body             | $KEEP [0.91, 10.13] -- $DELETE [0.04,  7.04] -- $TRANSFORM_VERB_VB_VBZ [0.02,  6.13]\n",
      "Entropy: 0.708503 | Label: ,                | $KEEP [0.86,  9.92] -- $APPEND_and [0.06,  7.29] -- $APPEND_, [0.03,  6.51]\n",
      "Entropy: 1.313911 | Label: specifically     | $KEEP [0.71,  9.74] -- $APPEND_, [0.09,  7.65] -- $APPEND_in [0.08,  7.55]\n",
      "Entropy: 0.701424 | Label: the              | $KEEP [0.87,  9.62] -- $DELETE [0.07,  7.14] -- $REPLACE_to [0.01,  5.25]\n",
      "Entropy: 1.314244 | Label: bone             | $TRANSFORM_AGREEMENT_PLURAL [0.44, 10.22] -- $KEEP [0.33,  9.92] -- $TRANSFORM_VERB_VB_VBZ [0.20,  9.44]\n",
      "Entropy: 0.194183 | Label: .                | $KEEP [0.97, 10.77] -- $DELETE [0.01,  6.08] -- $APPEND_\" [0.01,  5.98]\n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 2  \n",
      "\u001b[37;1mRewards:\u001b[0m 3.000  \n",
      "\u001b[37;1mSource:\u001b[0m $START He \u001b[32;1msaid\u001b[0m [\u001b[31;1m$APPEND_,\u001b[0m] in other words that more fluoride may create damage in the human body , specifically the \u001b[32;1mbone\u001b[0m [\u001b[31;1m$TRANSFORM_AGREEMENT_PLURAL\u001b[0m] .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START He said , in other words that more fluoride may create damage in the human body , specifically the bones .  \n",
      "\n",
      "Entropy: 0.165614 | Label: $START           | $KEEP [0.98, 13.24] -- $APPEND_But [0.01,  8.82] -- $APPEND_In [0.00,  6.78]\n",
      "Entropy: 0.536466 | Label: He               | $KEEP [0.91, 10.39] -- $APPEND_also [0.03,  6.87] -- $APPEND_has [0.02,  6.29]\n",
      "Entropy: 0.713102 | Label: said             | $KEEP [0.88,  9.49] -- $DELETE [0.06,  6.77] -- $TRANSFORM_VERB_VBN_VBZ [0.01,  5.25]\n",
      "Entropy: 0.872808 | Label: ,                | $KEEP [0.70,  9.18] -- $DELETE [0.26,  8.20] -- $APPEND_, [0.02,  5.64]\n",
      "Entropy: 0.986687 | Label: in               | $KEEP [0.76,  9.16] -- $DELETE [0.13,  7.36] -- $TRANSFORM_CASE_CAPITAL [0.05,  6.42]\n",
      "Entropy: 0.702330 | Label: other            | $KEEP [0.84,  9.93] -- $DELETE [0.11,  7.88] -- $APPEND_, [0.01,  5.75]\n",
      "Entropy: 0.520717 | Label: words            | $APPEND_, [0.82, 12.25] -- $KEEP [0.18, 10.71] -- $DELETE [0.00,  6.91]\n",
      "Entropy: 0.984366 | Label: that             | $KEEP [0.72, 10.15] -- $APPEND_, [0.19,  8.79] -- $REPLACE_, [0.04,  7.26]\n",
      "Entropy: 1.162173 | Label: more             | $KEEP [0.64,  9.69] -- $DELETE [0.29,  8.88] -- $APPEND_, [0.01,  5.62]\n",
      "Entropy: 0.658490 | Label: fluoride         | $KEEP [0.87, 10.35] -- $APPEND_, [0.09,  8.12] -- $TRANSFORM_AGREEMENT_PLURAL [0.01,  5.54]\n",
      "Entropy: 1.233957 | Label: may              | $KEEP [0.66,  9.27] -- $REPLACE_might [0.23,  8.22] -- $DELETE [0.03,  6.30]\n",
      "Entropy: 1.082996 | Label: create           | $KEEP [0.84,  9.29] -- $DELETE [0.04,  6.31] -- $REPLACE_cause [0.02,  5.52]\n",
      "Entropy: 0.611322 | Label: damage           | $KEEP [0.93, 10.20] -- $APPEND_to [0.01,  5.94] -- $TRANSFORM_VERB_VB_VBZ [0.01,  5.22]\n",
      "Entropy: 1.593776 | Label: in               | $KEEP [0.42,  9.23] -- $REPLACE_to [0.33,  8.98] -- $APPEND_to [0.10,  7.81]\n",
      "Entropy: 0.375662 | Label: the              | $KEEP [0.93, 10.06] -- $DELETE [0.04,  6.88] -- $APPEND_the [0.01,  4.91]\n",
      "Entropy: 0.530751 | Label: human            | $KEEP [0.91,  9.68] -- $APPEND_'s [0.04,  6.43] -- $DELETE [0.04,  6.43]\n",
      "Entropy: 0.569928 | Label: body             | $KEEP [0.90, 10.06] -- $DELETE [0.04,  6.84] -- $TRANSFORM_VERB_VB_VBZ [0.03,  6.66]\n",
      "Entropy: 0.762314 | Label: ,                | $KEEP [0.84,  9.81] -- $APPEND_and [0.08,  7.42] -- $APPEND_, [0.03,  6.46]\n",
      "Entropy: 1.361783 | Label: specifically     | $KEEP [0.69,  9.67] -- $APPEND_, [0.09,  7.68] -- $APPEND_in [0.09,  7.60]\n",
      "Entropy: 1.051006 | Label: the              | $KEEP [0.76,  9.55] -- $DELETE [0.12,  7.67] -- $REPLACE_to [0.05,  6.86]\n",
      "Entropy: 0.429566 | Label: bones            | $KEEP [0.95,  9.57] -- $DELETE [0.02,  5.63] -- $TRANSFORM_VERB_VBZ_VB [0.01,  4.63]\n",
      "Entropy: 0.190316 | Label: .                | $KEEP [0.97, 10.81] -- $APPEND_\" [0.01,  6.05] -- $DELETE [0.01,  6.00]\n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 3  \n",
      "\u001b[37;1mRewards:\u001b[0m 1.000  \n",
      "\u001b[37;1mSource:\u001b[0m $START He said , in other \u001b[32;1mwords\u001b[0m [\u001b[31;1m$APPEND_,\u001b[0m] that more fluoride may create damage in the human body , specifically the bones .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START He said , in other words , that more fluoride may create damage in the human body , specifically the bones .  \n",
      "\n",
      "Entropy: 0.128865 | Label: $START           | $KEEP [0.98, 13.68] -- $APPEND_But [0.01,  9.10] -- $APPEND_However [0.00,  6.83]\n",
      "Entropy: 0.573299 | Label: He               | $KEEP [0.90, 10.39] -- $APPEND_also [0.03,  6.95] -- $APPEND_has [0.02,  6.78]\n",
      "Entropy: 0.616019 | Label: said             | $KEEP [0.90,  9.57] -- $DELETE [0.04,  6.45] -- $TRANSFORM_VERB_VBN_VBZ [0.02,  5.78]\n",
      "Entropy: 0.561616 | Label: ,                | $KEEP [0.87,  9.87] -- $DELETE [0.08,  7.52] -- $APPEND_, [0.04,  6.72]\n",
      "Entropy: 0.746074 | Label: in               | $KEEP [0.83,  9.42] -- $DELETE [0.09,  7.25] -- $REPLACE_in [0.03,  5.98]\n",
      "Entropy: 0.574701 | Label: other            | $KEEP [0.88, 10.06] -- $DELETE [0.08,  7.67] -- $APPEND_other [0.01,  5.36]\n",
      "Entropy: 0.430831 | Label: words            | $KEEP [0.93, 10.07] -- $DELETE [0.05,  7.11] -- $APPEND_, [0.00,  4.82]\n",
      "Entropy: 0.325644 | Label: ,                | $KEEP [0.94, 10.66] -- $DELETE [0.04,  7.57] -- $APPEND_, [0.01,  6.29]\n",
      "Entropy: 0.513652 | Label: that             | $KEEP [0.91, 10.04] -- $DELETE [0.06,  7.29] -- $APPEND_that [0.01,  4.97]\n",
      "Entropy: 1.117075 | Label: more             | $KEEP [0.63, 10.13] -- $DELETE [0.31,  9.41] -- $REPLACE_higher [0.01,  5.82]\n",
      "Entropy: 0.545956 | Label: fluoride         | $KEEP [0.93, 10.42] -- $TRANSFORM_AGREEMENT_PLURAL [0.01,  5.90] -- $APPEND_, [0.01,  5.73]\n",
      "Entropy: 1.243765 | Label: may              | $KEEP [0.63,  9.27] -- $REPLACE_might [0.26,  8.39] -- $DELETE [0.03,  6.28]\n",
      "Entropy: 1.147280 | Label: create           | $KEEP [0.83,  9.26] -- $DELETE [0.04,  6.32] -- $REPLACE_cause [0.02,  5.68]\n",
      "Entropy: 0.638872 | Label: damage           | $KEEP [0.92, 10.19] -- $APPEND_to [0.01,  5.88] -- $TRANSFORM_VERB_VB_VBZ [0.01,  5.28]\n",
      "Entropy: 1.628133 | Label: in               | $KEEP [0.40,  9.19] -- $REPLACE_to [0.33,  8.99] -- $APPEND_to [0.11,  7.86]\n",
      "Entropy: 0.386557 | Label: the              | $KEEP [0.93, 10.03] -- $DELETE [0.04,  6.87] -- $APPEND_the [0.01,  4.95]\n",
      "Entropy: 0.537680 | Label: human            | $KEEP [0.91,  9.68] -- $APPEND_'s [0.04,  6.50] -- $DELETE [0.03,  6.36]\n",
      "Entropy: 0.590893 | Label: body             | $KEEP [0.90, 10.05] -- $TRANSFORM_VERB_VB_VBZ [0.04,  6.86] -- $DELETE [0.03,  6.70]\n",
      "Entropy: 0.811434 | Label: ,                | $KEEP [0.83,  9.80] -- $APPEND_and [0.09,  7.59] -- $APPEND_, [0.03,  6.50]\n",
      "Entropy: 1.440634 | Label: specifically     | $KEEP [0.66,  9.71] -- $APPEND_in [0.10,  7.83] -- $APPEND_, [0.09,  7.74]\n",
      "Entropy: 1.105923 | Label: the              | $KEEP [0.74,  9.53] -- $DELETE [0.12,  7.69] -- $REPLACE_to [0.06,  7.06]\n",
      "Entropy: 0.442333 | Label: bones            | $KEEP [0.94,  9.56] -- $DELETE [0.02,  5.60] -- $TRANSFORM_VERB_VBZ_VB [0.01,  4.78]\n",
      "Entropy: 0.184488 | Label: .                | $KEEP [0.97, 10.83] -- $APPEND_\" [0.01,  5.95] -- $DELETE [0.01,  5.94]\n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m \u001b[32;1m4\u001b[0m  \n",
      "\u001b[37;1mRewards:\u001b[0m 0.000  \n",
      "\u001b[37;1mSource:\u001b[0m $START He said , in other words , that more fluoride may create damage in the human body , specifically the bones .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START He said , in other words , that more fluoride may create damage in the human body , specifically the bones .  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_dict = dict(\n",
    "    text = \"he said in other words that the more fluoride may create damage in human body , specifically the bone .\",\n",
    "    references = [\n",
    "        \"He said in other words that the more fluoride may create damage in the human body , specifically the bone .\",\n",
    "        \"He said , in other words , that more fluoride may create damage in the human body , specifically the bone .\",\n",
    "        \"He said , in other words , that more fluoride may create damage to the human body , specifically the bones .\",\n",
    "        \"In other words , he said that more fluoride may damage the human body , specifically the bones .\"\n",
    "    ]\n",
    ")\n",
    "state = env.reset(data_dict=data_dict)\n",
    "done = False\n",
    "while not done:\n",
    "    action = greedy_action(rl_model, state, env.labels, verbose=True)\n",
    "    next_state, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    state = next_state\n",
    "    outputs = env.render()\n",
    "    for o in outputs:\n",
    "        print(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2ebd33-87ff-4c46-80d4-ab6322d8c147",
   "metadata": {},
   "source": [
    "# RL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23afbcae-b6db-46dc-b4aa-a890c3161f52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 0.142187 | Label: $START           | $KEEP [0.98, 13.14] -- $APPEND_But [0.01,  8.24] -- $APPEND_However [0.00,  7.45]\n",
      "Entropy: 0.284960 | Label: Unfortunately    | $KEEP [0.96, 10.57] -- $DELETE [0.02,  6.58] -- $APPEND_, [0.00,  5.15]\n",
      "Entropy: 0.316656 | Label: ,                | $KEEP [0.93, 10.65] -- $DELETE [0.05,  7.77] -- $APPEND_, [0.01,  5.68]\n",
      "Entropy: 0.262932 | Label: there            | $KEEP [0.96, 10.90] -- $DELETE [0.02,  7.25] -- $APPEND_there [0.00,  5.00]\n",
      "Entropy: 0.547691 | Label: is               | $KEEP [0.89, 10.12] -- $DELETE [0.07,  7.58] -- $REPLACE_are [0.01,  5.33]\n",
      "Entropy: 0.452718 | Label: still            | $KEEP [0.92, 11.01] -- $DELETE [0.04,  7.91] -- $APPEND_much [0.02,  6.99]\n",
      "Entropy: 0.424061 | Label: a                | $KEEP [0.92, 11.81] -- $DELETE [0.06,  9.04] -- $APPEND_lot [0.00,  6.57]\n",
      "Entropy: 0.395132 | Label: long             | $KEEP [0.94, 10.71] -- $DELETE [0.03,  7.14] -- $APPEND_a [0.01,  5.68]\n",
      "Entropy: 0.262892 | Label: way              | $KEEP [0.97, 11.56] -- $DELETE [0.00,  6.23] -- $APPEND_much [0.00,  5.75]\n",
      "Entropy: 0.423724 | Label: to               | $KEEP [0.94, 10.87] -- $DELETE [0.02,  6.79] -- $APPEND_be [0.01,  6.07]\n",
      "Entropy: 1.008666 | Label: do               | $KEEP [0.81, 11.31] -- $REPLACE_go [0.08,  8.97] -- $DELETE [0.04,  8.27]\n",
      "Entropy: 0.693958 | Label: in               | $KEEP [0.86,  9.62] -- $DELETE [0.09,  7.36] -- $APPEND_the [0.01,  5.35]\n",
      "Entropy: 0.601683 | Label: terms            | $APPEND_of [0.88, 11.04] -- $KEEP [0.06,  8.27] -- $DELETE [0.03,  7.69]\n",
      "Entropy: 0.441442 | Label: environment      | $KEEP [0.93,  9.87] -- $DELETE [0.05,  6.92] -- $TRANSFORM_AGREEMENT_PLURAL [0.00,  3.72]\n",
      "Entropy: 0.880201 | Label: concerns         | $KEEP [0.84,  9.61] -- $DELETE [0.09,  7.41] -- $REPLACE_issues [0.02,  5.61]\n",
      "Entropy: 0.423690 | Label: ,                | $KEEP [0.91, 10.43] -- $DELETE [0.07,  7.86] -- $APPEND_, [0.01,  5.86]\n",
      "Entropy: 0.318278 | Label: but              | $KEEP [0.96, 10.21] -- $DELETE [0.01,  5.77] -- $APPEND_, [0.01,  5.00]\n",
      "Entropy: 0.269983 | Label: some             | $KEEP [0.97, 10.68] -- $DELETE [0.01,  6.46] -- $REPLACE_few [0.00,  4.34]\n",
      "Entropy: 0.351522 | Label: of               | $KEEP [0.94, 10.25] -- $DELETE [0.05,  7.25] -- $APPEND_the [0.01,  5.10]\n",
      "Entropy: 1.418347 | Label: this             | $REPLACE_the [0.54,  9.64] -- $KEEP [0.20,  8.67] -- $DELETE [0.11,  8.04]\n",
      "Entropy: 0.525845 | Label: solutions        | $KEEP [0.92,  9.58] -- $DELETE [0.04,  6.49] -- $APPEND_are [0.00,  4.26]\n",
      "Entropy: 0.349423 | Label: suggested        | $KEEP [0.96,  9.88] -- $DELETE [0.01,  5.69] -- $APPEND_, [0.00,  3.24]\n",
      "Entropy: 0.257855 | Label: by               | $KEEP [0.96, 10.02] -- $DELETE [0.01,  5.66] -- $REPLACE_by [0.01,  4.98]\n",
      "Entropy: 0.297950 | Label: the              | $KEEP [0.95, 10.17] -- $DELETE [0.04,  6.94] -- $TRANSFORM_CASE_CAPITAL [0.00,  3.64]\n",
      "Entropy: 1.456377 | Label: mayor            | $KEEP [0.57, 10.06] -- $APPEND_will [0.25,  9.24] -- $APPEND_could [0.06,  7.83]\n",
      "Entropy: 1.220305 | Label: help             | $KEEP [0.83,  8.74] -- $DELETE [0.02,  5.11] -- $TRANSFORM_VERB_VB_VBN [0.02,  4.83]\n",
      "Entropy: 1.202322 | Label: us               | $KEEP [0.73,  9.21] -- $DELETE [0.09,  7.16] -- $APPEND_in [0.06,  6.69]\n",
      "Entropy: 1.013830 | Label: stopping         | $TRANSFORM_VERB_VBG_VB [0.83, 10.50] -- $KEEP [0.08,  8.16] -- $DELETE [0.03,  7.09]\n",
      "Entropy: 0.966808 | Label: the              | $DELETE [0.53,  9.71] -- $KEEP [0.44,  9.53] -- $REPLACE_to [0.00,  3.60]\n",
      "Entropy: 0.387075 | Label: pollution        | $KEEP [0.96, 10.08] -- $DELETE [0.01,  5.86] -- $TRANSFORM_AGREEMENT_PLURAL [0.00,  3.95]\n",
      "Entropy: 0.175216 | Label: .                | $KEEP [0.98, 10.91] -- $DELETE [0.01,  6.08] -- $APPEND_. [0.00,  5.48]\n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 0  \n",
      "\u001b[37;1mRewards:\u001b[0m 0.000  \n",
      "\u001b[37;1mSource:\u001b[0m $START Unfortunately , there is still a long way to do in terms environment concerns , but some of this solutions suggested by the mayor help us stopping the pollution .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START Unfortunately , there is still a long way to do in terms environment concerns , but some of this solutions suggested by the mayor help us stopping the pollution .  \n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 1  \n",
      "\u001b[37;1mRewards:\u001b[0m 2.000  \n",
      "\u001b[37;1mSource:\u001b[0m $START Unfortunately , there is still a long way to do in \u001b[32;1mterms\u001b[0m [\u001b[31;1m$APPEND_of\u001b[0m] environment concerns , but some of \u001b[32;1mthis\u001b[0m [\u001b[31;1m$REPLACE_the\u001b[0m] solutions suggested by the mayor help us \u001b[32;1mstopping\u001b[0m [\u001b[31;1m$TRANSFORM_VERB_VBG_VB\u001b[0m] \u001b[32;1mthe\u001b[0m [\u001b[31;1m$DELETE\u001b[0m] pollution .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START Unfortunately , there is still a long way to do in terms of environment concerns , but some of the solutions suggested by the mayor help us stop pollution .  \n",
      "\n",
      "Entropy: 0.105472 | Label: $START           | $KEEP [0.99, 13.60] -- $APPEND_But [0.01,  8.46] -- $APPEND_However [0.00,  7.53]\n",
      "Entropy: 0.333633 | Label: Unfortunately    | $KEEP [0.96, 10.51] -- $DELETE [0.02,  6.47] -- $APPEND_, [0.01,  5.48]\n",
      "Entropy: 0.338643 | Label: ,                | $KEEP [0.93, 10.58] -- $DELETE [0.05,  7.67] -- $APPEND_, [0.01,  5.98]\n",
      "Entropy: 0.303885 | Label: there            | $KEEP [0.95, 10.79] -- $DELETE [0.03,  7.19] -- $REPLACE_there [0.00,  5.22]\n",
      "Entropy: 0.672130 | Label: is               | $KEEP [0.86,  9.91] -- $DELETE [0.09,  7.63] -- $REPLACE_are [0.01,  5.36]\n",
      "Entropy: 0.578231 | Label: still            | $KEEP [0.89, 10.92] -- $DELETE [0.04,  7.93] -- $APPEND_much [0.03,  7.54]\n",
      "Entropy: 0.541277 | Label: a                | $KEEP [0.89, 11.49] -- $DELETE [0.07,  8.96] -- $APPEND_lot [0.01,  6.85]\n",
      "Entropy: 0.516248 | Label: long             | $KEEP [0.92, 10.51] -- $DELETE [0.03,  7.16] -- $APPEND_a [0.01,  5.83]\n",
      "Entropy: 0.332718 | Label: way              | $KEEP [0.96, 11.49] -- $APPEND_much [0.00,  6.18] -- $DELETE [0.00,  6.02]\n",
      "Entropy: 0.531257 | Label: to               | $KEEP [0.93, 10.71] -- $DELETE [0.02,  6.75] -- $APPEND_be [0.01,  6.12]\n",
      "Entropy: 1.244023 | Label: do               | $KEEP [0.73, 11.29] -- $REPLACE_go [0.15,  9.68] -- $DELETE [0.04,  8.36]\n",
      "Entropy: 0.659533 | Label: in               | $KEEP [0.87,  9.48] -- $DELETE [0.09,  7.22] -- $REPLACE_in [0.01,  4.80]\n",
      "Entropy: 0.665021 | Label: terms            | $KEEP [0.82,  9.78] -- $DELETE [0.15,  8.10] -- $APPEND_of [0.00,  4.53]\n",
      "Entropy: 0.704616 | Label: of               | $KEEP [0.88, 10.34] -- $DELETE [0.04,  7.34] -- $APPEND_the [0.03,  7.06]\n",
      "Entropy: 0.738191 | Label: environment      | $KEEP [0.87,  9.67] -- $DELETE [0.08,  7.24] -- $TRANSFORM_AGREEMENT_PLURAL [0.00,  4.19]\n",
      "Entropy: 1.022644 | Label: concerns         | $KEEP [0.82,  9.51] -- $DELETE [0.08,  7.25] -- $REPLACE_issues [0.03,  6.11]\n",
      "Entropy: 0.436973 | Label: ,                | $KEEP [0.91, 10.33] -- $DELETE [0.06,  7.65] -- $APPEND_, [0.01,  5.96]\n",
      "Entropy: 0.367423 | Label: but              | $KEEP [0.95, 10.14] -- $DELETE [0.01,  5.51] -- $APPEND_, [0.01,  5.14]\n",
      "Entropy: 0.285841 | Label: some             | $KEEP [0.97, 10.72] -- $DELETE [0.01,  6.27] -- $REPLACE_few [0.00,  4.98]\n",
      "Entropy: 0.243161 | Label: of               | $KEEP [0.96, 10.45] -- $DELETE [0.02,  6.71] -- $APPEND_the [0.00,  5.14]\n",
      "Entropy: 0.384174 | Label: the              | $KEEP [0.95, 10.10] -- $DELETE [0.02,  6.37] -- $APPEND_new [0.01,  5.24]\n",
      "Entropy: 0.459221 | Label: solutions        | $KEEP [0.94,  9.69] -- $DELETE [0.02,  5.91] -- $APPEND_are [0.00,  4.26]\n",
      "Entropy: 0.432834 | Label: suggested        | $KEEP [0.95,  9.73] -- $DELETE [0.01,  5.22] -- $APPEND_today [0.00,  3.87]\n",
      "Entropy: 0.286026 | Label: by               | $KEEP [0.96,  9.88] -- $DELETE [0.01,  5.29] -- $REPLACE_by [0.01,  4.93]\n",
      "Entropy: 0.353768 | Label: the              | $KEEP [0.94,  9.97] -- $DELETE [0.03,  6.64] -- $APPEND_new [0.00,  4.05]\n",
      "Entropy: 1.633105 | Label: mayor            | $KEEP [0.44,  9.66] -- $APPEND_will [0.34,  9.41] -- $APPEND_could [0.06,  7.74]\n",
      "Entropy: 1.207882 | Label: help             | $KEEP [0.82,  8.66] -- $TRANSFORM_VERB_VB_VBN [0.04,  5.58] -- $APPEND_to [0.02,  4.73]\n",
      "Entropy: 0.886333 | Label: us               | $KEEP [0.80,  9.73] -- $APPEND_to [0.10,  7.62] -- $DELETE [0.06,  7.09]\n",
      "Entropy: 0.850167 | Label: stop             | $KEEP [0.88,  9.28] -- $DELETE [0.03,  5.78] -- $APPEND_the [0.02,  5.33]\n",
      "Entropy: 0.478328 | Label: pollution        | $KEEP [0.95, 10.18] -- $DELETE [0.01,  5.48] -- $TRANSFORM_AGREEMENT_PLURAL [0.00,  4.54]\n",
      "Entropy: 0.183659 | Label: .                | $KEEP [0.98, 10.92] -- $DELETE [0.01,  5.66] -- $APPEND_\" [0.01,  5.66]\n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m \u001b[32;1m2\u001b[0m  \n",
      "\u001b[37;1mRewards:\u001b[0m 0.000  \n",
      "\u001b[37;1mSource:\u001b[0m $START Unfortunately , there is still a long way to do in terms of environment concerns , but some of the solutions suggested by the mayor help us stop pollution .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START Unfortunately , there is still a long way to do in terms of environment concerns , but some of the solutions suggested by the mayor help us stop pollution .  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_dict = dict(\n",
    "    text = \"$START Unfortunately , there is still a long way to do in terms environment concerns , but some of this solutions suggested by the mayor help us stopping the pollution .\",\n",
    "    references = [\n",
    "        \"Unfortunately , there is still a long way to go in terms of environmental concerns , but some of these solutions suggested by the mayor help us stop the pollution .\"\n",
    "    ]\n",
    ")\n",
    "state = env.reset(data_dict=data_dict)\n",
    "done = False\n",
    "while not done:\n",
    "    action = greedy_action(rl_model, state, env.labels, verbose=True)\n",
    "    next_state, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    state = next_state\n",
    "    outputs = env.render()\n",
    "    for o in outputs:\n",
    "        print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04ca7094-2523-4467-8031-ca9989334d7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 0.149045 | Label: $START           | $KEEP [0.98, 13.62] -- $APPEND_But [0.01,  9.30] -- $APPEND_And [0.00,  7.32]\n",
      "Entropy: 0.292497 | Label: I                | $KEEP [0.96, 11.82] -- $APPEND_also [0.02,  7.78] -- $APPEND_would [0.01,  6.93]\n",
      "Entropy: 0.351736 | Label: think            | $KEEP [0.94, 10.61] -- $APPEND_that [0.04,  7.34] -- $TRANSFORM_VERB_VB_VBN [0.01,  5.68]\n",
      "Entropy: 1.183376 | Label: someone          | $KEEP [0.78,  9.55] -- $REPLACE_people [0.07,  7.08] -- $DELETE [0.05,  6.76]\n",
      "Entropy: 0.582261 | Label: should           | $KEEP [0.92, 10.12] -- $DELETE [0.02,  6.19] -- $REPLACE_would [0.01,  5.41]\n",
      "Entropy: 1.012070 | Label: get              | $KEEP [0.84, 10.13] -- $APPEND_to [0.03,  6.62] -- $REPLACE_get [0.02,  6.58]\n",
      "Entropy: 0.853198 | Label: exercise         | $KEEP [0.89,  9.43] -- $DELETE [0.02,  5.61] -- $TRANSFORM_VERB_VB_VBN [0.01,  4.90]\n",
      "Entropy: 0.627109 | Label: by               | $KEEP [0.89,  9.75] -- $DELETE [0.07,  7.15] -- $REPLACE_by [0.02,  5.78]\n",
      "Entropy: 1.426065 | Label: starting         | $APPEND_to [0.44,  8.97] -- $KEEP [0.28,  8.51] -- $DELETE [0.23,  8.32]\n",
      "Entropy: 1.707141 | Label: play             | $KEEP [0.53,  8.55] -- $DELETE [0.18,  7.49] -- $TRANSFORM_VERB_VB_VBG [0.17,  7.42]\n",
      "Entropy: 1.531872 | Label: some             | $KEEP [0.65,  8.89] -- $REPLACE_their [0.11,  7.15] -- $DELETE [0.08,  6.79]\n",
      "Entropy: 0.946773 | Label: favourite        | $KEEP [0.88,  9.85] -- $DELETE [0.03,  6.48] -- $REPLACE_favourite [0.02,  5.92]\n",
      "Entropy: 1.398229 | Label: sport            | $KEEP [0.60, 10.00] -- $TRANSFORM_VERB_VB_VBZ [0.16,  8.70] -- $APPEND_, [0.13,  8.50]\n",
      "Entropy: 0.430483 | Label: instead          | $KEEP [0.92, 10.30] -- $APPEND_, [0.05,  7.40] -- $DELETE [0.02,  6.44]\n",
      "Entropy: 0.579172 | Label: of               | $KEEP [0.92, 10.06] -- $APPEND_of [0.02,  6.31] -- $DELETE [0.01,  5.95]\n",
      "Entropy: 0.918385 | Label: watching         | $KEEP [0.86,  9.81] -- $REPLACE_watching [0.03,  6.60] -- $REPLACE_seeing [0.02,  6.16]\n",
      "Entropy: 1.243777 | Label: To               | $KEEP [0.82,  9.87] -- $DELETE [0.06,  7.18] -- $TRANSFORM_CASE_LOWER [0.02,  6.05]\n",
      "Entropy: 0.638023 | Label: or               | $KEEP [0.92,  9.86] -- $DELETE [0.01,  5.22] -- $REPLACE_or [0.01,  5.07]\n",
      "Entropy: 1.421736 | Label: playing          | $KEEP [0.46,  9.04] -- $APPEND_a [0.40,  8.91] -- $APPEND_the [0.06,  7.09]\n",
      "Entropy: 1.178335 | Label: game             | $TRANSFORM_VERB_VB_VBZ [0.66, 10.37] -- $KEEP [0.24,  9.35] -- $TRANSFORM_AGREEMENT_PLURAL [0.04,  7.54]\n",
      "Entropy: 0.286847 | Label: .                | $KEEP [0.96, 10.39] -- $DELETE [0.01,  5.96] -- $REPLACE_! [0.01,  5.50]\n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 0  \n",
      "\u001b[37;1mRewards:\u001b[0m 0.000  \n",
      "\u001b[37;1mSource:\u001b[0m $START I think someone should get exercise by starting play some favourite sport instead of watching To or playing game .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START I think someone should get exercise by starting play some favourite sport instead of watching To or playing game .  \n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 1  \n",
      "\u001b[37;1mRewards:\u001b[0m 3.000  \n",
      "\u001b[37;1mSource:\u001b[0m $START I think someone should get exercise by \u001b[32;1mstarting\u001b[0m [\u001b[31;1m$APPEND_to\u001b[0m] play some favourite sport instead of watching To or playing \u001b[32;1mgame\u001b[0m [\u001b[31;1m$TRANSFORM_VERB_VB_VBZ\u001b[0m] .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START I think someone should get exercise by starting to play some favourite sport instead of watching To or playing games .  \n",
      "\n",
      "Entropy: 0.137574 | Label: $START           | $KEEP [0.98, 13.80] -- $APPEND_But [0.01,  9.46] -- $APPEND_And [0.00,  7.53]\n",
      "Entropy: 0.313089 | Label: I                | $KEEP [0.95, 11.77] -- $APPEND_also [0.02,  7.88] -- $APPEND_would [0.01,  6.92]\n",
      "Entropy: 0.412613 | Label: think            | $KEEP [0.93, 10.51] -- $APPEND_that [0.05,  7.52] -- $TRANSFORM_VERB_VB_VBN [0.01,  5.82]\n",
      "Entropy: 1.342979 | Label: someone          | $KEEP [0.74,  9.44] -- $REPLACE_people [0.09,  7.34] -- $DELETE [0.05,  6.72]\n",
      "Entropy: 0.679937 | Label: should           | $KEEP [0.90, 10.01] -- $DELETE [0.02,  6.23] -- $REPLACE_would [0.01,  5.61]\n",
      "Entropy: 1.289994 | Label: get              | $KEEP [0.78, 10.00] -- $APPEND_to [0.03,  6.85] -- $REPLACE_get [0.03,  6.78]\n",
      "Entropy: 1.038983 | Label: exercise         | $KEEP [0.87,  9.33] -- $DELETE [0.02,  5.56] -- $APPEND_, [0.01,  5.12]\n",
      "Entropy: 0.703138 | Label: by               | $KEEP [0.88,  9.59] -- $DELETE [0.05,  6.72] -- $REPLACE_by [0.04,  6.42]\n",
      "Entropy: 0.986312 | Label: starting         | $KEEP [0.82,  8.83] -- $DELETE [0.11,  6.78] -- $APPEND_to [0.02,  4.87]\n",
      "Entropy: 0.592127 | Label: to               | $KEEP [0.86,  9.97] -- $DELETE [0.12,  8.00] -- $REPLACE_to [0.00,  3.51]\n",
      "Entropy: 1.282864 | Label: play             | $KEEP [0.78,  8.85] -- $DELETE [0.08,  6.63] -- $APPEND_playing [0.03,  5.74]\n",
      "Entropy: 1.752859 | Label: some             | $KEEP [0.57,  8.69] -- $REPLACE_their [0.18,  7.54] -- $DELETE [0.06,  6.45]\n",
      "Entropy: 1.230920 | Label: favourite        | $KEEP [0.83,  9.75] -- $REPLACE_favourite [0.03,  6.57] -- $DELETE [0.03,  6.39]\n",
      "Entropy: 1.611194 | Label: sport            | $KEEP [0.38,  9.86] -- $TRANSFORM_VERB_VB_VBZ [0.35,  9.77] -- $APPEND_, [0.11,  8.64]\n",
      "Entropy: 0.491908 | Label: instead          | $KEEP [0.90, 10.14] -- $APPEND_, [0.06,  7.42] -- $DELETE [0.02,  6.44]\n",
      "Entropy: 0.619157 | Label: of               | $KEEP [0.91, 10.07] -- $APPEND_of [0.03,  6.47] -- $DELETE [0.01,  5.95]\n",
      "Entropy: 1.066143 | Label: watching         | $KEEP [0.83,  9.69] -- $REPLACE_watching [0.04,  6.62] -- $REPLACE_seeing [0.03,  6.30]\n",
      "Entropy: 1.412968 | Label: To               | $KEEP [0.80, 10.06] -- $DELETE [0.05,  7.28] -- $TRANSFORM_CASE_LOWER [0.02,  6.53]\n",
      "Entropy: 0.712952 | Label: or               | $KEEP [0.90,  9.80] -- $REPLACE_and [0.01,  5.53] -- $DELETE [0.01,  5.25]\n",
      "Entropy: 0.923227 | Label: playing          | $KEEP [0.86,  9.37] -- $DELETE [0.04,  6.18] -- $APPEND_the [0.02,  5.66]\n",
      "Entropy: 0.601053 | Label: games            | $KEEP [0.92,  9.79] -- $DELETE [0.03,  6.24] -- $TRANSFORM_VERB_VBZ_VB [0.01,  5.22]\n",
      "Entropy: 0.290658 | Label: .                | $KEEP [0.96, 10.50] -- $DELETE [0.01,  6.01] -- $REPLACE_! [0.01,  5.83]\n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m \u001b[32;1m2\u001b[0m  \n",
      "\u001b[37;1mRewards:\u001b[0m 0.000  \n",
      "\u001b[37;1mSource:\u001b[0m $START I think someone should get exercise by starting to play some favourite sport instead of watching To or playing games .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START I think someone should get exercise by starting to play some favourite sport instead of watching To or playing games .  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_dict = dict(\n",
    "    text = \"$START I think someone should get exercise by starting play some favourite sport instead of watching To or playing game .\",\n",
    "    references = [\n",
    "        \"$START I think people should get exercise by starting to play some favourite sport instead of watching To or playing games .\"\n",
    "    ]\n",
    ")\n",
    "state = env.reset(data_dict=data_dict)\n",
    "done = False\n",
    "while not done:\n",
    "    action = greedy_action(rl_model, state, env.labels, verbose=True)\n",
    "    next_state, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    state = next_state\n",
    "    outputs = env.render()\n",
    "    for o in outputs:\n",
    "        print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0234f1f0-8fec-4f87-bea8-c90e01b35182",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 0.188871 | Label: $START           | $KEEP [0.97, 13.55] -- $APPEND_But [0.01,  8.93] -- $APPEND_I [0.00,  8.05]\n",
      "Entropy: 0.424570 | Label: I                | $KEEP [0.93, 10.97] -- $DELETE [0.04,  7.90] -- $APPEND_am [0.01,  6.33]\n",
      "Entropy: 1.358291 | Label: 'm               | $REPLACE_am [0.47,  9.61] -- $DELETE [0.31,  9.19] -- $KEEP [0.13,  8.30]\n",
      "Entropy: 0.899895 | Label: planning         | $KEEP [0.85,  9.10] -- $DELETE [0.05,  6.30] -- $TRANSFORM_VERB_VBG_VB [0.03,  5.89]\n",
      "Entropy: 0.374026 | Label: to               | $KEEP [0.94, 10.36] -- $DELETE [0.03,  6.99] -- $REPLACE_on [0.00,  4.76]\n",
      "Entropy: 0.937385 | Label: improve          | $KEEP [0.82,  9.23] -- $TRANSFORM_VERB_VB_VBG [0.09,  7.06] -- $DELETE [0.04,  6.17]\n",
      "Entropy: 0.262185 | Label: my               | $KEEP [0.96, 10.66] -- $DELETE [0.02,  6.98] -- $REPLACE_my [0.00,  4.79]\n",
      "Entropy: 0.633877 | Label: English          | $KEEP [0.82, 10.48] -- $APPEND_, [0.15,  8.75] -- $DELETE [0.02,  6.75]\n",
      "Entropy: 0.283158 | Label: and              | $KEEP [0.96, 10.16] -- $DELETE [0.01,  5.61] -- $APPEND_, [0.00,  4.87]\n",
      "Entropy: 0.484123 | Label: I                | $KEEP [0.89, 10.62] -- $DELETE [0.09,  8.37] -- $REPLACE_I [0.00,  4.81]\n",
      "Entropy: 0.623794 | Label: have             | $KEEP [0.88,  9.82] -- $DELETE [0.07,  7.23] -- $APPEND_have [0.01,  5.40]\n",
      "Entropy: 0.509393 | Label: already          | $KEEP [0.91, 10.13] -- $DELETE [0.04,  6.97] -- $APPEND_been [0.02,  6.32]\n",
      "Entropy: 0.484875 | Label: registered       | $KEEP [0.94,  9.48] -- $DELETE [0.02,  5.58] -- $APPEND_him [0.00,  3.70]\n",
      "Entropy: 0.729348 | Label: for              | $KEEP [0.88,  9.51] -- $DELETE [0.04,  6.46] -- $REPLACE_to [0.03,  6.09]\n",
      "Entropy: 0.792324 | Label: a                | $KEEP [0.88, 10.32] -- $DELETE [0.03,  6.80] -- $REPLACE_the [0.02,  6.29]\n",
      "Entropy: 0.531902 | Label: course           | $KEEP [0.94,  9.79] -- $DELETE [0.01,  5.47] -- $APPEND_there [0.01,  4.92]\n",
      "Entropy: 0.190203 | Label: .                | $KEEP [0.97, 11.13] -- $APPEND_. [0.01,  6.11] -- $DELETE [0.01,  5.91]\n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 0  \n",
      "\u001b[37;1mRewards:\u001b[0m 0.000  \n",
      "\u001b[37;1mSource:\u001b[0m $START I 'm planning to improve my English and I have already registered for a course .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START I 'm planning to improve my English and I have already registered for a course .  \n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 1  \n",
      "\u001b[37;1mRewards:\u001b[0m 2.000  \n",
      "\u001b[37;1mSource:\u001b[0m $START I \u001b[32;1m'm\u001b[0m [\u001b[31;1m$REPLACE_am\u001b[0m] planning to improve my English and I have already registered for a course .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START I am planning to improve my English and I have already registered for a course .  \n",
      "\n",
      "Entropy: 0.126038 | Label: $START           | $KEEP [0.98, 13.85] -- $APPEND_But [0.01,  8.89] -- $APPEND_So [0.00,  7.81]\n",
      "Entropy: 0.214078 | Label: I                | $KEEP [0.97, 11.72] -- $DELETE [0.01,  7.10] -- $APPEND_also [0.01,  6.66]\n",
      "Entropy: 0.709668 | Label: am               | $KEEP [0.84,  9.80] -- $DELETE [0.11,  7.72] -- $APPEND_also [0.01,  5.72]\n",
      "Entropy: 0.746064 | Label: planning         | $KEEP [0.89,  9.41] -- $DELETE [0.04,  6.33] -- $APPEND_to [0.01,  5.14]\n",
      "Entropy: 0.368478 | Label: to               | $KEEP [0.95, 10.36] -- $DELETE [0.03,  6.88] -- $REPLACE_on [0.00,  4.60]\n",
      "Entropy: 0.996743 | Label: improve          | $KEEP [0.81,  9.22] -- $TRANSFORM_VERB_VB_VBG [0.10,  7.12] -- $DELETE [0.04,  6.24]\n",
      "Entropy: 0.302280 | Label: my               | $KEEP [0.95, 10.56] -- $DELETE [0.03,  6.98] -- $REPLACE_my [0.00,  4.94]\n",
      "Entropy: 0.675480 | Label: English          | $KEEP [0.81, 10.48] -- $APPEND_, [0.16,  8.86] -- $DELETE [0.02,  6.82]\n",
      "Entropy: 0.322170 | Label: and              | $KEEP [0.96, 10.05] -- $DELETE [0.01,  5.75] -- $APPEND_, [0.01,  4.96]\n",
      "Entropy: 0.521148 | Label: I                | $KEEP [0.87, 10.52] -- $DELETE [0.11,  8.41] -- $REPLACE_I [0.00,  4.86]\n",
      "Entropy: 0.599082 | Label: have             | $KEEP [0.89,  9.87] -- $DELETE [0.05,  7.08] -- $APPEND_have [0.01,  5.58]\n",
      "Entropy: 0.556061 | Label: already          | $KEEP [0.90, 10.07] -- $DELETE [0.04,  7.01] -- $APPEND_been [0.02,  6.47]\n",
      "Entropy: 0.535320 | Label: registered       | $KEEP [0.93,  9.47] -- $DELETE [0.02,  5.52] -- $APPEND_him [0.00,  4.00]\n",
      "Entropy: 0.759030 | Label: for              | $KEEP [0.87,  9.55] -- $DELETE [0.04,  6.49] -- $REPLACE_to [0.03,  6.06]\n",
      "Entropy: 0.924761 | Label: a                | $KEEP [0.86, 10.42] -- $DELETE [0.03,  6.93] -- $APPEND_new [0.02,  6.66]\n",
      "Entropy: 0.577390 | Label: course           | $KEEP [0.93,  9.86] -- $DELETE [0.01,  5.53] -- $APPEND_there [0.01,  5.07]\n",
      "Entropy: 0.210806 | Label: .                | $KEEP [0.97, 10.99] -- $APPEND_. [0.01,  5.95] -- $DELETE [0.01,  5.87]\n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m \u001b[32;1m2\u001b[0m  \n",
      "\u001b[37;1mRewards:\u001b[0m 0.000  \n",
      "\u001b[37;1mSource:\u001b[0m $START I am planning to improve my English and I have already registered for a course .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START I am planning to improve my English and I have already registered for a course .  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_dict = {\n",
    "    \"text\": \"I 'm planning to improve my English and I have already registered for a course .\",\n",
    "    \"references\": [\n",
    "        \"I am planning to improve my English and I have already registered on a course .\"\n",
    "    ]\n",
    "}\n",
    "state = env.reset(data_dict=data_dict)\n",
    "done = False\n",
    "while not done:\n",
    "    action = greedy_action(rl_model, state, env.labels, verbose=True)\n",
    "    next_state, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    state = next_state\n",
    "    outputs = env.render()\n",
    "    for o in outputs:\n",
    "        print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e81f68-b651-488e-b877-039b5682bbfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drl-gec",
   "language": "python",
   "name": "drl-gec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
