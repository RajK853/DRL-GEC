{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "469c966d-81b5-4cd6-935a-25d77e8a4868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2085486-38df-4b43-b092-f563f06c8ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rajk/Machine_Learning/DRL-GEC\n",
      "/home/rajk/Machine_Learning/DRL-GEC/notebooks\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "import src.envs\n",
    "from src.utils import load_text, decode\n",
    "from src.models.seq2labels import PretrainedEncoder, Seq2Labels\n",
    "%cd notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e197391-3820-41b9-910d-5809a74ab6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d75d2a72-c4bc-409f-8c26-287fcfccc531",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def greedy_action(policy, state, all_labels, verbose=True):\n",
    "    [logits] = policy([state])\n",
    "    top_logits, i = logits.topk(3)\n",
    "    top_logits = top_logits.cpu().numpy()\n",
    "    i = i.cpu().numpy()\n",
    "    dist = Categorical(logits=logits)\n",
    "    top_probs = dist.probs[torch.arange(len(state)).unsqueeze(1), i]\n",
    "    entropy = dist.entropy().cpu().numpy()\n",
    "    if verbose:\n",
    "        for a, e, label_logit_prob in zip(state, entropy, zip(all_labels[i], top_logits, top_probs)):\n",
    "            print(f\"Entropy: {e:4f} | Label: {a:15}  |\", \" -- \".join(f\"{lab} [{prob:3.2f}, {log:5.2f}]\" for (lab, log, prob) in zip(*label_logit_prob)))\n",
    "        print()\n",
    "    action = logits.argmax(axis=-1)\n",
    "    return action.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abb5a4c6-c668-4ef3-89d7-3c47b668bec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path, output_size):\n",
    "    model_name = \"roberta-base\"\n",
    "    encoder = PretrainedEncoder(model_name).to(device)\n",
    "    policy = Seq2Labels(encoder_model=encoder, num_labels=output_size).to(device)\n",
    "    policy.load_state_dict(torch.load(model_path))\n",
    "    policy.eval()\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e4dde0-c3f4-448b-82c0-56c5cfd76c06",
   "metadata": {},
   "source": [
    "# Load Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "359d9b7a-79b0-4ad0-9c64-47d85aee5b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of data in wi+locness: 24932\n",
      "Number of data without correct sentences: 24932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajk/miniconda3/envs/drl-gec/lib/python3.8/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/rajk/miniconda3/envs/drl-gec/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"wi_locness_gec-v0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65ea936-90e4-490b-b640-c42caf641a1d",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbb5f929-496e-4094-b422-8bc706d9831d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# rl_model_path = os.path.abspath(\"pg_logs/finetune_rl_22_10_2022_01:15/model-best.pt\")\n",
    "rl_model_path = os.path.abspath(\"pg_logs/finetune_rl_29_10_2022_11:41/model-last.pt\")\n",
    "sl_model_path = os.path.abspath(\"sl_logs/finetune_wi+locness_18:10:2022_21:42/model-best.pt\")\n",
    "rl_model = load_model(rl_model_path, output_size=len(env.labels))\n",
    "sl_model = load_model(sl_model_path, output_size=len(env.labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e90b34-f61b-454c-bbd4-aac2a0583fe3",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78177cae-217e-49fb-8ae4-bd375c24c8ae",
   "metadata": {},
   "source": [
    "# SL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09ab4c7e-5a4c-47ff-96cc-952eca185852",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 0.617051 | Label: $START           | $KEEP [0.91,  9.35] -- $APPEND_The [0.01,  5.02] -- $APPEND_But [0.01,  4.53]\n",
      "Entropy: 0.080073 | Label: he               | $TRANSFORM_CASE_CAPITAL [0.99, 12.58] -- $KEEP [0.01,  8.13] -- $REPLACE_He [0.00,  4.81]\n",
      "Entropy: 0.892204 | Label: said             | $APPEND_, [0.71,  8.61] -- $KEEP [0.23,  7.46] -- $APPEND_. [0.02,  4.96]\n",
      "Entropy: 1.111054 | Label: in               | $KEEP [0.62,  7.50] -- $TRANSFORM_CASE_CAPITAL [0.23,  6.50] -- $DELETE [0.12,  5.84]\n",
      "Entropy: 0.635756 | Label: other            | $KEEP [0.88,  7.89] -- $DELETE [0.09,  5.59] -- $TRANSFORM_CASE_CAPITAL [0.01,  2.96]\n",
      "Entropy: 1.050573 | Label: words            | $KEEP [0.74,  7.67] -- $APPEND_, [0.14,  6.00] -- $DELETE [0.05,  4.95]\n",
      "Entropy: 0.642304 | Label: that             | $KEEP [0.86,  8.26] -- $DELETE [0.07,  5.82] -- $APPEND_, [0.03,  5.06]\n",
      "Entropy: 1.241009 | Label: the              | $DELETE [0.47,  6.61] -- $KEEP [0.46,  6.58] -- $REPLACE_a [0.01,  2.16]\n",
      "Entropy: 0.674606 | Label: more             | $KEEP [0.89,  8.38] -- $REPLACE_more [0.04,  5.24] -- $DELETE [0.02,  4.41]\n",
      "Entropy: 0.801275 | Label: fluoride         | $KEEP [0.88,  8.38] -- $APPEND_, [0.04,  5.34] -- $APPEND_it [0.02,  4.60]\n",
      "Entropy: 1.021366 | Label: may              | $KEEP [0.80,  8.38] -- $REPLACE_might [0.08,  6.08] -- $REPLACE_could [0.02,  4.88]\n",
      "Entropy: 0.490360 | Label: create           | $KEEP [0.94,  8.70] -- $REPLACE_cause [0.01,  4.15] -- $TRANSFORM_VERB_VB_VBN [0.01,  3.94]\n",
      "Entropy: 0.282356 | Label: damage           | $KEEP [0.97,  9.31] -- $APPEND_to [0.01,  4.88] -- $TRANSFORM_VERB_VB_VBZ [0.00,  2.39]\n",
      "Entropy: 0.581908 | Label: in               | $APPEND_the [0.88, 10.35] -- $KEEP [0.05,  7.44] -- $REPLACE_to [0.04,  7.18]\n",
      "Entropy: 0.882855 | Label: human            | $KEEP [0.82,  7.88] -- $APPEND_'s [0.11,  5.84] -- $TRANSFORM_AGREEMENT_PLURAL [0.02,  4.20]\n",
      "Entropy: 0.555606 | Label: body             | $KEEP [0.92,  8.11] -- $TRANSFORM_VERB_VB_VBZ [0.03,  4.58] -- $TRANSFORM_AGREEMENT_PLURAL [0.01,  3.48]\n",
      "Entropy: 0.470411 | Label: ,                | $KEEP [0.93,  7.92] -- $APPEND_, [0.01,  3.78] -- $APPEND_and [0.01,  3.76]\n",
      "Entropy: 0.574635 | Label: specifically     | $KEEP [0.93,  7.90] -- $APPEND_in [0.01,  3.30] -- $APPEND_, [0.01,  3.24]\n",
      "Entropy: 0.443138 | Label: the              | $KEEP [0.91,  8.23] -- $DELETE [0.06,  5.58] -- $REPLACE_to [0.00,  2.63]\n",
      "Entropy: 1.302485 | Label: bone             | $KEEP [0.50,  7.68] -- $TRANSFORM_VERB_VB_VBZ [0.34,  7.29] -- $TRANSFORM_AGREEMENT_PLURAL [0.13,  6.32]\n",
      "Entropy: 0.163517 | Label: .                | $KEEP [0.98,  8.49] -- $APPEND_\" [0.01,  3.57] -- $DELETE [0.00,  2.62]\n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 0  \n",
      "\u001b[37;1mRewards:\u001b[0m 0.521  \n",
      "\u001b[37;1mSource:\u001b[0m $START \u001b[32;1mhe\u001b[0m [\u001b[31;1m$TRANSFORM_CASE_CAPITAL\u001b[0m] \u001b[32;1msaid\u001b[0m [\u001b[31;1m$APPEND_,\u001b[0m] in other words that \u001b[32;1mthe\u001b[0m [\u001b[31;1m$DELETE\u001b[0m] more fluoride may create damage \u001b[32;1min\u001b[0m [\u001b[31;1m$APPEND_the\u001b[0m] human body , specifically the bone .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START He said , in other words that more fluoride may create damage in the human body , specifically the bone .  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "state = \"$START he said in other words that the more fluoride may create damage in human body , specifically the bone .\".split()\n",
    "references = [\n",
    "    \"$START He said in other words that the more fluoride may create damage in the human body , specifically the bone .\".split(),\n",
    "    \"$START He said , in other words , that more fluoride may create damage in the human body , specifically the bone .\".split(),\n",
    "    \"$START He said , in other words , that more fluoride may create damage to the human body , specifically the bones .\".split(),\n",
    "    \"$START In other words , he said that more fluoride may damage the human body , specifically the bones .\".split()\n",
    "]\n",
    "for i in range(1):\n",
    "    action = greedy_action(sl_model, state, env.labels, verbose=True)\n",
    "    labels = env.labels[action]\n",
    "    new_state = decode(state, labels)\n",
    "    reward = env.compute_reward(state, new_state, references)\n",
    "    output = env.render_text(state, labels, reward, new_state, i)\n",
    "    state = new_state\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039e687c-e3cf-4ef2-987f-63898788dfe6",
   "metadata": {},
   "source": [
    "# RL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9c189a0-5eed-4b6a-af18-a43437147161",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 1.412778 | Label: $START           | $KEEP [0.76,  9.87] -- $APPEND_But [0.04,  6.80] -- $APPEND_That [0.02,  6.18]\n",
      "Entropy: 1.558759 | Label: he               | $TRANSFORM_CASE_CAPITAL [0.64, 11.63] -- $DELETE [0.09,  9.67] -- $REPLACE_It [0.08,  9.60]\n",
      "Entropy: 1.582957 | Label: said             | $KEEP [0.54,  9.86] -- $APPEND_, [0.20,  8.89] -- $DELETE [0.09,  8.07]\n",
      "Entropy: 1.889009 | Label: in               | $KEEP [0.38,  9.15] -- $REPLACE_In [0.19,  8.44] -- $DELETE [0.17,  8.34]\n",
      "Entropy: 0.918801 | Label: other            | $KEEP [0.82,  9.18] -- $DELETE [0.11,  7.15] -- $REPLACE_in [0.02,  5.35]\n",
      "Entropy: 1.079268 | Label: words            | $KEEP [0.76,  9.22] -- $APPEND_, [0.12,  7.36] -- $DELETE [0.06,  6.74]\n",
      "Entropy: 0.628331 | Label: that             | $KEEP [0.87, 10.59] -- $DELETE [0.10,  8.40] -- $APPEND_, [0.01,  6.45]\n",
      "Entropy: 2.106235 | Label: the              | $DELETE [0.59,  8.52] -- $KEEP [0.24,  7.64] -- $APPEND_. [0.01,  3.88]\n",
      "Entropy: 0.945120 | Label: more             | $KEEP [0.79,  9.83] -- $DELETE [0.13,  7.99] -- $REPLACE_more [0.02,  6.21]\n",
      "Entropy: 1.174733 | Label: fluoride         | $KEEP [0.71,  9.98] -- $APPEND_it [0.18,  8.62] -- $REPLACE_it [0.03,  6.78]\n",
      "Entropy: 0.937438 | Label: may              | $KEEP [0.88,  9.98] -- $REPLACE_might [0.02,  6.17] -- $REPLACE_could [0.02,  6.17]\n",
      "Entropy: 1.545629 | Label: create           | $KEEP [0.76,  9.54] -- $REPLACE_cause [0.08,  7.27] -- $DELETE [0.04,  6.55]\n",
      "Entropy: 0.897660 | Label: damage           | $KEEP [0.53, 10.46] -- $APPEND_to [0.45, 10.29] -- $REPLACE_to [0.01,  6.01]\n",
      "Entropy: 1.430497 | Label: in               | $APPEND_the [0.47, 10.15] -- $REPLACE_to [0.30,  9.72] -- $KEEP [0.15,  9.00]\n",
      "Entropy: 1.077113 | Label: human            | $KEEP [0.79,  8.86] -- $APPEND_'s [0.08,  6.62] -- $DELETE [0.03,  5.44]\n",
      "Entropy: 0.900002 | Label: body             | $KEEP [0.85,  9.24] -- $APPEND_and [0.05,  6.38] -- $APPEND_, [0.03,  5.83]\n",
      "Entropy: 0.784612 | Label: ,                | $KEEP [0.84, 10.11] -- $APPEND_and [0.06,  7.53] -- $APPEND_in [0.03,  6.83]\n",
      "Entropy: 0.627977 | Label: specifically     | $KEEP [0.88, 10.31] -- $APPEND_in [0.05,  7.37] -- $APPEND_to [0.02,  6.68]\n",
      "Entropy: 0.609918 | Label: the              | $KEEP [0.89, 10.04] -- $DELETE [0.04,  6.90] -- $REPLACE_to [0.04,  6.90]\n",
      "Entropy: 1.290496 | Label: bone             | $KEEP [0.65,  8.79] -- $TRANSFORM_AGREEMENT_PLURAL [0.20,  7.63] -- $TRANSFORM_VERB_VB_VBZ [0.09,  6.76]\n",
      "Entropy: 0.324979 | Label: .                | $KEEP [0.94, 10.85] -- $APPEND_\" [0.05,  7.85] -- $APPEND_. [0.00,  4.92]\n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 0  \n",
      "\u001b[37;1mRewards:\u001b[0m 0.460  \n",
      "\u001b[37;1mSource:\u001b[0m $START \u001b[32;1mhe\u001b[0m [\u001b[31;1m$TRANSFORM_CASE_CAPITAL\u001b[0m] said in other words that \u001b[32;1mthe\u001b[0m [\u001b[31;1m$DELETE\u001b[0m] more fluoride may create damage \u001b[32;1min\u001b[0m [\u001b[31;1m$APPEND_the\u001b[0m] human body , specifically the bone .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START He said in other words that more fluoride may create damage in the human body , specifically the bone .  \n",
      "\n",
      "Entropy: 0.580027 | Label: $START           | $KEEP [0.92, 10.13] -- $APPEND_But [0.01,  5.68] -- $APPEND_In [0.01,  5.42]\n",
      "Entropy: 0.725575 | Label: He               | $KEEP [0.88, 10.16] -- $REPLACE_He [0.04,  6.95] -- $APPEND_, [0.02,  6.33]\n",
      "Entropy: 1.059183 | Label: said             | $APPEND_, [0.52, 10.36] -- $KEEP [0.41, 10.13] -- $REPLACE_, [0.03,  7.49]\n",
      "Entropy: 1.644688 | Label: in               | $KEEP [0.56,  8.82] -- $DELETE [0.14,  7.44] -- $REPLACE_in [0.11,  7.18]\n",
      "Entropy: 1.037266 | Label: other            | $KEEP [0.80,  9.06] -- $DELETE [0.11,  7.12] -- $REPLACE_in [0.02,  5.38]\n",
      "Entropy: 1.497185 | Label: words            | $KEEP [0.69,  8.89] -- $APPEND_, [0.13,  7.20] -- $DELETE [0.08,  6.79]\n",
      "Entropy: 0.333521 | Label: that             | $KEEP [0.95, 10.65] -- $DELETE [0.02,  6.87] -- $APPEND_, [0.01,  6.32]\n",
      "Entropy: 0.818193 | Label: more             | $KEEP [0.86,  9.86] -- $DELETE [0.06,  7.12] -- $APPEND_of [0.03,  6.56]\n",
      "Entropy: 1.769623 | Label: fluoride         | $KEEP [0.80,  9.80] -- $TRANSFORM_AGREEMENT_PLURAL [0.04,  6.76] -- $REPLACE_waste [0.01,  5.60]\n",
      "Entropy: 0.922809 | Label: may              | $KEEP [0.84, 10.15] -- $REPLACE_might [0.06,  7.43] -- $REPLACE_could [0.04,  7.06]\n",
      "Entropy: 1.546782 | Label: create           | $KEEP [0.60,  9.73] -- $REPLACE_cause [0.27,  8.95] -- $DELETE [0.03,  6.61]\n",
      "Entropy: 0.806368 | Label: damage           | $KEEP [0.76, 10.41] -- $APPEND_to [0.21,  9.10] -- $REPLACE_to [0.00,  5.28]\n",
      "Entropy: 1.004618 | Label: in               | $REPLACE_to [0.68, 10.60] -- $KEEP [0.25,  9.59] -- $DELETE [0.03,  7.33]\n",
      "Entropy: 0.970541 | Label: the              | $KEEP [0.78,  9.47] -- $REPLACE_to [0.10,  7.42] -- $DELETE [0.06,  6.99]\n",
      "Entropy: 0.674571 | Label: human            | $KEEP [0.89,  9.31] -- $DELETE [0.04,  6.22] -- $APPEND_'s [0.03,  5.91]\n",
      "Entropy: 0.671574 | Label: body             | $KEEP [0.89,  9.53] -- $APPEND_, [0.04,  6.41] -- $APPEND_and [0.03,  6.09]\n",
      "Entropy: 0.820859 | Label: ,                | $KEEP [0.82, 10.16] -- $APPEND_and [0.07,  7.69] -- $APPEND_, [0.04,  7.18]\n",
      "Entropy: 0.684934 | Label: specifically     | $KEEP [0.87, 10.19] -- $APPEND_in [0.07,  7.62] -- $APPEND_, [0.02,  6.27]\n",
      "Entropy: 0.674797 | Label: the              | $KEEP [0.88,  9.86] -- $REPLACE_to [0.04,  6.78] -- $DELETE [0.04,  6.70]\n",
      "Entropy: 1.517989 | Label: bone             | $KEEP [0.48,  8.63] -- $TRANSFORM_AGREEMENT_PLURAL [0.32,  8.22] -- $TRANSFORM_VERB_VB_VBZ [0.14,  7.42]\n",
      "Entropy: 0.236988 | Label: .                | $KEEP [0.96, 10.52] -- $APPEND_\" [0.03,  7.00] -- $APPEND_. [0.00,  4.58]\n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 1  \n",
      "\u001b[37;1mRewards:\u001b[0m 0.365  \n",
      "\u001b[37;1mSource:\u001b[0m $START He \u001b[32;1msaid\u001b[0m [\u001b[31;1m$APPEND_,\u001b[0m] in other words that more fluoride may create damage \u001b[32;1min\u001b[0m [\u001b[31;1m$REPLACE_to\u001b[0m] the human body , specifically the bone .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START He said , in other words that more fluoride may create damage to the human body , specifically the bone .  \n",
      "\n",
      "Entropy: 0.761446 | Label: $START           | $KEEP [0.89, 10.01] -- $APPEND_In [0.01,  5.86] -- $APPEND_But [0.01,  5.65]\n",
      "Entropy: 0.658043 | Label: He               | $KEEP [0.90, 10.31] -- $REPLACE_He [0.02,  6.68] -- $APPEND_, [0.01,  6.04]\n",
      "Entropy: 0.774604 | Label: said             | $KEEP [0.86, 10.07] -- $APPEND_\" [0.04,  6.96] -- $DELETE [0.02,  6.38]\n",
      "Entropy: 1.377145 | Label: ,                | $KEEP [0.65,  9.08] -- $DELETE [0.22,  8.00] -- $APPEND_, [0.02,  5.75]\n",
      "Entropy: 1.934455 | Label: in               | $KEEP [0.38,  9.00] -- $DELETE [0.22,  8.45] -- $REPLACE_In [0.15,  8.09]\n",
      "Entropy: 1.161579 | Label: other            | $KEEP [0.81,  9.32] -- $DELETE [0.10,  7.24] -- $REPLACE_in [0.01,  4.83]\n",
      "Entropy: 1.124141 | Label: words            | $KEEP [0.59,  9.68] -- $APPEND_, [0.34,  9.12] -- $DELETE [0.03,  6.53]\n",
      "Entropy: 0.809302 | Label: that             | $KEEP [0.82, 10.44] -- $APPEND_, [0.10,  8.34] -- $REPLACE_, [0.03,  7.12]\n",
      "Entropy: 0.810275 | Label: more             | $KEEP [0.87,  9.73] -- $DELETE [0.04,  6.70] -- $APPEND_of [0.03,  6.47]\n",
      "Entropy: 1.749600 | Label: fluoride         | $KEEP [0.78,  9.78] -- $TRANSFORM_AGREEMENT_PLURAL [0.03,  6.65] -- $APPEND_, [0.03,  6.44]\n",
      "Entropy: 0.964748 | Label: may              | $KEEP [0.85, 10.07] -- $REPLACE_might [0.04,  7.09] -- $REPLACE_could [0.03,  6.86]\n",
      "Entropy: 1.609501 | Label: create           | $KEEP [0.63,  9.49] -- $REPLACE_cause [0.22,  8.44] -- $DELETE [0.03,  6.42]\n",
      "Entropy: 0.462907 | Label: damage           | $KEEP [0.93, 10.57] -- $APPEND_to [0.05,  7.64] -- $DELETE [0.00,  5.31]\n",
      "Entropy: 0.664694 | Label: to               | $KEEP [0.85, 10.89] -- $REPLACE_to [0.08,  8.53] -- $DELETE [0.03,  7.54]\n",
      "Entropy: 0.716105 | Label: the              | $KEEP [0.86,  9.63] -- $DELETE [0.08,  7.25] -- $REPLACE_to [0.02,  5.98]\n",
      "Entropy: 0.605774 | Label: human            | $KEEP [0.90,  9.48] -- $DELETE [0.04,  6.33] -- $APPEND_'s [0.02,  5.89]\n",
      "Entropy: 0.663050 | Label: body             | $KEEP [0.89,  9.57] -- $APPEND_, [0.04,  6.40] -- $APPEND_and [0.03,  6.11]\n",
      "Entropy: 0.812268 | Label: ,                | $KEEP [0.82, 10.16] -- $APPEND_and [0.10,  8.02] -- $APPEND_, [0.04,  7.15]\n",
      "Entropy: 0.487154 | Label: specifically     | $KEEP [0.92, 10.04] -- $APPEND_, [0.03,  6.61] -- $APPEND_and [0.01,  5.70]\n",
      "Entropy: 0.553899 | Label: the              | $KEEP [0.90,  9.96] -- $DELETE [0.06,  7.19] -- $REPLACE_to [0.01,  5.55]\n",
      "Entropy: 1.539186 | Label: bone             | $KEEP [0.53,  8.69] -- $TRANSFORM_AGREEMENT_PLURAL [0.30,  8.12] -- $TRANSFORM_VERB_VB_VBZ [0.11,  7.09]\n",
      "Entropy: 0.259031 | Label: .                | $KEEP [0.95, 10.74] -- $APPEND_\" [0.03,  7.42] -- $APPEND_. [0.00,  4.89]\n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 2  \n",
      "\u001b[37;1mRewards:\u001b[0m -0.100  \n",
      "\u001b[37;1mSource:\u001b[0m $START He said , in other words that more fluoride may create damage to the human body , specifically the bone .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START He said , in other words that more fluoride may create damage to the human body , specifically the bone .  \n",
      "\n",
      "Entropy: 0.761446 | Label: $START           | $KEEP [0.89, 10.01] -- $APPEND_In [0.01,  5.86] -- $APPEND_But [0.01,  5.65]\n",
      "Entropy: 0.658043 | Label: He               | $KEEP [0.90, 10.31] -- $REPLACE_He [0.02,  6.68] -- $APPEND_, [0.01,  6.04]\n",
      "Entropy: 0.774604 | Label: said             | $KEEP [0.86, 10.07] -- $APPEND_\" [0.04,  6.96] -- $DELETE [0.02,  6.38]\n",
      "Entropy: 1.377145 | Label: ,                | $KEEP [0.65,  9.08] -- $DELETE [0.22,  8.00] -- $APPEND_, [0.02,  5.75]\n",
      "Entropy: 1.934455 | Label: in               | $KEEP [0.38,  9.00] -- $DELETE [0.22,  8.45] -- $REPLACE_In [0.15,  8.09]\n",
      "Entropy: 1.161579 | Label: other            | $KEEP [0.81,  9.32] -- $DELETE [0.10,  7.24] -- $REPLACE_in [0.01,  4.83]\n",
      "Entropy: 1.124141 | Label: words            | $KEEP [0.59,  9.68] -- $APPEND_, [0.34,  9.12] -- $DELETE [0.03,  6.53]\n",
      "Entropy: 0.809302 | Label: that             | $KEEP [0.82, 10.44] -- $APPEND_, [0.10,  8.34] -- $REPLACE_, [0.03,  7.12]\n",
      "Entropy: 0.810275 | Label: more             | $KEEP [0.87,  9.73] -- $DELETE [0.04,  6.70] -- $APPEND_of [0.03,  6.47]\n",
      "Entropy: 1.749600 | Label: fluoride         | $KEEP [0.78,  9.78] -- $TRANSFORM_AGREEMENT_PLURAL [0.03,  6.65] -- $APPEND_, [0.03,  6.44]\n",
      "Entropy: 0.964748 | Label: may              | $KEEP [0.85, 10.07] -- $REPLACE_might [0.04,  7.09] -- $REPLACE_could [0.03,  6.86]\n",
      "Entropy: 1.609501 | Label: create           | $KEEP [0.63,  9.49] -- $REPLACE_cause [0.22,  8.44] -- $DELETE [0.03,  6.42]\n",
      "Entropy: 0.462907 | Label: damage           | $KEEP [0.93, 10.57] -- $APPEND_to [0.05,  7.64] -- $DELETE [0.00,  5.31]\n",
      "Entropy: 0.664694 | Label: to               | $KEEP [0.85, 10.89] -- $REPLACE_to [0.08,  8.53] -- $DELETE [0.03,  7.54]\n",
      "Entropy: 0.716105 | Label: the              | $KEEP [0.86,  9.63] -- $DELETE [0.08,  7.25] -- $REPLACE_to [0.02,  5.98]\n",
      "Entropy: 0.605774 | Label: human            | $KEEP [0.90,  9.48] -- $DELETE [0.04,  6.33] -- $APPEND_'s [0.02,  5.89]\n",
      "Entropy: 0.663050 | Label: body             | $KEEP [0.89,  9.57] -- $APPEND_, [0.04,  6.40] -- $APPEND_and [0.03,  6.11]\n",
      "Entropy: 0.812268 | Label: ,                | $KEEP [0.82, 10.16] -- $APPEND_and [0.10,  8.02] -- $APPEND_, [0.04,  7.15]\n",
      "Entropy: 0.487154 | Label: specifically     | $KEEP [0.92, 10.04] -- $APPEND_, [0.03,  6.61] -- $APPEND_and [0.01,  5.70]\n",
      "Entropy: 0.553899 | Label: the              | $KEEP [0.90,  9.96] -- $DELETE [0.06,  7.19] -- $REPLACE_to [0.01,  5.55]\n",
      "Entropy: 1.539186 | Label: bone             | $KEEP [0.53,  8.69] -- $TRANSFORM_AGREEMENT_PLURAL [0.30,  8.12] -- $TRANSFORM_VERB_VB_VBZ [0.11,  7.09]\n",
      "Entropy: 0.259031 | Label: .                | $KEEP [0.95, 10.74] -- $APPEND_\" [0.03,  7.42] -- $APPEND_. [0.00,  4.89]\n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 3  \n",
      "\u001b[37;1mRewards:\u001b[0m -0.100  \n",
      "\u001b[37;1mSource:\u001b[0m $START He said , in other words that more fluoride may create damage to the human body , specifically the bone .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START He said , in other words that more fluoride may create damage to the human body , specifically the bone .  \n",
      "\n",
      "Entropy: 0.761446 | Label: $START           | $KEEP [0.89, 10.01] -- $APPEND_In [0.01,  5.86] -- $APPEND_But [0.01,  5.65]\n",
      "Entropy: 0.658043 | Label: He               | $KEEP [0.90, 10.31] -- $REPLACE_He [0.02,  6.68] -- $APPEND_, [0.01,  6.04]\n",
      "Entropy: 0.774604 | Label: said             | $KEEP [0.86, 10.07] -- $APPEND_\" [0.04,  6.96] -- $DELETE [0.02,  6.38]\n",
      "Entropy: 1.377145 | Label: ,                | $KEEP [0.65,  9.08] -- $DELETE [0.22,  8.00] -- $APPEND_, [0.02,  5.75]\n",
      "Entropy: 1.934455 | Label: in               | $KEEP [0.38,  9.00] -- $DELETE [0.22,  8.45] -- $REPLACE_In [0.15,  8.09]\n",
      "Entropy: 1.161579 | Label: other            | $KEEP [0.81,  9.32] -- $DELETE [0.10,  7.24] -- $REPLACE_in [0.01,  4.83]\n",
      "Entropy: 1.124141 | Label: words            | $KEEP [0.59,  9.68] -- $APPEND_, [0.34,  9.12] -- $DELETE [0.03,  6.53]\n",
      "Entropy: 0.809302 | Label: that             | $KEEP [0.82, 10.44] -- $APPEND_, [0.10,  8.34] -- $REPLACE_, [0.03,  7.12]\n",
      "Entropy: 0.810275 | Label: more             | $KEEP [0.87,  9.73] -- $DELETE [0.04,  6.70] -- $APPEND_of [0.03,  6.47]\n",
      "Entropy: 1.749600 | Label: fluoride         | $KEEP [0.78,  9.78] -- $TRANSFORM_AGREEMENT_PLURAL [0.03,  6.65] -- $APPEND_, [0.03,  6.44]\n",
      "Entropy: 0.964748 | Label: may              | $KEEP [0.85, 10.07] -- $REPLACE_might [0.04,  7.09] -- $REPLACE_could [0.03,  6.86]\n",
      "Entropy: 1.609501 | Label: create           | $KEEP [0.63,  9.49] -- $REPLACE_cause [0.22,  8.44] -- $DELETE [0.03,  6.42]\n",
      "Entropy: 0.462907 | Label: damage           | $KEEP [0.93, 10.57] -- $APPEND_to [0.05,  7.64] -- $DELETE [0.00,  5.31]\n",
      "Entropy: 0.664694 | Label: to               | $KEEP [0.85, 10.89] -- $REPLACE_to [0.08,  8.53] -- $DELETE [0.03,  7.54]\n",
      "Entropy: 0.716105 | Label: the              | $KEEP [0.86,  9.63] -- $DELETE [0.08,  7.25] -- $REPLACE_to [0.02,  5.98]\n",
      "Entropy: 0.605774 | Label: human            | $KEEP [0.90,  9.48] -- $DELETE [0.04,  6.33] -- $APPEND_'s [0.02,  5.89]\n",
      "Entropy: 0.663050 | Label: body             | $KEEP [0.89,  9.57] -- $APPEND_, [0.04,  6.40] -- $APPEND_and [0.03,  6.11]\n",
      "Entropy: 0.812268 | Label: ,                | $KEEP [0.82, 10.16] -- $APPEND_and [0.10,  8.02] -- $APPEND_, [0.04,  7.15]\n",
      "Entropy: 0.487154 | Label: specifically     | $KEEP [0.92, 10.04] -- $APPEND_, [0.03,  6.61] -- $APPEND_and [0.01,  5.70]\n",
      "Entropy: 0.553899 | Label: the              | $KEEP [0.90,  9.96] -- $DELETE [0.06,  7.19] -- $REPLACE_to [0.01,  5.55]\n",
      "Entropy: 1.539186 | Label: bone             | $KEEP [0.53,  8.69] -- $TRANSFORM_AGREEMENT_PLURAL [0.30,  8.12] -- $TRANSFORM_VERB_VB_VBZ [0.11,  7.09]\n",
      "Entropy: 0.259031 | Label: .                | $KEEP [0.95, 10.74] -- $APPEND_\" [0.03,  7.42] -- $APPEND_. [0.00,  4.89]\n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 4  \n",
      "\u001b[37;1mRewards:\u001b[0m -0.100  \n",
      "\u001b[37;1mSource:\u001b[0m $START He said , in other words that more fluoride may create damage to the human body , specifically the bone .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START He said , in other words that more fluoride may create damage to the human body , specifically the bone .  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "state = \"$START he said in other words that the more fluoride may create damage in human body , specifically the bone .\".split()\n",
    "references = [\n",
    "    \"$START He said in other words that the more fluoride may create damage in the human body , specifically the bone .\".split(),\n",
    "    \"$START He said , in other words , that more fluoride may create damage in the human body , specifically the bone .\".split(),\n",
    "    \"$START He said , in other words , that more fluoride may create damage to the human body , specifically the bones .\".split(),\n",
    "    \"$START In other words , he said that more fluoride may damage the human body , specifically the bones .\".split()\n",
    "]\n",
    "for i in range(5):\n",
    "    action = greedy_action(rl_model, state, env.labels, verbose=True)\n",
    "    labels = env.labels[action]\n",
    "    new_state = decode(state, labels)\n",
    "    reward = env.compute_reward(state, new_state, references)\n",
    "    output = env.render_text(state, labels, reward, new_state, i)\n",
    "    state = new_state\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d652a6e9-f220-4a43-9d0f-8654aa955b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chararray(['$KEEP', '$KEEP', '$KEEP', '$KEEP', '$KEEP', '$KEEP', '$KEEP',\n",
       "           '$KEEP', '$KEEP', '$KEEP', '$KEEP', '$KEEP', '$KEEP', '$KEEP',\n",
       "           '$KEEP', '$KEEP', '$KEEP', '$KEEP', '$KEEP', '$KEEP', '$KEEP',\n",
       "           '$KEEP'], dtype='<U29')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = env.labels[action]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16f31d5e-1fc5-4792-b61e-2bcb3e3046bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(labels == \"$KEEP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39a596d1-45be-4c6e-b653-d081fe0de809",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37;1mTimestep:\u001b[0m 0  \n",
      "\u001b[37;1mRewards:\u001b[0m 0.348  \n",
      "\u001b[37;1mSource:\u001b[0m $START Tigers \u001b[32;1mis\u001b[0m [\u001b[31;1m$REPLACE_are\u001b[0m] cold blooded animals .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START Tigers are cold blooded animals .  \n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 1  \n",
      "\u001b[37;1mRewards:\u001b[0m -0.007  \n",
      "\u001b[37;1mSource:\u001b[0m $START Tigers are \u001b[32;1mcold\u001b[0m [\u001b[31;1m$APPEND_-\u001b[0m] blooded animals .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START Tigers are cold - blooded animals .  \n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 2  \n",
      "\u001b[37;1mRewards:\u001b[0m -0.100  \n",
      "\u001b[37;1mSource:\u001b[0m $START Tigers are cold - blooded animals .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START Tigers are cold - blooded animals .  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "state = \"$START Tigers is cold blooded animals .\".split()\n",
    "references = [\n",
    "    \"$START Tigers are cold-blooded animals .\".split(),\n",
    "    \"$START Tigers is a cold-blooded animal .\".split(),\n",
    "]\n",
    "for i in range(3):\n",
    "    action = greedy_action(sl_model, state, env.labels, verbose=False)\n",
    "    labels = env.labels[action]\n",
    "    new_state = decode(state, labels)\n",
    "    reward = env.compute_reward(state, new_state, references)\n",
    "    output = env.render_text(state, labels, reward, new_state, i)\n",
    "    state = new_state\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24090f68-fb9f-4a19-a951-83d704e87e89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37;1mTimestep:\u001b[0m 0  \n",
      "\u001b[37;1mRewards:\u001b[0m 0.139  \n",
      "\u001b[37;1mSource:\u001b[0m $START Tigers \u001b[32;1mis\u001b[0m [\u001b[31;1m$REPLACE_are\u001b[0m] \u001b[32;1mcold\u001b[0m [\u001b[31;1m$APPEND_-\u001b[0m] blooded animals .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START Tigers are cold - blooded animals .  \n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 1  \n",
      "\u001b[37;1mRewards:\u001b[0m -0.100  \n",
      "\u001b[37;1mSource:\u001b[0m $START Tigers are cold - blooded animals .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START Tigers are cold - blooded animals .  \n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 2  \n",
      "\u001b[37;1mRewards:\u001b[0m -0.100  \n",
      "\u001b[37;1mSource:\u001b[0m $START Tigers are cold - blooded animals .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START Tigers are cold - blooded animals .  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "state = \"$START Tigers is cold blooded animals .\".split()\n",
    "references = [\n",
    "    \"$START Tigers are cold-blooded animals .\".split(),\n",
    "    \"$START Tigers is a cold-blooded animal .\".split(),\n",
    "]\n",
    "for i in range(3):\n",
    "    action = greedy_action(rl_model, state, env.labels, verbose=False)\n",
    "    labels = env.labels[action]\n",
    "    new_state = decode(state, labels)\n",
    "    reward = env.compute_reward(state, new_state, references)\n",
    "    output = env.render_text(state, labels, reward, new_state, i)\n",
    "    state = new_state\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab85280-e067-4699-b794-4f1f4f9e11a9",
   "metadata": {},
   "source": [
    "# Model scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cd11584-68d0-41ac-a14f-9bfdcc7b399a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b5740_row1_col2, #T_b5740_row1_col3, #T_b5740_row2_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b5740\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b5740_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_b5740_level0_col1\" class=\"col_heading level0 col1\" >Precision</th>\n",
       "      <th id=\"T_b5740_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_b5740_level0_col3\" class=\"col_heading level0 col3\" >F-0.5 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b5740_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b5740_row0_col0\" class=\"data row0 col0\" >Pretrain</td>\n",
       "      <td id=\"T_b5740_row0_col1\" class=\"data row0 col1\" >0.6074</td>\n",
       "      <td id=\"T_b5740_row0_col2\" class=\"data row0 col2\" >0.2958</td>\n",
       "      <td id=\"T_b5740_row0_col3\" class=\"data row0 col3\" >0.5017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5740_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b5740_row1_col0\" class=\"data row1 col0\" >Pretrain + SL Fine-Tune</td>\n",
       "      <td id=\"T_b5740_row1_col1\" class=\"data row1 col1\" >0.6561</td>\n",
       "      <td id=\"T_b5740_row1_col2\" class=\"data row1 col2\" >0.4372</td>\n",
       "      <td id=\"T_b5740_row1_col3\" class=\"data row1 col3\" >0.5964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5740_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b5740_row2_col0\" class=\"data row2 col0\" >Pretrain + RL Fine-Tune</td>\n",
       "      <td id=\"T_b5740_row2_col1\" class=\"data row2 col1\" >0.6890</td>\n",
       "      <td id=\"T_b5740_row2_col2\" class=\"data row2 col2\" >0.3784</td>\n",
       "      <td id=\"T_b5740_row2_col3\" class=\"data row2 col3\" >0.5918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5740_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_b5740_row3_col0\" class=\"data row3 col0\" >Pretrain + SL Fine-Tune + RL Fine-Tune</td>\n",
       "      <td id=\"T_b5740_row3_col1\" class=\"data row3 col1\" >0.6842</td>\n",
       "      <td id=\"T_b5740_row3_col2\" class=\"data row3 col2\" >0.3593</td>\n",
       "      <td id=\"T_b5740_row3_col3\" class=\"data row3 col3\" >0.5794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f2676798310>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict = {\n",
    "    \"Pretrain\": os.path.abspath(\"sl_logs/pretrain_synthetic_18:10:2022_13:59/\"),\n",
    "    \"Pretrain + SL Fine-Tune\": os.path.abspath(\"sl_logs/finetune_wi+locness_18:10:2022_21:42\"),\n",
    "    \"Pretrain + RL Fine-Tune\": os.path.abspath(\"pg_logs/finetune_rl_22_10_2022_01:15\"),\n",
    "    \"Pretrain + SL Fine-Tune + RL Fine-Tune\": os.path.abspath(\"pg_logs/finetune_rl_23_10_2022_00:33\"),\n",
    "}\n",
    "\n",
    "results = []\n",
    "for model_name, model_path in model_dict.items():\n",
    "    dataset_path = os.path.join(model_path, \"conll\", \"conll_test.score\")\n",
    "    data = load_text(dataset_path)\n",
    "    p, r, f = (line.split(\": \")[1] for line in data[-3:])\n",
    "    results.append({\"Model\": model_name, \"Precision\": p, \"Recall\": r, \"F-0.5 Score\": f})\n",
    "conll_df = pd.DataFrame(results)\n",
    "conll_df.style.highlight_max(subset=[\"Precision\", \"Recall\", \"F-0.5 Score\"], color='lightgreen', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acc9ef84-308c-4774-bbfe-0be4d505b397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_21c96_row1_col1, #T_21c96_row1_col2 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_21c96\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_21c96_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_21c96_level0_col1\" class=\"col_heading level0 col1\" >Dev Score</th>\n",
       "      <th id=\"T_21c96_level0_col2\" class=\"col_heading level0 col2\" >Test Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_21c96_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_21c96_row0_col0\" class=\"data row0 col0\" >Pretrain</td>\n",
       "      <td id=\"T_21c96_row0_col1\" class=\"data row0 col1\" >0.511410</td>\n",
       "      <td id=\"T_21c96_row0_col2\" class=\"data row0 col2\" >0.538118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_21c96_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_21c96_row1_col0\" class=\"data row1 col0\" >Pretrain + SL Fine-Tune</td>\n",
       "      <td id=\"T_21c96_row1_col1\" class=\"data row1 col1\" >0.543455</td>\n",
       "      <td id=\"T_21c96_row1_col2\" class=\"data row1 col2\" >0.590690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_21c96_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_21c96_row2_col0\" class=\"data row2 col0\" >Pretrain + RL Fine-Tune</td>\n",
       "      <td id=\"T_21c96_row2_col1\" class=\"data row2 col1\" >0.532699</td>\n",
       "      <td id=\"T_21c96_row2_col2\" class=\"data row2 col2\" >0.576475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_21c96_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_21c96_row3_col0\" class=\"data row3 col0\" >Pretrain + SL Fine-Tune + RL Fine-Tune</td>\n",
       "      <td id=\"T_21c96_row3_col1\" class=\"data row3 col1\" >0.528306</td>\n",
       "      <td id=\"T_21c96_row3_col2\" class=\"data row3 col2\" >0.575681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f277056ab80>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict = {\n",
    "    \"Pretrain\": os.path.abspath(\"sl_logs/pretrain_synthetic_18:10:2022_13:59/\"),\n",
    "    \"Pretrain + SL Fine-Tune\": os.path.abspath(\"sl_logs/finetune_wi+locness_18:10:2022_21:42\"),\n",
    "    \"Pretrain + RL Fine-Tune\": os.path.abspath(\"pg_logs/finetune_rl_22_10_2022_01:15\"),\n",
    "    \"Pretrain + SL Fine-Tune + RL Fine-Tune\": os.path.abspath(\"pg_logs/finetune_rl_23_10_2022_00:33\"),\n",
    "}\n",
    "\n",
    "results = []\n",
    "for model_name, model_path in model_dict.items():\n",
    "    model_dict = {\"Model\": model_name}\n",
    "    for score_type in (\"dev\", \"test\"):\n",
    "        dataset_path = os.path.join(model_path, \"jfleg\", f\"jfleg_{score_type}.score\")\n",
    "        data = load_text(dataset_path)\n",
    "        score_list = eval(data[-1])\n",
    "        model_dict[f\"{score_type.title()} Score\"] = score_list[0][0]\n",
    "    results.append(model_dict)\n",
    "jfleg_df = pd.DataFrame(results)\n",
    "jfleg_df.style.highlight_max(subset=[\"Dev Score\", \"Test Score\"], color='lightgreen', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b78ffb-84af-4df2-8fe6-bc9b594bb89a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drl-gec",
   "language": "python",
   "name": "drl-gec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
