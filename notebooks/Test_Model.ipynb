{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "469c966d-81b5-4cd6-935a-25d77e8a4868",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2085486-38df-4b43-b092-f563f06c8ac9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rajk/Machine_Learning/DRL-GEC\n",
      "/home/rajk/Machine_Learning/DRL-GEC/notebooks\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "import src.envs\n",
    "from src.utils import load_text, apply_labels\n",
    "from src.models.seq2labels import PretrainedEncoder, Seq2Labels\n",
    "%cd notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e197391-3820-41b9-910d-5809a74ab6ef",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d75d2a72-c4bc-409f-8c26-287fcfccc531",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def greedy_action(policy, state, all_labels, verbose=True):\n",
    "    [logits] = policy([state])\n",
    "    top_logits, i = logits.topk(3)\n",
    "    top_logits = top_logits.cpu().numpy()\n",
    "    i = i.cpu().numpy()\n",
    "    dist = Categorical(logits=logits)\n",
    "    top_probs = dist.probs[torch.arange(len(state)).unsqueeze(1), i]\n",
    "    entropy = dist.entropy().cpu().numpy()\n",
    "    if verbose:\n",
    "        for a, e, label_logit_prob in zip(state, entropy, zip(all_labels[i], top_logits, top_probs)):\n",
    "            print(f\"Entropy: {e:4f} | Label: {a:15}  |\", \" -- \".join(f\"{lab} [{prob:3.2f}, {log:5.2f}]\" for (lab, log, prob) in zip(*label_logit_prob)))\n",
    "        print()\n",
    "    action = logits.argmax(axis=-1)\n",
    "    return action.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abb5a4c6-c668-4ef3-89d7-3c47b668bec4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_model(model_path, output_size):\n",
    "    model_name = \"roberta-base\"\n",
    "    encoder = PretrainedEncoder(model_name, local_files_only=True).to(device)\n",
    "    policy = Seq2Labels(encoder_model=encoder, num_labels=output_size).to(device)\n",
    "    policy.load_state_dict(torch.load(model_path))\n",
    "    policy.eval()\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e4dde0-c3f4-448b-82c0-56c5cfd76c06",
   "metadata": {},
   "source": [
    "# Load Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "359d9b7a-79b0-4ad0-9c64-47d85aee5b52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of data in wi+locness: 24734\n",
      "Number of data without correct sentences: 15413\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"wi_locness_gec_lev_dist-v1\", new_step_api=True, correct_examples_percent=[0.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65ea936-90e4-490b-b640-c42caf641a1d",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbb5f929-496e-4094-b422-8bc706d9831d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "rl_model_path = os.path.abspath(\"pg_logs_new/finetune_rl_18_11_2022_15:00/model-last.pt\")\n",
    "sl_model_path = os.path.abspath(\"sl_logs/finetune_wi+locness_02:11:2022_23:06/model-best.pt\")\n",
    "rl_model = load_model(rl_model_path, output_size=len(env.labels))\n",
    "sl_model = load_model(sl_model_path, output_size=len(env.labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e90b34-f61b-454c-bbd4-aac2a0583fe3",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78177cae-217e-49fb-8ae4-bd375c24c8ae",
   "metadata": {},
   "source": [
    "# SL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09ab4c7e-5a4c-47ff-96cc-952eca185852",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajk/miniconda3/envs/drl-gec/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:133: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method should be an int or np.int64, actual type: <class 'list'>\u001b[0m\n",
      "  logger.warn(f\"{pre} should be an int or np.int64, actual type: {type(obs)}\")\n",
      "/home/rajk/miniconda3/envs/drl-gec/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:165: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 0.533590 | Label: $START           | $KEEP [0.92, 10.03] -- $APPEND_But [0.02,  6.12] -- $APPEND_And [0.01,  5.13]\n",
      "Entropy: 0.337851 | Label: he               | $TRANSFORM_CASE_CAPITAL [0.93, 11.58] -- $KEEP [0.06,  8.82] -- $REPLACE_He [0.00,  6.32]\n",
      "Entropy: 0.871657 | Label: said             | $APPEND_, [0.64, 10.05] -- $KEEP [0.32,  9.38] -- $REPLACE_, [0.01,  5.69]\n",
      "Entropy: 0.779609 | Label: in               | $KEEP [0.81,  9.01] -- $TRANSFORM_CASE_CAPITAL [0.10,  6.89] -- $DELETE [0.07,  6.58]\n",
      "Entropy: 0.595660 | Label: other            | $KEEP [0.87,  9.40] -- $DELETE [0.10,  7.21] -- $MERGE_SPACE [0.00,  4.15]\n",
      "Entropy: 0.896537 | Label: words            | $KEEP [0.64,  9.58] -- $APPEND_, [0.30,  8.84] -- $DELETE [0.05,  6.94]\n",
      "Entropy: 0.789471 | Label: that             | $KEEP [0.77,  9.21] -- $DELETE [0.17,  7.70] -- $REPLACE_, [0.03,  5.89]\n",
      "Entropy: 0.998475 | Label: the              | $DELETE [0.51,  8.31] -- $KEEP [0.45,  8.19] -- $UNKNOWN [0.01,  4.09]\n",
      "Entropy: 0.856027 | Label: more             | $KEEP [0.80,  8.93] -- $DELETE [0.13,  7.12] -- $UNKNOWN [0.02,  5.30]\n",
      "Entropy: 0.916357 | Label: fluoride         | $KEEP [0.84,  8.95] -- $UNKNOWN [0.08,  6.59] -- $APPEND_, [0.01,  4.84]\n",
      "Entropy: 1.235567 | Label: may              | $KEEP [0.68,  8.63] -- $REPLACE_might [0.20,  7.41] -- $REPLACE_could [0.02,  4.97]\n",
      "Entropy: 1.158607 | Label: create           | $KEEP [0.82,  9.16] -- $REPLACE_cause [0.04,  6.09] -- $APPEND_more [0.03,  5.80]\n",
      "Entropy: 0.891328 | Label: damage           | $KEEP [0.83,  9.16] -- $APPEND_to [0.10,  7.00] -- $UNKNOWN [0.01,  5.05]\n",
      "Entropy: 1.151927 | Label: in               | $APPEND_the [0.49, 10.52] -- $REPLACE_to [0.37, 10.24] -- $KEEP [0.10,  8.91]\n",
      "Entropy: 0.985000 | Label: human            | $KEEP [0.78,  8.64] -- $APPEND_'s [0.10,  6.57] -- $TRANSFORM_AGREEMENT_PLURAL [0.04,  5.71]\n",
      "Entropy: 0.821482 | Label: body             | $KEEP [0.83,  9.02] -- $TRANSFORM_VERB_VB_VBZ [0.08,  6.64] -- $DELETE [0.05,  6.17]\n",
      "Entropy: 0.582184 | Label: ,                | $KEEP [0.90,  9.33] -- $APPEND_and [0.04,  6.15] -- $APPEND_, [0.01,  4.95]\n",
      "Entropy: 1.006162 | Label: specifically     | $KEEP [0.82,  8.82] -- $APPEND_, [0.05,  6.00] -- $APPEND_to [0.04,  5.85]\n",
      "Entropy: 0.584729 | Label: the              | $KEEP [0.87,  9.66] -- $DELETE [0.06,  6.99] -- $REPLACE_to [0.05,  6.74]\n",
      "Entropy: 1.280136 | Label: bone             | $TRANSFORM_VERB_VB_VBZ [0.46,  9.23] -- $KEEP [0.35,  8.95] -- $TRANSFORM_AGREEMENT_PLURAL [0.14,  8.00]\n",
      "Entropy: 0.212481 | Label: .                | $KEEP [0.97,  9.51] -- $APPEND_\" [0.01,  4.93] -- $DELETE [0.01,  4.79]\n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 0  \n",
      "\u001b[37;1mRewards:\u001b[0m 0.000  \n",
      "\u001b[37;1mSource:\u001b[0m $START he said in other words that the more fluoride may create damage in human body , specifically the bone .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START he said in other words that the more fluoride may create damage in human body , specifically the bone .  \n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 1  \n",
      "\u001b[37;1mRewards:\u001b[0m 7.000  \n",
      "\u001b[37;1mSource:\u001b[0m $START \u001b[32;1mhe\u001b[0m [\u001b[31;1m$TRANSFORM_CASE_CAPITAL\u001b[0m] \u001b[32;1msaid\u001b[0m [\u001b[31;1m$APPEND_,\u001b[0m] in other words that \u001b[32;1mthe\u001b[0m [\u001b[31;1m$DELETE\u001b[0m] more fluoride may create damage \u001b[32;1min\u001b[0m [\u001b[31;1m$APPEND_the\u001b[0m] human body , specifically the \u001b[32;1mbone\u001b[0m [\u001b[31;1m$TRANSFORM_VERB_VB_VBZ\u001b[0m] .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START He said , in other words that more fluoride may create damage in the human body , specifically the bones .  \n",
      "\n",
      "Entropy: 0.280879 | Label: $START           | $KEEP [0.96, 10.68] -- $APPEND_But [0.01,  5.59] -- $APPEND_The [0.01,  5.44]\n",
      "Entropy: 0.498259 | Label: He               | $KEEP [0.93,  9.67] -- $REPLACE_He [0.02,  5.65] -- $APPEND_also [0.01,  5.23]\n",
      "Entropy: 0.807606 | Label: said             | $KEEP [0.81,  8.84] -- $TRANSFORM_VERB_VBN_VBZ [0.13,  7.04] -- $APPEND_that [0.01,  4.73]\n",
      "Entropy: 0.786212 | Label: ,                | $KEEP [0.74,  8.57] -- $DELETE [0.22,  7.35] -- $REPLACE_. [0.01,  3.98]\n",
      "Entropy: 0.880883 | Label: in               | $KEEP [0.71,  9.20] -- $TRANSFORM_CASE_CAPITAL [0.21,  8.00] -- $DELETE [0.07,  6.87]\n",
      "Entropy: 0.615040 | Label: other            | $KEEP [0.87,  9.33] -- $DELETE [0.10,  7.14] -- $MERGE_SPACE [0.01,  4.32]\n",
      "Entropy: 0.757378 | Label: words            | $APPEND_, [0.62, 10.58] -- $KEEP [0.36, 10.04] -- $DELETE [0.01,  6.47]\n",
      "Entropy: 0.885435 | Label: that             | $KEEP [0.78,  8.99] -- $REPLACE_, [0.11,  7.04] -- $DELETE [0.05,  6.23]\n",
      "Entropy: 1.014177 | Label: more             | $KEEP [0.72,  9.06] -- $DELETE [0.21,  7.84] -- $UNKNOWN [0.01,  5.18]\n",
      "Entropy: 0.809422 | Label: fluoride         | $KEEP [0.84,  9.47] -- $UNKNOWN [0.06,  6.81] -- $APPEND_, [0.05,  6.59]\n",
      "Entropy: 1.237387 | Label: may              | $KEEP [0.66,  8.70] -- $REPLACE_might [0.23,  7.66] -- $REPLACE_could [0.02,  5.22]\n",
      "Entropy: 1.136317 | Label: create           | $KEEP [0.81,  9.27] -- $REPLACE_cause [0.06,  6.71] -- $APPEND_more [0.01,  5.06]\n",
      "Entropy: 0.690814 | Label: damage           | $KEEP [0.90,  9.34] -- $APPEND_to [0.02,  5.61] -- $TRANSFORM_VERB_VB_VBZ [0.02,  5.47]\n",
      "Entropy: 0.924157 | Label: in               | $REPLACE_to [0.60, 10.17] -- $KEEP [0.35,  9.64] -- $REPLACE_on [0.03,  7.06]\n",
      "Entropy: 0.326816 | Label: the              | $KEEP [0.94,  9.77] -- $DELETE [0.03,  6.46] -- $UNKNOWN [0.01,  5.06]\n",
      "Entropy: 0.612387 | Label: human            | $KEEP [0.88,  9.19] -- $APPEND_'s [0.05,  6.41] -- $DELETE [0.02,  5.55]\n",
      "Entropy: 0.606782 | Label: body             | $KEEP [0.90,  9.21] -- $TRANSFORM_VERB_VB_VBZ [0.03,  5.96] -- $DELETE [0.02,  5.54]\n",
      "Entropy: 0.694875 | Label: ,                | $KEEP [0.87,  9.31] -- $APPEND_and [0.06,  6.65] -- $APPEND_, [0.01,  5.14]\n",
      "Entropy: 1.102868 | Label: specifically     | $KEEP [0.80,  8.81] -- $APPEND_to [0.05,  5.95] -- $APPEND_in [0.05,  5.94]\n",
      "Entropy: 0.732912 | Label: the              | $KEEP [0.82,  9.93] -- $REPLACE_to [0.08,  7.64] -- $DELETE [0.07,  7.54]\n",
      "Entropy: 0.596064 | Label: bones            | $KEEP [0.90,  8.77] -- $UNKNOWN [0.04,  5.56] -- $DELETE [0.02,  5.05]\n",
      "Entropy: 0.203664 | Label: .                | $KEEP [0.97,  9.59] -- $APPEND_\" [0.01,  5.40] -- $DELETE [0.00,  4.30]\n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 2  \n",
      "\u001b[37;1mRewards:\u001b[0m 3.000  \n",
      "\u001b[37;1mSource:\u001b[0m $START He said , in other \u001b[32;1mwords\u001b[0m [\u001b[31;1m$APPEND_,\u001b[0m] that more fluoride may create damage \u001b[32;1min\u001b[0m [\u001b[31;1m$REPLACE_to\u001b[0m] the human body , specifically the bones .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START He said , in other words , that more fluoride may create damage to the human body , specifically the bones .  \n",
      "\n",
      "Entropy: 0.233626 | Label: $START           | $KEEP [0.97, 10.99] -- $APPEND_But [0.01,  5.84] -- $APPEND_The [0.00,  5.69]\n",
      "Entropy: 0.512063 | Label: He               | $KEEP [0.92,  9.68] -- $APPEND_has [0.01,  5.49] -- $REPLACE_He [0.01,  5.48]\n",
      "Entropy: 0.774419 | Label: said             | $KEEP [0.78,  9.08] -- $TRANSFORM_VERB_VBN_VBZ [0.18,  7.60] -- $TRANSFORM_VERB_VBN_VB [0.01,  4.14]\n",
      "Entropy: 0.417338 | Label: ,                | $KEEP [0.91,  9.06] -- $DELETE [0.07,  6.44] -- $APPEND_, [0.01,  4.10]\n",
      "Entropy: 0.624958 | Label: in               | $KEEP [0.85,  9.34] -- $TRANSFORM_CASE_CAPITAL [0.08,  6.97] -- $DELETE [0.06,  6.66]\n",
      "Entropy: 0.517128 | Label: other            | $KEEP [0.90,  9.36] -- $DELETE [0.07,  6.87] -- $MERGE_SPACE [0.01,  4.49]\n",
      "Entropy: 0.474720 | Label: words            | $KEEP [0.91,  9.38] -- $DELETE [0.05,  6.55] -- $UNKNOWN [0.01,  4.59]\n",
      "Entropy: 0.451410 | Label: ,                | $KEEP [0.89,  9.44] -- $DELETE [0.09,  7.17] -- $UNKNOWN [0.00,  4.08]\n",
      "Entropy: 0.602944 | Label: that             | $KEEP [0.87,  8.91] -- $DELETE [0.10,  6.71] -- $APPEND_the [0.01,  4.05]\n",
      "Entropy: 1.011901 | Label: more             | $KEEP [0.73,  9.37] -- $DELETE [0.20,  8.10] -- $UNKNOWN [0.02,  5.84]\n",
      "Entropy: 0.819115 | Label: fluoride         | $KEEP [0.84,  9.56] -- $UNKNOWN [0.09,  7.37] -- $TRANSFORM_AGREEMENT_PLURAL [0.02,  5.60]\n",
      "Entropy: 1.238695 | Label: may              | $KEEP [0.63,  8.72] -- $REPLACE_might [0.27,  7.86] -- $REPLACE_could [0.02,  5.35]\n",
      "Entropy: 1.195832 | Label: create           | $KEEP [0.80,  9.11] -- $REPLACE_cause [0.07,  6.63] -- $REPLACE_do [0.01,  4.95]\n",
      "Entropy: 0.535847 | Label: damage           | $KEEP [0.93,  9.35] -- $TRANSFORM_VERB_VB_VBZ [0.01,  5.07] -- $APPEND_to [0.01,  4.96]\n",
      "Entropy: 0.487438 | Label: to               | $KEEP [0.91, 10.16] -- $REPLACE_for [0.02,  6.41] -- $REPLACE_in [0.02,  6.26]\n",
      "Entropy: 0.341052 | Label: the              | $KEEP [0.94,  9.70] -- $DELETE [0.04,  6.58] -- $UNKNOWN [0.01,  4.91]\n",
      "Entropy: 0.574298 | Label: human            | $KEEP [0.89,  9.23] -- $APPEND_'s [0.05,  6.34] -- $DELETE [0.02,  5.58]\n",
      "Entropy: 0.587794 | Label: body             | $KEEP [0.90,  9.22] -- $TRANSFORM_VERB_VB_VBZ [0.03,  5.94] -- $DELETE [0.02,  5.26]\n",
      "Entropy: 0.697921 | Label: ,                | $KEEP [0.86,  9.34] -- $APPEND_and [0.07,  6.81] -- $REPLACE_and [0.01,  5.26]\n",
      "Entropy: 0.888229 | Label: specifically     | $KEEP [0.86,  8.81] -- $APPEND_, [0.04,  5.77] -- $UNKNOWN [0.02,  4.98]\n",
      "Entropy: 0.680712 | Label: the              | $KEEP [0.84,  9.74] -- $DELETE [0.10,  7.59] -- $REPLACE_to [0.03,  6.54]\n",
      "Entropy: 0.584902 | Label: bones            | $KEEP [0.90,  8.79] -- $UNKNOWN [0.03,  5.52] -- $TRANSFORM_VERB_VBZ_VB [0.02,  4.77]\n",
      "Entropy: 0.195644 | Label: .                | $KEEP [0.97,  9.62] -- $APPEND_\" [0.01,  5.37] -- $DELETE [0.00,  4.19]\n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m \u001b[32;1m3\u001b[0m  \n",
      "\u001b[37;1mRewards:\u001b[0m 0.100  \n",
      "\u001b[37;1mSource:\u001b[0m $START He said , in other words , that more fluoride may create damage to the human body , specifically the bones .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START He said , in other words , that more fluoride may create damage to the human body , specifically the bones .  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajk/miniconda3/envs/drl-gec/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
      "  logger.deprecation(\n",
      "/home/rajk/miniconda3/envs/drl-gec/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:133: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method should be an int or np.int64, actual type: <class 'list'>\u001b[0m\n",
      "  logger.warn(f\"{pre} should be an int or np.int64, actual type: {type(obs)}\")\n",
      "/home/rajk/miniconda3/envs/drl-gec/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:165: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/home/rajk/miniconda3/envs/drl-gec/lib/python3.8/site-packages/gym/core.py:57: DeprecationWarning: \u001b[33mWARN: You are calling render method, but you didn't specified the argument render_mode at environment initialization. To maintain backward compatibility, the environment will render in human mode.\n",
      "If you want to render in human mode, initialize the environment in this way: gym.make('EnvName', render_mode='human') and don't call the render method.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n",
      "/home/rajk/miniconda3/envs/drl-gec/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:297: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "data_dict = dict(\n",
    "    text = \"he said in other words that the more fluoride may create damage in human body , specifically the bone .\",\n",
    "    references = [\n",
    "        \"He said in other words that the more fluoride may create damage in the human body , specifically the bone .\",\n",
    "        \"He said , in other words , that more fluoride may create damage in the human body , specifically the bone .\",\n",
    "        \"He said , in other words , that more fluoride may create damage to the human body , specifically the bones .\",\n",
    "        \"In other words , he said that more fluoride may damage the human body , specifically the bones .\"\n",
    "    ],\n",
    ")\n",
    "state = env.reset(data_dict=data_dict)\n",
    "done = False\n",
    "while not done:\n",
    "    action = greedy_action(sl_model, state, env.labels, verbose=True)\n",
    "    next_state, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    state = next_state\n",
    "    outputs = env.render()\n",
    "    for o in outputs:\n",
    "        print(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039e687c-e3cf-4ef2-987f-63898788dfe6",
   "metadata": {},
   "source": [
    "# RL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9c189a0-5eed-4b6a-af18-a43437147161",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 0.839501 | Label: $START           | $KEEP [0.84, 11.68] -- $APPEND_But [0.07,  9.23] -- $APPEND_And [0.02,  7.76]\n",
      "Entropy: 1.406336 | Label: he               | $TRANSFORM_CASE_CAPITAL [0.57, 11.05] -- $REPLACE_He [0.25, 10.24] -- $KEEP [0.07,  8.88]\n",
      "Entropy: 1.145620 | Label: said             | $KEEP [0.52,  9.45] -- $APPEND_, [0.40,  9.18] -- $DELETE [0.03,  6.54]\n",
      "Entropy: 1.294882 | Label: in               | $KEEP [0.71,  8.97] -- $DELETE [0.11,  7.14] -- $TRANSFORM_CASE_CAPITAL [0.05,  6.37]\n",
      "Entropy: 0.762814 | Label: other            | $KEEP [0.84,  9.56] -- $DELETE [0.09,  7.34] -- $APPEND_other [0.01,  5.40]\n",
      "Entropy: 0.878034 | Label: words            | $KEEP [0.67,  9.87] -- $APPEND_, [0.27,  8.96] -- $DELETE [0.04,  7.02]\n",
      "Entropy: 0.643609 | Label: that             | $KEEP [0.84, 10.36] -- $DELETE [0.12,  8.39] -- $APPEND_, [0.02,  6.70]\n",
      "Entropy: 1.400433 | Label: the              | $DELETE [0.62,  9.26] -- $KEEP [0.29,  8.50] -- $APPEND_use [0.01,  4.54]\n",
      "Entropy: 1.202860 | Label: more             | $KEEP [0.76,  9.78] -- $DELETE [0.14,  8.06] -- $APPEND_use [0.02,  6.14]\n",
      "Entropy: 0.529477 | Label: fluoride         | $KEEP [0.93, 10.14] -- $APPEND_, [0.02,  6.41] -- $DELETE [0.01,  4.99]\n",
      "Entropy: 1.072868 | Label: may              | $KEEP [0.78,  9.15] -- $REPLACE_might [0.10,  7.14] -- $DELETE [0.05,  6.34]\n",
      "Entropy: 0.862349 | Label: create           | $KEEP [0.87,  9.39] -- $DELETE [0.04,  6.20] -- $APPEND_more [0.02,  5.49]\n",
      "Entropy: 0.535857 | Label: damage           | $KEEP [0.92,  9.89] -- $APPEND_to [0.04,  6.72] -- $DELETE [0.01,  5.53]\n",
      "Entropy: 1.382788 | Label: in               | $APPEND_the [0.62, 10.12] -- $REPLACE_to [0.12,  8.47] -- $KEEP [0.12,  8.47]\n",
      "Entropy: 0.755197 | Label: human            | $KEEP [0.86,  9.13] -- $APPEND_'s [0.06,  6.38] -- $DELETE [0.02,  5.56]\n",
      "Entropy: 0.825596 | Label: body             | $KEEP [0.83,  9.86] -- $DELETE [0.07,  7.34] -- $TRANSFORM_VERB_VB_VBZ [0.06,  7.25]\n",
      "Entropy: 0.518286 | Label: ,                | $KEEP [0.91,  9.92] -- $DELETE [0.02,  6.27] -- $APPEND_, [0.02,  6.19]\n",
      "Entropy: 0.813922 | Label: specifically     | $KEEP [0.84,  9.68] -- $APPEND_, [0.09,  7.40] -- $APPEND_in [0.01,  5.49]\n",
      "Entropy: 0.591092 | Label: the              | $KEEP [0.88,  9.71] -- $DELETE [0.08,  7.37] -- $REPLACE_to [0.01,  5.38]\n",
      "Entropy: 1.257647 | Label: bone             | $KEEP [0.44, 10.00] -- $TRANSFORM_AGREEMENT_PLURAL [0.41,  9.93] -- $TRANSFORM_VERB_VB_VBZ [0.12,  8.68]\n",
      "Entropy: 0.199063 | Label: .                | $KEEP [0.97, 10.75] -- $DELETE [0.01,  6.09] -- $APPEND_\" [0.01,  6.05]\n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 0  \n",
      "\u001b[37;1mRewards:\u001b[0m 0.000  \n",
      "\u001b[37;1mSource:\u001b[0m $START he said in other words that the more fluoride may create damage in human body , specifically the bone .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START he said in other words that the more fluoride may create damage in human body , specifically the bone .  \n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 1  \n",
      "\u001b[37;1mRewards:\u001b[0m 4.000  \n",
      "\u001b[37;1mSource:\u001b[0m $START \u001b[32;1mhe\u001b[0m [\u001b[31;1m$TRANSFORM_CASE_CAPITAL\u001b[0m] said in other words that \u001b[32;1mthe\u001b[0m [\u001b[31;1m$DELETE\u001b[0m] more fluoride may create damage \u001b[32;1min\u001b[0m [\u001b[31;1m$APPEND_the\u001b[0m] human body , specifically the bone .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START He said in other words that more fluoride may create damage in the human body , specifically the bone .  \n",
      "\n",
      "Entropy: 0.205148 | Label: $START           | $KEEP [0.97, 12.82] -- $APPEND_But [0.01,  8.47] -- $APPEND_In [0.00,  6.90]\n",
      "Entropy: 0.585856 | Label: He               | $KEEP [0.91, 10.21] -- $REPLACE_He [0.02,  6.43] -- $APPEND_has [0.01,  5.93]\n",
      "Entropy: 1.007574 | Label: said             | $APPEND_, [0.56, 10.08] -- $KEEP [0.39,  9.71] -- $REPLACE_, [0.02,  6.52]\n",
      "Entropy: 1.231109 | Label: in               | $KEEP [0.74,  8.87] -- $DELETE [0.09,  6.79] -- $REPLACE_in [0.04,  5.95]\n",
      "Entropy: 0.772326 | Label: other            | $KEEP [0.85,  9.63] -- $DELETE [0.07,  7.19] -- $APPEND_other [0.02,  5.78]\n",
      "Entropy: 0.929165 | Label: words            | $KEEP [0.60,  9.82] -- $APPEND_, [0.35,  9.28] -- $DELETE [0.03,  6.90]\n",
      "Entropy: 0.564484 | Label: that             | $KEEP [0.89, 10.28] -- $DELETE [0.05,  7.44] -- $APPEND_, [0.03,  6.94]\n",
      "Entropy: 1.107267 | Label: more             | $KEEP [0.64,  9.61] -- $DELETE [0.31,  8.88] -- $APPEND_of [0.01,  4.86]\n",
      "Entropy: 0.448299 | Label: fluoride         | $KEEP [0.94, 10.36] -- $APPEND_, [0.01,  6.06] -- $TRANSFORM_AGREEMENT_PLURAL [0.01,  5.90]\n",
      "Entropy: 1.208260 | Label: may              | $KEEP [0.70,  9.16] -- $REPLACE_might [0.18,  7.79] -- $DELETE [0.04,  6.17]\n",
      "Entropy: 0.969280 | Label: create           | $KEEP [0.86,  9.34] -- $DELETE [0.03,  5.95] -- $REPLACE_cause [0.03,  5.87]\n",
      "Entropy: 0.464323 | Label: damage           | $KEEP [0.94, 10.07] -- $APPEND_to [0.01,  5.56] -- $DELETE [0.01,  5.19]\n",
      "Entropy: 1.541457 | Label: in               | $KEEP [0.48,  9.13] -- $REPLACE_to [0.29,  8.64] -- $DELETE [0.09,  7.44]\n",
      "Entropy: 0.379273 | Label: the              | $KEEP [0.93,  9.94] -- $DELETE [0.04,  6.85] -- $APPEND_the [0.00,  4.67]\n",
      "Entropy: 0.568268 | Label: human            | $KEEP [0.90,  9.63] -- $APPEND_'s [0.04,  6.59] -- $DELETE [0.04,  6.42]\n",
      "Entropy: 0.491792 | Label: body             | $KEEP [0.92, 10.12] -- $DELETE [0.03,  6.81] -- $TRANSFORM_VERB_VB_VBZ [0.02,  6.03]\n",
      "Entropy: 0.625642 | Label: ,                | $KEEP [0.89,  9.87] -- $APPEND_and [0.03,  6.63] -- $APPEND_, [0.03,  6.51]\n",
      "Entropy: 1.021643 | Label: specifically     | $KEEP [0.79,  9.64] -- $APPEND_, [0.12,  7.72] -- $APPEND_in [0.03,  6.41]\n",
      "Entropy: 0.657709 | Label: the              | $KEEP [0.87,  9.64] -- $DELETE [0.08,  7.28] -- $REPLACE_to [0.01,  5.43]\n",
      "Entropy: 1.188870 | Label: bone             | $TRANSFORM_AGREEMENT_PLURAL [0.55, 10.72] -- $KEEP [0.29, 10.07] -- $TRANSFORM_VERB_VB_VBZ [0.14,  9.32]\n",
      "Entropy: 0.181671 | Label: .                | $KEEP [0.97, 10.82] -- $APPEND_\" [0.01,  6.10] -- $DELETE [0.01,  5.84]\n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 2  \n",
      "\u001b[37;1mRewards:\u001b[0m 3.000  \n",
      "\u001b[37;1mSource:\u001b[0m $START He \u001b[32;1msaid\u001b[0m [\u001b[31;1m$APPEND_,\u001b[0m] in other words that more fluoride may create damage in the human body , specifically the \u001b[32;1mbone\u001b[0m [\u001b[31;1m$TRANSFORM_AGREEMENT_PLURAL\u001b[0m] .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START He said , in other words that more fluoride may create damage in the human body , specifically the bones .  \n",
      "\n",
      "Entropy: 0.244987 | Label: $START           | $KEEP [0.96, 12.84] -- $APPEND_But [0.02,  8.72] -- $APPEND_In [0.00,  7.28]\n",
      "Entropy: 0.582475 | Label: He               | $KEEP [0.91, 10.24] -- $APPEND_also [0.02,  6.47] -- $APPEND_has [0.02,  6.33]\n",
      "Entropy: 0.809945 | Label: said             | $KEEP [0.86,  9.38] -- $DELETE [0.05,  6.46] -- $APPEND_that [0.02,  5.59]\n",
      "Entropy: 0.953472 | Label: ,                | $KEEP [0.69,  9.01] -- $DELETE [0.26,  8.03] -- $APPEND_, [0.02,  5.51]\n",
      "Entropy: 1.341798 | Label: in               | $KEEP [0.66,  8.98] -- $DELETE [0.12,  7.28] -- $TRANSFORM_CASE_CAPITAL [0.11,  7.22]\n",
      "Entropy: 0.758338 | Label: other            | $KEEP [0.85,  9.70] -- $DELETE [0.08,  7.37] -- $APPEND_other [0.01,  5.62]\n",
      "Entropy: 0.638904 | Label: words            | $APPEND_, [0.74, 11.59] -- $KEEP [0.25, 10.49] -- $DELETE [0.01,  6.66]\n",
      "Entropy: 0.899867 | Label: that             | $KEEP [0.77, 10.10] -- $APPEND_, [0.14,  8.38] -- $REPLACE_, [0.04,  7.16]\n",
      "Entropy: 1.123573 | Label: more             | $KEEP [0.68,  9.37] -- $DELETE [0.25,  8.37] -- $APPEND_, [0.01,  5.24]\n",
      "Entropy: 0.594648 | Label: fluoride         | $KEEP [0.88, 10.33] -- $APPEND_, [0.08,  7.98] -- $TRANSFORM_AGREEMENT_PLURAL [0.01,  5.74]\n",
      "Entropy: 1.173331 | Label: may              | $KEEP [0.72,  9.20] -- $REPLACE_might [0.17,  7.74] -- $DELETE [0.03,  6.08]\n",
      "Entropy: 0.956991 | Label: create           | $KEEP [0.86,  9.33] -- $DELETE [0.03,  5.97] -- $REPLACE_cause [0.02,  5.63]\n",
      "Entropy: 0.477783 | Label: damage           | $KEEP [0.94, 10.03] -- $APPEND_to [0.01,  5.63] -- $DELETE [0.01,  5.30]\n",
      "Entropy: 1.540597 | Label: in               | $KEEP [0.46,  9.13] -- $REPLACE_to [0.31,  8.72] -- $DELETE [0.09,  7.49]\n",
      "Entropy: 0.381952 | Label: the              | $KEEP [0.93,  9.95] -- $DELETE [0.04,  6.89] -- $APPEND_the [0.00,  4.60]\n",
      "Entropy: 0.540084 | Label: human            | $KEEP [0.90,  9.63] -- $APPEND_'s [0.04,  6.52] -- $DELETE [0.03,  6.25]\n",
      "Entropy: 0.568038 | Label: body             | $KEEP [0.90, 10.02] -- $TRANSFORM_VERB_VB_VBZ [0.03,  6.63] -- $DELETE [0.03,  6.60]\n",
      "Entropy: 0.658789 | Label: ,                | $KEEP [0.88,  9.78] -- $APPEND_and [0.04,  6.75] -- $APPEND_, [0.03,  6.46]\n",
      "Entropy: 1.039292 | Label: specifically     | $KEEP [0.78,  9.59] -- $APPEND_, [0.12,  7.68] -- $APPEND_in [0.03,  6.40]\n",
      "Entropy: 0.918086 | Label: the              | $KEEP [0.79,  9.58] -- $DELETE [0.12,  7.71] -- $REPLACE_to [0.05,  6.73]\n",
      "Entropy: 0.359017 | Label: bones            | $KEEP [0.96,  9.65] -- $DELETE [0.02,  5.62] -- $TRANSFORM_VERB_VBZ_VB [0.00,  3.34]\n",
      "Entropy: 0.175774 | Label: .                | $KEEP [0.98, 10.91] -- $APPEND_\" [0.01,  6.20] -- $DELETE [0.01,  5.81]\n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 3  \n",
      "\u001b[37;1mRewards:\u001b[0m 1.000  \n",
      "\u001b[37;1mSource:\u001b[0m $START He said , in other \u001b[32;1mwords\u001b[0m [\u001b[31;1m$APPEND_,\u001b[0m] that more fluoride may create damage in the human body , specifically the bones .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START He said , in other words , that more fluoride may create damage in the human body , specifically the bones .  \n",
      "\n",
      "Entropy: 0.190171 | Label: $START           | $KEEP [0.97, 13.23] -- $APPEND_But [0.01,  8.94] -- $APPEND_In [0.00,  7.03]\n",
      "Entropy: 0.620085 | Label: He               | $KEEP [0.90, 10.21] -- $APPEND_has [0.03,  6.83] -- $APPEND_also [0.02,  6.46]\n",
      "Entropy: 0.715759 | Label: said             | $KEEP [0.88,  9.42] -- $TRANSFORM_VERB_VBN_VBZ [0.03,  6.08] -- $DELETE [0.03,  6.07]\n",
      "Entropy: 0.629074 | Label: ,                | $KEEP [0.85,  9.61] -- $DELETE [0.09,  7.37] -- $APPEND_, [0.04,  6.45]\n",
      "Entropy: 1.019122 | Label: in               | $KEEP [0.77,  9.14] -- $DELETE [0.10,  7.11] -- $TRANSFORM_CASE_CAPITAL [0.05,  6.41]\n",
      "Entropy: 0.600869 | Label: other            | $KEEP [0.89,  9.82] -- $DELETE [0.06,  7.10] -- $APPEND_other [0.01,  5.59]\n",
      "Entropy: 0.460152 | Label: words            | $KEEP [0.93,  9.81] -- $DELETE [0.04,  6.60] -- $APPEND_, [0.00,  4.56]\n",
      "Entropy: 0.343679 | Label: ,                | $KEEP [0.93, 10.46] -- $DELETE [0.05,  7.49] -- $APPEND_, [0.01,  5.87]\n",
      "Entropy: 0.503488 | Label: that             | $KEEP [0.91,  9.91] -- $DELETE [0.06,  7.24] -- $APPEND_that [0.01,  4.72]\n",
      "Entropy: 1.071425 | Label: more             | $KEEP [0.66,  9.76] -- $DELETE [0.28,  8.91] -- $APPEND_of [0.00,  4.73]\n",
      "Entropy: 0.460695 | Label: fluoride         | $KEEP [0.94, 10.40] -- $TRANSFORM_AGREEMENT_PLURAL [0.01,  6.01] -- $APPEND_, [0.01,  5.65]\n",
      "Entropy: 1.186358 | Label: may              | $KEEP [0.70,  9.20] -- $REPLACE_might [0.19,  7.88] -- $DELETE [0.03,  6.05]\n",
      "Entropy: 1.000351 | Label: create           | $KEEP [0.85,  9.32] -- $DELETE [0.03,  5.99] -- $REPLACE_cause [0.02,  5.73]\n",
      "Entropy: 0.485334 | Label: damage           | $KEEP [0.94, 10.02] -- $APPEND_to [0.01,  5.49] -- $DELETE [0.01,  5.27]\n",
      "Entropy: 1.575712 | Label: in               | $KEEP [0.46,  9.09] -- $REPLACE_to [0.30,  8.69] -- $DELETE [0.09,  7.45]\n",
      "Entropy: 0.389280 | Label: the              | $KEEP [0.93,  9.93] -- $DELETE [0.04,  6.86] -- $APPEND_the [0.00,  4.64]\n",
      "Entropy: 0.540667 | Label: human            | $KEEP [0.90,  9.64] -- $APPEND_'s [0.04,  6.58] -- $DELETE [0.03,  6.17]\n",
      "Entropy: 0.590334 | Label: body             | $KEEP [0.90, 10.00] -- $TRANSFORM_VERB_VB_VBZ [0.04,  6.81] -- $DELETE [0.03,  6.46]\n",
      "Entropy: 0.706306 | Label: ,                | $KEEP [0.87,  9.75] -- $APPEND_and [0.05,  6.91] -- $APPEND_, [0.03,  6.51]\n",
      "Entropy: 1.086949 | Label: specifically     | $KEEP [0.77,  9.62] -- $APPEND_, [0.11,  7.68] -- $APPEND_in [0.04,  6.59]\n",
      "Entropy: 0.958914 | Label: the              | $KEEP [0.77,  9.55] -- $DELETE [0.12,  7.72] -- $REPLACE_to [0.05,  6.86]\n",
      "Entropy: 0.370265 | Label: bones            | $KEEP [0.96,  9.63] -- $DELETE [0.02,  5.58] -- $TRANSFORM_VERB_VBZ_VB [0.00,  3.49]\n",
      "Entropy: 0.169732 | Label: .                | $KEEP [0.98, 10.92] -- $APPEND_\" [0.01,  6.03] -- $DELETE [0.01,  5.74]\n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m \u001b[32;1m4\u001b[0m  \n",
      "\u001b[37;1mRewards:\u001b[0m 0.000  \n",
      "\u001b[37;1mSource:\u001b[0m $START He said , in other words , that more fluoride may create damage in the human body , specifically the bones .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START He said , in other words , that more fluoride may create damage in the human body , specifically the bones .  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_dict = dict(\n",
    "    text = \"he said in other words that the more fluoride may create damage in human body , specifically the bone .\",\n",
    "    references = [\n",
    "        \"He said in other words that the more fluoride may create damage in the human body , specifically the bone .\",\n",
    "        \"He said , in other words , that more fluoride may create damage in the human body , specifically the bone .\",\n",
    "        \"He said , in other words , that more fluoride may create damage to the human body , specifically the bones .\",\n",
    "        \"In other words , he said that more fluoride may damage the human body , specifically the bones .\"\n",
    "    ]\n",
    ")\n",
    "state = env.reset(data_dict=data_dict)\n",
    "done = False\n",
    "while not done:\n",
    "    action = greedy_action(rl_model, state, env.labels, verbose=True)\n",
    "    next_state, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    state = next_state\n",
    "    outputs = env.render()\n",
    "    for o in outputs:\n",
    "        print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b78ffb-84af-4df2-8fe6-bc9b594bb89a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a2ebd33-87ff-4c46-80d4-ab6322d8c147",
   "metadata": {},
   "source": [
    "# RL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23afbcae-b6db-46dc-b4aa-a890c3161f52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 0.153830 | Label: $START           | $KEEP [0.98, 13.09] -- $APPEND_But [0.01,  8.42] -- $APPEND_However [0.00,  7.50]\n",
      "Entropy: 0.274802 | Label: Unfortunately    | $KEEP [0.97, 10.59] -- $DELETE [0.01,  6.20] -- $APPEND_, [0.00,  5.13]\n",
      "Entropy: 0.301851 | Label: ,                | $KEEP [0.94, 10.57] -- $DELETE [0.05,  7.53] -- $APPEND_, [0.01,  5.59]\n",
      "Entropy: 0.301055 | Label: there            | $KEEP [0.95, 10.65] -- $DELETE [0.02,  6.80] -- $REPLACE_there [0.01,  5.44]\n",
      "Entropy: 0.524787 | Label: is               | $KEEP [0.91, 10.02] -- $DELETE [0.05,  7.07] -- $REPLACE_are [0.01,  5.04]\n",
      "Entropy: 0.487239 | Label: still            | $KEEP [0.91, 10.68] -- $DELETE [0.04,  7.63] -- $APPEND_much [0.02,  6.84]\n",
      "Entropy: 0.428117 | Label: a                | $KEEP [0.92, 11.41] -- $DELETE [0.06,  8.66] -- $APPEND_lot [0.00,  6.15]\n",
      "Entropy: 0.402745 | Label: long             | $KEEP [0.94, 10.43] -- $DELETE [0.02,  6.78] -- $APPEND_of [0.01,  5.41]\n",
      "Entropy: 0.299234 | Label: way              | $KEEP [0.97, 11.46] -- $DELETE [0.00,  6.02] -- $APPEND_much [0.00,  5.68]\n",
      "Entropy: 0.517634 | Label: to               | $KEEP [0.93, 10.49] -- $DELETE [0.02,  6.72] -- $APPEND_be [0.01,  5.85]\n",
      "Entropy: 1.162630 | Label: do               | $REPLACE_go [0.62, 11.80] -- $KEEP [0.29, 11.06] -- $APPEND_go [0.03,  8.92]\n",
      "Entropy: 0.822961 | Label: in               | $KEEP [0.84,  9.32] -- $DELETE [0.11,  7.25] -- $APPEND_the [0.01,  5.29]\n",
      "Entropy: 0.699157 | Label: terms            | $APPEND_of [0.85, 10.47] -- $KEEP [0.09,  8.24] -- $DELETE [0.03,  7.07]\n",
      "Entropy: 0.507135 | Label: environment      | $KEEP [0.92,  9.68] -- $DELETE [0.05,  6.80] -- $TRANSFORM_AGREEMENT_PLURAL [0.00,  4.40]\n",
      "Entropy: 1.041192 | Label: concerns         | $KEEP [0.82,  9.38] -- $DELETE [0.08,  7.04] -- $REPLACE_issues [0.03,  6.20]\n",
      "Entropy: 0.397497 | Label: ,                | $KEEP [0.92, 10.33] -- $DELETE [0.06,  7.53] -- $APPEND_, [0.01,  5.75]\n",
      "Entropy: 0.310564 | Label: but              | $KEEP [0.96, 10.03] -- $DELETE [0.01,  5.22] -- $APPEND_, [0.00,  4.77]\n",
      "Entropy: 0.306111 | Label: some             | $KEEP [0.96, 10.38] -- $DELETE [0.01,  5.85] -- $REPLACE_many [0.00,  4.43]\n",
      "Entropy: 0.337238 | Label: of               | $KEEP [0.94, 10.12] -- $DELETE [0.04,  6.99] -- $APPEND_the [0.01,  5.30]\n",
      "Entropy: 1.566743 | Label: this             | $REPLACE_the [0.42,  9.24] -- $KEEP [0.22,  8.58] -- $REPLACE_these [0.21,  8.55]\n",
      "Entropy: 0.518126 | Label: solutions        | $KEEP [0.93,  9.48] -- $DELETE [0.02,  5.74] -- $APPEND_are [0.01,  4.61]\n",
      "Entropy: 0.363957 | Label: suggested        | $KEEP [0.96,  9.77] -- $DELETE [0.01,  5.21] -- $APPEND_today [0.00,  3.19]\n",
      "Entropy: 0.252295 | Label: by               | $KEEP [0.97,  9.90] -- $DELETE [0.01,  5.42] -- $REPLACE_by [0.01,  4.82]\n",
      "Entropy: 0.321772 | Label: the              | $KEEP [0.95,  9.93] -- $DELETE [0.04,  6.72] -- $APPEND_new [0.00,  3.50]\n",
      "Entropy: 1.590612 | Label: mayor            | $KEEP [0.46,  9.83] -- $APPEND_will [0.30,  9.43] -- $APPEND_could [0.10,  8.36]\n",
      "Entropy: 1.309978 | Label: help             | $KEEP [0.81,  8.73] -- $APPEND_help [0.04,  5.65] -- $TRANSFORM_VERB_VB_VBN [0.02,  5.20]\n",
      "Entropy: 1.146446 | Label: us               | $KEEP [0.76,  9.19] -- $DELETE [0.07,  6.81] -- $APPEND_in [0.06,  6.63]\n",
      "Entropy: 1.888579 | Label: stopping         | $TRANSFORM_VERB_VBG_VB [0.66,  9.71] -- $KEEP [0.13,  8.09] -- $DELETE [0.04,  6.98]\n",
      "Entropy: 0.965436 | Label: the              | $DELETE [0.57,  9.71] -- $KEEP [0.41,  9.38] -- $REPLACE_to [0.00,  3.78]\n",
      "Entropy: 0.318522 | Label: pollution        | $KEEP [0.96, 10.14] -- $DELETE [0.01,  5.85] -- $TRANSFORM_AGREEMENT_PLURAL [0.00,  4.26]\n",
      "Entropy: 0.146230 | Label: .                | $KEEP [0.98, 11.07] -- $DELETE [0.01,  5.83] -- $APPEND_\" [0.00,  5.26]\n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 0  \n",
      "\u001b[37;1mRewards:\u001b[0m 0.000  \n",
      "\u001b[37;1mSource:\u001b[0m $START Unfortunately , there is still a long way to do in terms environment concerns , but some of this solutions suggested by the mayor help us stopping the pollution .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START Unfortunately , there is still a long way to do in terms environment concerns , but some of this solutions suggested by the mayor help us stopping the pollution .  \n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 1  \n",
      "\u001b[37;1mRewards:\u001b[0m 4.000  \n",
      "\u001b[37;1mSource:\u001b[0m $START Unfortunately , there is still a long way to \u001b[32;1mdo\u001b[0m [\u001b[31;1m$REPLACE_go\u001b[0m] in \u001b[32;1mterms\u001b[0m [\u001b[31;1m$APPEND_of\u001b[0m] environment concerns , but some of \u001b[32;1mthis\u001b[0m [\u001b[31;1m$REPLACE_the\u001b[0m] solutions suggested by the mayor help us \u001b[32;1mstopping\u001b[0m [\u001b[31;1m$TRANSFORM_VERB_VBG_VB\u001b[0m] \u001b[32;1mthe\u001b[0m [\u001b[31;1m$DELETE\u001b[0m] pollution .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START Unfortunately , there is still a long way to go in terms of environment concerns , but some of the solutions suggested by the mayor help us stop pollution .  \n",
      "\n",
      "Entropy: 0.113208 | Label: $START           | $KEEP [0.98, 13.58] -- $APPEND_But [0.01,  8.69] -- $APPEND_However [0.00,  7.69]\n",
      "Entropy: 0.312614 | Label: Unfortunately    | $KEEP [0.96, 10.58] -- $DELETE [0.01,  6.11] -- $APPEND_, [0.01,  5.55]\n",
      "Entropy: 0.324555 | Label: ,                | $KEEP [0.94, 10.45] -- $DELETE [0.05,  7.43] -- $APPEND_, [0.01,  5.81]\n",
      "Entropy: 0.323324 | Label: there            | $KEEP [0.95, 10.50] -- $DELETE [0.02,  6.75] -- $REPLACE_there [0.01,  5.65]\n",
      "Entropy: 0.627151 | Label: is               | $KEEP [0.89,  9.76] -- $DELETE [0.05,  6.93] -- $REPLACE_is [0.01,  5.27]\n",
      "Entropy: 0.542767 | Label: still            | $KEEP [0.90, 10.44] -- $DELETE [0.06,  7.72] -- $APPEND_much [0.02,  6.44]\n",
      "Entropy: 0.398446 | Label: a                | $KEEP [0.93, 11.05] -- $DELETE [0.04,  7.88] -- $APPEND_whole [0.00,  5.58]\n",
      "Entropy: 0.421560 | Label: long             | $KEEP [0.94, 10.43] -- $DELETE [0.02,  6.69] -- $APPEND_a [0.01,  5.53]\n",
      "Entropy: 0.265689 | Label: way              | $KEEP [0.97, 10.68] -- $DELETE [0.00,  5.39] -- $TRANSFORM_AGREEMENT_PLURAL [0.00,  4.90]\n",
      "Entropy: 0.191401 | Label: to               | $KEEP [0.98, 10.69] -- $DELETE [0.01,  6.22] -- $APPEND_be [0.00,  3.90]\n",
      "Entropy: 0.399048 | Label: go               | $KEEP [0.94, 10.26] -- $APPEND_, [0.03,  6.84] -- $DELETE [0.01,  5.65]\n",
      "Entropy: 0.724179 | Label: in               | $KEEP [0.86,  9.21] -- $DELETE [0.09,  6.94] -- $APPEND_the [0.01,  4.82]\n",
      "Entropy: 0.705965 | Label: terms            | $KEEP [0.85,  9.45] -- $DELETE [0.12,  7.46] -- $APPEND_of [0.00,  3.99]\n",
      "Entropy: 0.591808 | Label: of               | $KEEP [0.91, 10.09] -- $DELETE [0.03,  6.78] -- $APPEND_the [0.03,  6.50]\n",
      "Entropy: 0.802337 | Label: environment      | $KEEP [0.85,  9.54] -- $DELETE [0.09,  7.28] -- $REPLACE_environment [0.01,  4.97]\n",
      "Entropy: 1.191665 | Label: concerns         | $KEEP [0.80,  9.27] -- $DELETE [0.07,  6.85] -- $REPLACE_issues [0.05,  6.56]\n",
      "Entropy: 0.426856 | Label: ,                | $KEEP [0.92, 10.20] -- $DELETE [0.05,  7.32] -- $APPEND_, [0.01,  5.90]\n",
      "Entropy: 0.340289 | Label: but              | $KEEP [0.96,  9.98] -- $DELETE [0.01,  4.96] -- $APPEND_, [0.01,  4.91]\n",
      "Entropy: 0.310435 | Label: some             | $KEEP [0.96, 10.45] -- $DELETE [0.01,  5.63] -- $REPLACE_few [0.00,  4.94]\n",
      "Entropy: 0.232838 | Label: of               | $KEEP [0.96, 10.30] -- $DELETE [0.02,  6.53] -- $APPEND_the [0.00,  5.01]\n",
      "Entropy: 0.384377 | Label: the              | $KEEP [0.95,  9.98] -- $DELETE [0.02,  5.92] -- $APPEND_new [0.01,  5.39]\n",
      "Entropy: 0.506368 | Label: solutions        | $KEEP [0.93,  9.51] -- $DELETE [0.01,  5.22] -- $APPEND_are [0.01,  4.97]\n",
      "Entropy: 0.459420 | Label: suggested        | $KEEP [0.95,  9.66] -- $DELETE [0.01,  4.81] -- $APPEND_today [0.00,  3.78]\n",
      "Entropy: 0.282210 | Label: by               | $KEEP [0.96,  9.74] -- $DELETE [0.01,  5.10] -- $REPLACE_by [0.01,  4.76]\n",
      "Entropy: 0.381289 | Label: the              | $KEEP [0.94,  9.73] -- $DELETE [0.04,  6.46] -- $APPEND_new [0.00,  4.05]\n",
      "Entropy: 1.661435 | Label: mayor            | $APPEND_will [0.39,  9.44] -- $KEEP [0.37,  9.39] -- $APPEND_could [0.09,  7.97]\n",
      "Entropy: 1.317191 | Label: help             | $KEEP [0.79,  8.67] -- $TRANSFORM_VERB_VB_VBN [0.05,  5.98] -- $APPEND_help [0.03,  5.38]\n",
      "Entropy: 0.721398 | Label: us               | $KEEP [0.86,  9.83] -- $APPEND_to [0.07,  7.29] -- $DELETE [0.04,  6.74]\n",
      "Entropy: 0.795678 | Label: stop             | $KEEP [0.90,  9.32] -- $DELETE [0.02,  5.25] -- $REPLACE_reduce [0.01,  5.16]\n",
      "Entropy: 0.327271 | Label: pollution        | $KEEP [0.96, 10.32] -- $DELETE [0.01,  5.37] -- $TRANSFORM_AGREEMENT_PLURAL [0.00,  4.88]\n",
      "Entropy: 0.155108 | Label: .                | $KEEP [0.98, 11.09] -- $APPEND_\" [0.00,  5.63] -- $DELETE [0.00,  5.47]\n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 2  \n",
      "\u001b[37;1mRewards:\u001b[0m -1.000  \n",
      "\u001b[37;1mSource:\u001b[0m $START Unfortunately , there is still a long way to go in terms of environment concerns , but some of the solutions suggested by the \u001b[32;1mmayor\u001b[0m [\u001b[31;1m$APPEND_will\u001b[0m] help us stop pollution .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START Unfortunately , there is still a long way to go in terms of environment concerns , but some of the solutions suggested by the mayor will help us stop pollution .  \n",
      "\n",
      "Entropy: 0.108905 | Label: $START           | $KEEP [0.99, 13.68] -- $APPEND_But [0.01,  8.78] -- $APPEND_However [0.00,  7.75]\n",
      "Entropy: 0.324865 | Label: Unfortunately    | $KEEP [0.96, 10.57] -- $DELETE [0.01,  6.13] -- $APPEND_, [0.01,  5.66]\n",
      "Entropy: 0.331663 | Label: ,                | $KEEP [0.94, 10.45] -- $DELETE [0.05,  7.44] -- $APPEND_, [0.01,  5.88]\n",
      "Entropy: 0.336214 | Label: there            | $KEEP [0.95, 10.46] -- $DELETE [0.02,  6.76] -- $REPLACE_there [0.01,  5.67]\n",
      "Entropy: 0.615269 | Label: is               | $KEEP [0.89,  9.80] -- $DELETE [0.05,  6.90] -- $REPLACE_is [0.01,  5.33]\n",
      "Entropy: 0.547799 | Label: still            | $KEEP [0.90, 10.44] -- $DELETE [0.06,  7.72] -- $APPEND_much [0.02,  6.43]\n",
      "Entropy: 0.408840 | Label: a                | $KEEP [0.93, 11.01] -- $DELETE [0.04,  7.86] -- $APPEND_whole [0.00,  5.57]\n",
      "Entropy: 0.436447 | Label: long             | $KEEP [0.94, 10.40] -- $DELETE [0.02,  6.70] -- $APPEND_a [0.01,  5.51]\n",
      "Entropy: 0.270183 | Label: way              | $KEEP [0.97, 10.66] -- $DELETE [0.00,  5.38] -- $TRANSFORM_AGREEMENT_PLURAL [0.00,  4.86]\n",
      "Entropy: 0.196668 | Label: to               | $KEEP [0.98, 10.66] -- $DELETE [0.01,  6.23] -- $APPEND_be [0.00,  3.93]\n",
      "Entropy: 0.410019 | Label: go               | $KEEP [0.94, 10.24] -- $APPEND_, [0.03,  6.84] -- $DELETE [0.01,  5.67]\n",
      "Entropy: 0.739710 | Label: in               | $KEEP [0.86,  9.18] -- $DELETE [0.09,  6.94] -- $APPEND_the [0.01,  4.79]\n",
      "Entropy: 0.716958 | Label: terms            | $KEEP [0.85,  9.42] -- $DELETE [0.12,  7.44] -- $APPEND_of [0.00,  4.01]\n",
      "Entropy: 0.605762 | Label: of               | $KEEP [0.91, 10.09] -- $DELETE [0.03,  6.79] -- $APPEND_the [0.03,  6.56]\n",
      "Entropy: 0.820592 | Label: environment      | $KEEP [0.85,  9.55] -- $DELETE [0.09,  7.31] -- $REPLACE_environment [0.01,  5.10]\n",
      "Entropy: 1.198176 | Label: concerns         | $KEEP [0.79,  9.41] -- $DELETE [0.08,  7.14] -- $REPLACE_issues [0.05,  6.72]\n",
      "Entropy: 0.438899 | Label: ,                | $KEEP [0.92, 10.16] -- $DELETE [0.05,  7.33] -- $APPEND_, [0.01,  5.86]\n",
      "Entropy: 0.333273 | Label: but              | $KEEP [0.96,  9.99] -- $DELETE [0.01,  5.23] -- $APPEND_, [0.00,  4.73]\n",
      "Entropy: 0.300681 | Label: some             | $KEEP [0.96, 10.49] -- $DELETE [0.01,  5.62] -- $REPLACE_few [0.00,  4.84]\n",
      "Entropy: 0.246870 | Label: of               | $KEEP [0.96, 10.25] -- $DELETE [0.02,  6.47] -- $APPEND_the [0.01,  5.20]\n",
      "Entropy: 0.395630 | Label: the              | $KEEP [0.94, 10.00] -- $DELETE [0.01,  5.84] -- $APPEND_new [0.01,  5.73]\n",
      "Entropy: 0.525591 | Label: solutions        | $KEEP [0.93,  9.39] -- $DELETE [0.02,  5.28] -- $APPEND_are [0.01,  4.17]\n",
      "Entropy: 0.468835 | Label: suggested        | $KEEP [0.95,  9.65] -- $DELETE [0.01,  4.72] -- $APPEND_today [0.00,  3.97]\n",
      "Entropy: 0.283352 | Label: by               | $KEEP [0.96,  9.68] -- $DELETE [0.01,  5.04] -- $REPLACE_by [0.01,  4.63]\n",
      "Entropy: 0.374745 | Label: the              | $KEEP [0.94,  9.72] -- $DELETE [0.04,  6.50] -- $APPEND_new [0.00,  4.41]\n",
      "Entropy: 0.745810 | Label: mayor            | $KEEP [0.88,  9.12] -- $TRANSFORM_AGREEMENT_PLURAL [0.05,  6.14] -- $TRANSFORM_CASE_CAPITAL [0.02,  5.07]\n",
      "Entropy: 0.749141 | Label: will             | $KEEP [0.88,  9.95] -- $DELETE [0.02,  5.98] -- $REPLACE_would [0.02,  5.92]\n",
      "Entropy: 0.746901 | Label: help             | $KEEP [0.87,  9.45] -- $APPEND_help [0.05,  6.57] -- $REPLACE_help [0.02,  5.81]\n",
      "Entropy: 0.670428 | Label: us               | $KEEP [0.86, 10.12] -- $APPEND_to [0.08,  7.78] -- $DELETE [0.03,  6.83]\n",
      "Entropy: 0.807414 | Label: stop             | $KEEP [0.89,  9.50] -- $REPLACE_reduce [0.02,  5.71] -- $DELETE [0.01,  5.24]\n",
      "Entropy: 0.327975 | Label: pollution        | $KEEP [0.96, 10.35] -- $DELETE [0.01,  5.37] -- $TRANSFORM_AGREEMENT_PLURAL [0.00,  4.78]\n",
      "Entropy: 0.163426 | Label: .                | $KEEP [0.98, 11.10] -- $APPEND_\" [0.00,  5.74] -- $REPLACE_! [0.00,  5.60]\n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m \u001b[32;1m3\u001b[0m  \n",
      "\u001b[37;1mRewards:\u001b[0m 0.000  \n",
      "\u001b[37;1mSource:\u001b[0m $START Unfortunately , there is still a long way to go in terms of environment concerns , but some of the solutions suggested by the mayor will help us stop pollution .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START Unfortunately , there is still a long way to go in terms of environment concerns , but some of the solutions suggested by the mayor will help us stop pollution .  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_dict = dict(\n",
    "    text = \"$START Unfortunately , there is still a long way to do in terms environment concerns , but some of this solutions suggested by the mayor help us stopping the pollution .\",\n",
    "    references = [\n",
    "        \"Unfortunately , there is still a long way to go in terms of environmental concerns , but some of these solutions suggested by the mayor help us stop the pollution .\"\n",
    "    ]\n",
    ")\n",
    "state = env.reset(data_dict=data_dict)\n",
    "done = False\n",
    "while not done:\n",
    "    action = greedy_action(rl_model, state, env.labels, verbose=True)\n",
    "    next_state, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    state = next_state\n",
    "    outputs = env.render()\n",
    "    for o in outputs:\n",
    "        print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ca7094-2523-4467-8031-ca9989334d7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dict = dict(\n",
    "    text = \"$START I think someone should get exercise by starting play some favourite sport instead of watching To or playing game .\",\n",
    "    references = [\n",
    "        \"$START I think people should get exercise by starting to play some favourite sport instead of watching To or playing games .\"\n",
    "    ]\n",
    ")\n",
    "state = env.reset(data_dict=data_dict)\n",
    "done = False\n",
    "while not done:\n",
    "    action = greedy_action(rl_model, state, env.labels, verbose=True)\n",
    "    next_state, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    state = next_state\n",
    "    outputs = env.render()\n",
    "    for o in outputs:\n",
    "        print(o)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drl-gec",
   "language": "python",
   "name": "drl-gec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
