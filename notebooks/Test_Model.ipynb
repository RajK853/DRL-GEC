{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "469c966d-81b5-4cd6-935a-25d77e8a4868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2085486-38df-4b43-b092-f563f06c8ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rajk/Machine_Learning/DRL-GEC\n",
      "/home/rajk/Machine_Learning/DRL-GEC/notebooks\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "import src.envs\n",
    "from src.utils import load_text, apply_labels\n",
    "from src.models.seq2labels import PretrainedEncoder, Seq2Labels\n",
    "%cd notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e197391-3820-41b9-910d-5809a74ab6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d75d2a72-c4bc-409f-8c26-287fcfccc531",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def greedy_action(policy, state, all_labels, verbose=True):\n",
    "    [logits] = policy([state])\n",
    "    top_logits, i = logits.topk(3)\n",
    "    top_logits = top_logits.cpu().numpy()\n",
    "    i = i.cpu().numpy()\n",
    "    dist = Categorical(logits=logits)\n",
    "    top_probs = dist.probs[torch.arange(len(state)).unsqueeze(1), i]\n",
    "    entropy = dist.entropy().cpu().numpy()\n",
    "    if verbose:\n",
    "        for a, e, label_logit_prob in zip(state, entropy, zip(all_labels[i], top_logits, top_probs)):\n",
    "            print(f\"Entropy: {e:4f} | Label: {a:15}  |\", \" -- \".join(f\"{lab} [{prob:3.2f}, {log:5.2f}]\" for (lab, log, prob) in zip(*label_logit_prob)))\n",
    "        print()\n",
    "    action = logits.argmax(axis=-1)\n",
    "    return action.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abb5a4c6-c668-4ef3-89d7-3c47b668bec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path, output_size):\n",
    "    model_name = \"roberta-base\"\n",
    "    encoder = PretrainedEncoder(model_name).to(device)\n",
    "    policy = Seq2Labels(encoder_model=encoder, num_labels=output_size).to(device)\n",
    "    policy.load_state_dict(torch.load(model_path))\n",
    "    policy.eval()\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e4dde0-c3f4-448b-82c0-56c5cfd76c06",
   "metadata": {},
   "source": [
    "# Load Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "359d9b7a-79b0-4ad0-9c64-47d85aee5b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of data in wi+locness: 26815\n",
      "Number of data without correct sentences: 17494\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"wi_locness_gec_lev_dist-v1\", new_step_api=True, correct_examples_percent=[0.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65ea936-90e4-490b-b640-c42caf641a1d",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbb5f929-496e-4094-b422-8bc706d9831d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'roberta.pooler.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'roberta.pooler.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "rl_model_path = os.path.abspath(\"pg_logs/finetune_rl_12_11_2022_11:40/model-last.pt\")\n",
    "sl_model_path = os.path.abspath(\"sl_logs/finetune_wi+locness_02:11:2022_23:06/model-best.pt\")\n",
    "rl_model = load_model(rl_model_path, output_size=len(env.labels))\n",
    "sl_model = load_model(sl_model_path, output_size=len(env.labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e90b34-f61b-454c-bbd4-aac2a0583fe3",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78177cae-217e-49fb-8ae4-bd375c24c8ae",
   "metadata": {},
   "source": [
    "# SL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09ab4c7e-5a4c-47ff-96cc-952eca185852",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 0.533590 | Label: $START           | $KEEP [0.92, 10.03] -- $APPEND_But [0.02,  6.12] -- $APPEND_And [0.01,  5.13]\n",
      "Entropy: 0.337851 | Label: he               | $TRANSFORM_CASE_CAPITAL [0.93, 11.58] -- $KEEP [0.06,  8.82] -- $REPLACE_He [0.00,  6.32]\n",
      "Entropy: 0.871657 | Label: said             | $APPEND_, [0.64, 10.05] -- $KEEP [0.32,  9.38] -- $REPLACE_, [0.01,  5.69]\n",
      "Entropy: 0.779609 | Label: in               | $KEEP [0.81,  9.01] -- $TRANSFORM_CASE_CAPITAL [0.10,  6.89] -- $DELETE [0.07,  6.58]\n",
      "Entropy: 0.595660 | Label: other            | $KEEP [0.87,  9.40] -- $DELETE [0.10,  7.21] -- $MERGE_SPACE [0.00,  4.15]\n",
      "Entropy: 0.896537 | Label: words            | $KEEP [0.64,  9.58] -- $APPEND_, [0.30,  8.84] -- $DELETE [0.05,  6.94]\n",
      "Entropy: 0.789471 | Label: that             | $KEEP [0.77,  9.21] -- $DELETE [0.17,  7.70] -- $REPLACE_, [0.03,  5.89]\n",
      "Entropy: 0.998475 | Label: the              | $DELETE [0.51,  8.31] -- $KEEP [0.45,  8.19] -- $UNKNOWN [0.01,  4.09]\n",
      "Entropy: 0.856027 | Label: more             | $KEEP [0.80,  8.93] -- $DELETE [0.13,  7.12] -- $UNKNOWN [0.02,  5.30]\n",
      "Entropy: 0.916357 | Label: fluoride         | $KEEP [0.84,  8.95] -- $UNKNOWN [0.08,  6.59] -- $APPEND_, [0.01,  4.84]\n",
      "Entropy: 1.235567 | Label: may              | $KEEP [0.68,  8.63] -- $REPLACE_might [0.20,  7.41] -- $REPLACE_could [0.02,  4.97]\n",
      "Entropy: 1.158607 | Label: create           | $KEEP [0.82,  9.16] -- $REPLACE_cause [0.04,  6.09] -- $APPEND_more [0.03,  5.80]\n",
      "Entropy: 0.891328 | Label: damage           | $KEEP [0.83,  9.16] -- $APPEND_to [0.10,  7.00] -- $UNKNOWN [0.01,  5.05]\n",
      "Entropy: 1.151927 | Label: in               | $APPEND_the [0.49, 10.52] -- $REPLACE_to [0.37, 10.24] -- $KEEP [0.10,  8.91]\n",
      "Entropy: 0.985000 | Label: human            | $KEEP [0.78,  8.64] -- $APPEND_'s [0.10,  6.57] -- $TRANSFORM_AGREEMENT_PLURAL [0.04,  5.71]\n",
      "Entropy: 0.821482 | Label: body             | $KEEP [0.83,  9.02] -- $TRANSFORM_VERB_VB_VBZ [0.08,  6.64] -- $DELETE [0.05,  6.17]\n",
      "Entropy: 0.582184 | Label: ,                | $KEEP [0.90,  9.33] -- $APPEND_and [0.04,  6.15] -- $APPEND_, [0.01,  4.95]\n",
      "Entropy: 1.006162 | Label: specifically     | $KEEP [0.82,  8.82] -- $APPEND_, [0.05,  6.00] -- $APPEND_to [0.04,  5.85]\n",
      "Entropy: 0.584729 | Label: the              | $KEEP [0.87,  9.66] -- $DELETE [0.06,  6.99] -- $REPLACE_to [0.05,  6.74]\n",
      "Entropy: 1.280136 | Label: bone             | $TRANSFORM_VERB_VB_VBZ [0.46,  9.23] -- $KEEP [0.35,  8.95] -- $TRANSFORM_AGREEMENT_PLURAL [0.14,  8.00]\n",
      "Entropy: 0.212481 | Label: .                | $KEEP [0.97,  9.51] -- $APPEND_\" [0.01,  4.93] -- $DELETE [0.01,  4.79]\n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 0  \n",
      "\u001b[37;1mRewards:\u001b[0m 0.000  \n",
      "\u001b[37;1mSource:\u001b[0m $START he said in other words that the more fluoride may create damage in human body , specifically the bone .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START he said in other words that the more fluoride may create damage in human body , specifically the bone .  \n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 1  \n",
      "\u001b[37;1mRewards:\u001b[0m 7.000  \n",
      "\u001b[37;1mSource:\u001b[0m $START \u001b[32;1mhe\u001b[0m [\u001b[31;1m$TRANSFORM_CASE_CAPITAL\u001b[0m] \u001b[32;1msaid\u001b[0m [\u001b[31;1m$APPEND_,\u001b[0m] in other words that \u001b[32;1mthe\u001b[0m [\u001b[31;1m$DELETE\u001b[0m] more fluoride may create damage \u001b[32;1min\u001b[0m [\u001b[31;1m$APPEND_the\u001b[0m] human body , specifically the \u001b[32;1mbone\u001b[0m [\u001b[31;1m$TRANSFORM_VERB_VB_VBZ\u001b[0m] .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START He said , in other words that more fluoride may create damage in the human body , specifically the bones .  \n",
      "\n",
      "Entropy: 0.280879 | Label: $START           | $KEEP [0.96, 10.68] -- $APPEND_But [0.01,  5.59] -- $APPEND_The [0.01,  5.44]\n",
      "Entropy: 0.498259 | Label: He               | $KEEP [0.93,  9.67] -- $REPLACE_He [0.02,  5.65] -- $APPEND_also [0.01,  5.23]\n",
      "Entropy: 0.807606 | Label: said             | $KEEP [0.81,  8.84] -- $TRANSFORM_VERB_VBN_VBZ [0.13,  7.04] -- $APPEND_that [0.01,  4.73]\n",
      "Entropy: 0.786212 | Label: ,                | $KEEP [0.74,  8.57] -- $DELETE [0.22,  7.35] -- $REPLACE_. [0.01,  3.98]\n",
      "Entropy: 0.880883 | Label: in               | $KEEP [0.71,  9.20] -- $TRANSFORM_CASE_CAPITAL [0.21,  8.00] -- $DELETE [0.07,  6.87]\n",
      "Entropy: 0.615040 | Label: other            | $KEEP [0.87,  9.33] -- $DELETE [0.10,  7.14] -- $MERGE_SPACE [0.01,  4.32]\n",
      "Entropy: 0.757378 | Label: words            | $APPEND_, [0.62, 10.58] -- $KEEP [0.36, 10.04] -- $DELETE [0.01,  6.47]\n",
      "Entropy: 0.885435 | Label: that             | $KEEP [0.78,  8.99] -- $REPLACE_, [0.11,  7.04] -- $DELETE [0.05,  6.23]\n",
      "Entropy: 1.014177 | Label: more             | $KEEP [0.72,  9.06] -- $DELETE [0.21,  7.84] -- $UNKNOWN [0.01,  5.18]\n",
      "Entropy: 0.809422 | Label: fluoride         | $KEEP [0.84,  9.47] -- $UNKNOWN [0.06,  6.81] -- $APPEND_, [0.05,  6.59]\n",
      "Entropy: 1.237387 | Label: may              | $KEEP [0.66,  8.70] -- $REPLACE_might [0.23,  7.66] -- $REPLACE_could [0.02,  5.22]\n",
      "Entropy: 1.136317 | Label: create           | $KEEP [0.81,  9.27] -- $REPLACE_cause [0.06,  6.71] -- $APPEND_more [0.01,  5.06]\n",
      "Entropy: 0.690814 | Label: damage           | $KEEP [0.90,  9.34] -- $APPEND_to [0.02,  5.61] -- $TRANSFORM_VERB_VB_VBZ [0.02,  5.47]\n",
      "Entropy: 0.924157 | Label: in               | $REPLACE_to [0.60, 10.17] -- $KEEP [0.35,  9.64] -- $REPLACE_on [0.03,  7.06]\n",
      "Entropy: 0.326816 | Label: the              | $KEEP [0.94,  9.77] -- $DELETE [0.03,  6.46] -- $UNKNOWN [0.01,  5.06]\n",
      "Entropy: 0.612387 | Label: human            | $KEEP [0.88,  9.19] -- $APPEND_'s [0.05,  6.41] -- $DELETE [0.02,  5.55]\n",
      "Entropy: 0.606782 | Label: body             | $KEEP [0.90,  9.21] -- $TRANSFORM_VERB_VB_VBZ [0.03,  5.96] -- $DELETE [0.02,  5.54]\n",
      "Entropy: 0.694875 | Label: ,                | $KEEP [0.87,  9.31] -- $APPEND_and [0.06,  6.65] -- $APPEND_, [0.01,  5.14]\n",
      "Entropy: 1.102868 | Label: specifically     | $KEEP [0.80,  8.81] -- $APPEND_to [0.05,  5.95] -- $APPEND_in [0.05,  5.94]\n",
      "Entropy: 0.732912 | Label: the              | $KEEP [0.82,  9.93] -- $REPLACE_to [0.08,  7.64] -- $DELETE [0.07,  7.54]\n",
      "Entropy: 0.596064 | Label: bones            | $KEEP [0.90,  8.77] -- $UNKNOWN [0.04,  5.56] -- $DELETE [0.02,  5.05]\n",
      "Entropy: 0.203664 | Label: .                | $KEEP [0.97,  9.59] -- $APPEND_\" [0.01,  5.40] -- $DELETE [0.00,  4.30]\n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 2  \n",
      "\u001b[37;1mRewards:\u001b[0m 3.000  \n",
      "\u001b[37;1mSource:\u001b[0m $START He said , in other \u001b[32;1mwords\u001b[0m [\u001b[31;1m$APPEND_,\u001b[0m] that more fluoride may create damage \u001b[32;1min\u001b[0m [\u001b[31;1m$REPLACE_to\u001b[0m] the human body , specifically the bones .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START He said , in other words , that more fluoride may create damage to the human body , specifically the bones .  \n",
      "\n",
      "Entropy: 0.233626 | Label: $START           | $KEEP [0.97, 10.99] -- $APPEND_But [0.01,  5.84] -- $APPEND_The [0.00,  5.69]\n",
      "Entropy: 0.512063 | Label: He               | $KEEP [0.92,  9.68] -- $APPEND_has [0.01,  5.49] -- $REPLACE_He [0.01,  5.48]\n",
      "Entropy: 0.774419 | Label: said             | $KEEP [0.78,  9.08] -- $TRANSFORM_VERB_VBN_VBZ [0.18,  7.60] -- $TRANSFORM_VERB_VBN_VB [0.01,  4.14]\n",
      "Entropy: 0.417338 | Label: ,                | $KEEP [0.91,  9.06] -- $DELETE [0.07,  6.44] -- $APPEND_, [0.01,  4.10]\n",
      "Entropy: 0.624958 | Label: in               | $KEEP [0.85,  9.34] -- $TRANSFORM_CASE_CAPITAL [0.08,  6.97] -- $DELETE [0.06,  6.66]\n",
      "Entropy: 0.517128 | Label: other            | $KEEP [0.90,  9.36] -- $DELETE [0.07,  6.87] -- $MERGE_SPACE [0.01,  4.49]\n",
      "Entropy: 0.474720 | Label: words            | $KEEP [0.91,  9.38] -- $DELETE [0.05,  6.55] -- $UNKNOWN [0.01,  4.59]\n",
      "Entropy: 0.451410 | Label: ,                | $KEEP [0.89,  9.44] -- $DELETE [0.09,  7.17] -- $UNKNOWN [0.00,  4.08]\n",
      "Entropy: 0.602944 | Label: that             | $KEEP [0.87,  8.91] -- $DELETE [0.10,  6.71] -- $APPEND_the [0.01,  4.05]\n",
      "Entropy: 1.011901 | Label: more             | $KEEP [0.73,  9.37] -- $DELETE [0.20,  8.10] -- $UNKNOWN [0.02,  5.84]\n",
      "Entropy: 0.819115 | Label: fluoride         | $KEEP [0.84,  9.56] -- $UNKNOWN [0.09,  7.37] -- $TRANSFORM_AGREEMENT_PLURAL [0.02,  5.60]\n",
      "Entropy: 1.238695 | Label: may              | $KEEP [0.63,  8.72] -- $REPLACE_might [0.27,  7.86] -- $REPLACE_could [0.02,  5.35]\n",
      "Entropy: 1.195832 | Label: create           | $KEEP [0.80,  9.11] -- $REPLACE_cause [0.07,  6.63] -- $REPLACE_do [0.01,  4.95]\n",
      "Entropy: 0.535847 | Label: damage           | $KEEP [0.93,  9.35] -- $TRANSFORM_VERB_VB_VBZ [0.01,  5.07] -- $APPEND_to [0.01,  4.96]\n",
      "Entropy: 0.487438 | Label: to               | $KEEP [0.91, 10.16] -- $REPLACE_for [0.02,  6.41] -- $REPLACE_in [0.02,  6.26]\n",
      "Entropy: 0.341052 | Label: the              | $KEEP [0.94,  9.70] -- $DELETE [0.04,  6.58] -- $UNKNOWN [0.01,  4.91]\n",
      "Entropy: 0.574298 | Label: human            | $KEEP [0.89,  9.23] -- $APPEND_'s [0.05,  6.34] -- $DELETE [0.02,  5.58]\n",
      "Entropy: 0.587794 | Label: body             | $KEEP [0.90,  9.22] -- $TRANSFORM_VERB_VB_VBZ [0.03,  5.94] -- $DELETE [0.02,  5.26]\n",
      "Entropy: 0.697921 | Label: ,                | $KEEP [0.86,  9.34] -- $APPEND_and [0.07,  6.81] -- $REPLACE_and [0.01,  5.26]\n",
      "Entropy: 0.888229 | Label: specifically     | $KEEP [0.86,  8.81] -- $APPEND_, [0.04,  5.77] -- $UNKNOWN [0.02,  4.98]\n",
      "Entropy: 0.680712 | Label: the              | $KEEP [0.84,  9.74] -- $DELETE [0.10,  7.59] -- $REPLACE_to [0.03,  6.54]\n",
      "Entropy: 0.584902 | Label: bones            | $KEEP [0.90,  8.79] -- $UNKNOWN [0.03,  5.52] -- $TRANSFORM_VERB_VBZ_VB [0.02,  4.77]\n",
      "Entropy: 0.195644 | Label: .                | $KEEP [0.97,  9.62] -- $APPEND_\" [0.01,  5.37] -- $DELETE [0.00,  4.19]\n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m \u001b[32;1m3\u001b[0m  \n",
      "\u001b[37;1mRewards:\u001b[0m 0.100  \n",
      "\u001b[37;1mSource:\u001b[0m $START He said , in other words , that more fluoride may create damage to the human body , specifically the bones .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START He said , in other words , that more fluoride may create damage to the human body , specifically the bones .  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajk/miniconda3/envs/drl-gec/lib/python3.8/site-packages/gym/core.py:57: DeprecationWarning: \u001b[33mWARN: You are calling render method, but you didn't specified the argument render_mode at environment initialization. To maintain backward compatibility, the environment will render in human mode.\n",
      "If you want to render in human mode, initialize the environment in this way: gym.make('EnvName', render_mode='human') and don't call the render method.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n",
      "/home/rajk/miniconda3/envs/drl-gec/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:297: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "data_dict = dict(\n",
    "    text = \"he said in other words that the more fluoride may create damage in human body , specifically the bone .\",\n",
    "    references = [\n",
    "        \"He said in other words that the more fluoride may create damage in the human body , specifically the bone .\",\n",
    "        \"He said , in other words , that more fluoride may create damage in the human body , specifically the bone .\",\n",
    "        \"He said , in other words , that more fluoride may create damage to the human body , specifically the bones .\",\n",
    "        \"In other words , he said that more fluoride may damage the human body , specifically the bones .\"\n",
    "    ],\n",
    ")\n",
    "state = env.reset(data_dict=data_dict)\n",
    "done = False\n",
    "while not done:\n",
    "    action = greedy_action(sl_model, state, env.labels, verbose=True)\n",
    "    next_state, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    state = next_state\n",
    "    outputs = env.render()\n",
    "    for o in outputs:\n",
    "        print(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039e687c-e3cf-4ef2-987f-63898788dfe6",
   "metadata": {},
   "source": [
    "# RL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9c189a0-5eed-4b6a-af18-a43437147161",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 0.645639 | Label: $START           | $KEEP [0.91,  9.74] -- $APPEND_But [0.02,  5.96] -- $APPEND_The [0.01,  5.17]\n",
      "Entropy: 1.304728 | Label: he               | $TRANSFORM_CASE_CAPITAL [0.60, 10.71] -- $REPLACE_He [0.23,  9.77] -- $KEEP [0.06,  8.48]\n",
      "Entropy: 1.088627 | Label: said             | $KEEP [0.60,  9.10] -- $APPEND_, [0.32,  8.48] -- $DELETE [0.02,  5.81]\n",
      "Entropy: 1.227594 | Label: in               | $KEEP [0.72,  8.87] -- $TRANSFORM_CASE_CAPITAL [0.08,  6.72] -- $REPLACE_In [0.08,  6.67]\n",
      "Entropy: 0.718042 | Label: other            | $KEEP [0.85,  9.28] -- $DELETE [0.09,  7.05] -- $APPEND_other [0.01,  4.63]\n",
      "Entropy: 0.825542 | Label: words            | $KEEP [0.69,  9.62] -- $APPEND_, [0.27,  8.69] -- $DELETE [0.02,  6.14]\n",
      "Entropy: 0.767806 | Label: that             | $KEEP [0.81,  9.25] -- $DELETE [0.12,  7.31] -- $APPEND_, [0.03,  5.93]\n",
      "Entropy: 0.995892 | Label: the              | $KEEP [0.58,  8.18] -- $DELETE [0.39,  7.78] -- $APPEND_more [0.00,  2.72]\n",
      "Entropy: 0.712402 | Label: more             | $KEEP [0.88,  8.87] -- $DELETE [0.06,  6.22] -- $APPEND_of [0.01,  4.57]\n",
      "Entropy: 0.593345 | Label: fluoride         | $KEEP [0.92,  9.01] -- $APPEND_, [0.02,  5.27] -- $DELETE [0.01,  4.58]\n",
      "Entropy: 0.927542 | Label: may              | $KEEP [0.79,  9.06] -- $REPLACE_might [0.13,  7.24] -- $REPLACE_would [0.02,  5.19]\n",
      "Entropy: 0.994487 | Label: create           | $KEEP [0.85,  9.17] -- $APPEND_more [0.03,  5.93] -- $REPLACE_cause [0.03,  5.83]\n",
      "Entropy: 0.855943 | Label: damage           | $KEEP [0.84,  9.12] -- $APPEND_to [0.09,  6.86] -- $DELETE [0.02,  5.25]\n",
      "Entropy: 1.306791 | Label: in               | $APPEND_the [0.46,  9.85] -- $REPLACE_to [0.27,  9.33] -- $KEEP [0.22,  9.09]\n",
      "Entropy: 0.956524 | Label: human            | $KEEP [0.77,  9.00] -- $APPEND_'s [0.13,  7.21] -- $REPLACE_the [0.05,  6.22]\n",
      "Entropy: 0.634629 | Label: body             | $KEEP [0.89,  9.51] -- $DELETE [0.05,  6.55] -- $TRANSFORM_VERB_VB_VBZ [0.03,  5.95]\n",
      "Entropy: 0.401306 | Label: ,                | $KEEP [0.93,  9.93] -- $APPEND_and [0.03,  6.40] -- $APPEND_, [0.01,  5.56]\n",
      "Entropy: 0.710660 | Label: specifically     | $KEEP [0.86,  9.56] -- $APPEND_, [0.07,  7.11] -- $APPEND_to [0.02,  5.75]\n",
      "Entropy: 0.361778 | Label: the              | $KEEP [0.94,  9.91] -- $DELETE [0.02,  6.20] -- $REPLACE_to [0.02,  5.90]\n",
      "Entropy: 1.171850 | Label: bone             | $KEEP [0.52,  9.18] -- $TRANSFORM_AGREEMENT_PLURAL [0.34,  8.76] -- $TRANSFORM_VERB_VB_VBZ [0.11,  7.57]\n",
      "Entropy: 0.216760 | Label: .                | $KEEP [0.97,  9.73] -- $APPEND_\" [0.01,  5.21] -- $DELETE [0.00,  4.45]\n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 0  \n",
      "\u001b[37;1mRewards:\u001b[0m 0.000  \n",
      "\u001b[37;1mSource:\u001b[0m $START he said in other words that the more fluoride may create damage in human body , specifically the bone .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START he said in other words that the more fluoride may create damage in human body , specifically the bone .  \n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 1  \n",
      "\u001b[37;1mRewards:\u001b[0m 3.000  \n",
      "\u001b[37;1mSource:\u001b[0m $START \u001b[32;1mhe\u001b[0m [\u001b[31;1m$TRANSFORM_CASE_CAPITAL\u001b[0m] said in other words that the more fluoride may create damage \u001b[32;1min\u001b[0m [\u001b[31;1m$APPEND_the\u001b[0m] human body , specifically the bone .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START He said in other words that the more fluoride may create damage in the human body , specifically the bone .  \n",
      "\n",
      "Entropy: 0.323165 | Label: $START           | $KEEP [0.96, 10.11] -- $APPEND_But [0.01,  5.16] -- $APPEND_The [0.01,  5.05]\n",
      "Entropy: 0.550969 | Label: He               | $KEEP [0.91,  9.58] -- $REPLACE_He [0.04,  6.33] -- $DELETE [0.01,  4.79]\n",
      "Entropy: 0.992167 | Label: said             | $KEEP [0.52,  9.37] -- $APPEND_, [0.43,  9.16] -- $REPLACE_, [0.02,  6.07]\n",
      "Entropy: 1.018235 | Label: in               | $KEEP [0.80,  8.73] -- $REPLACE_in [0.04,  5.74] -- $REPLACE_In [0.04,  5.73]\n",
      "Entropy: 0.718448 | Label: other            | $KEEP [0.86,  9.24] -- $DELETE [0.09,  6.98] -- $REPLACE_other [0.01,  4.72]\n",
      "Entropy: 0.871608 | Label: words            | $KEEP [0.68,  9.45] -- $APPEND_, [0.28,  8.56] -- $DELETE [0.02,  6.12]\n",
      "Entropy: 0.749843 | Label: that             | $KEEP [0.82,  9.26] -- $DELETE [0.11,  7.27] -- $APPEND_, [0.03,  5.85]\n",
      "Entropy: 1.063385 | Label: the              | $KEEP [0.54,  8.06] -- $DELETE [0.42,  7.81] -- $APPEND_more [0.00,  2.87]\n",
      "Entropy: 0.767928 | Label: more             | $KEEP [0.87,  8.79] -- $DELETE [0.06,  6.19] -- $APPEND_of [0.01,  4.55]\n",
      "Entropy: 0.636111 | Label: fluoride         | $KEEP [0.91,  9.01] -- $APPEND_, [0.02,  5.31] -- $DELETE [0.01,  4.59]\n",
      "Entropy: 1.001073 | Label: may              | $KEEP [0.76,  9.04] -- $REPLACE_might [0.16,  7.46] -- $REPLACE_would [0.02,  5.29]\n",
      "Entropy: 1.078544 | Label: create           | $KEEP [0.83,  9.13] -- $REPLACE_cause [0.04,  6.19] -- $APPEND_more [0.03,  5.81]\n",
      "Entropy: 0.714774 | Label: damage           | $KEEP [0.90,  9.17] -- $APPEND_to [0.03,  5.72] -- $DELETE [0.02,  5.18]\n",
      "Entropy: 1.057006 | Label: in               | $REPLACE_to [0.47,  9.34] -- $KEEP [0.46,  9.31] -- $REPLACE_on [0.02,  6.35]\n",
      "Entropy: 0.299218 | Label: the              | $KEEP [0.95,  9.87] -- $DELETE [0.03,  6.49] -- $REPLACE_to [0.00,  4.51]\n",
      "Entropy: 0.629382 | Label: human            | $KEEP [0.87,  9.50] -- $APPEND_'s [0.08,  7.08] -- $DELETE [0.03,  6.24]\n",
      "Entropy: 0.402242 | Label: body             | $KEEP [0.94,  9.71] -- $DELETE [0.02,  5.97] -- $TRANSFORM_VERB_VB_VBZ [0.01,  5.07]\n",
      "Entropy: 0.444158 | Label: ,                | $KEEP [0.92,  9.90] -- $APPEND_and [0.03,  6.57] -- $APPEND_, [0.01,  5.58]\n",
      "Entropy: 0.798853 | Label: specifically     | $KEEP [0.84,  9.47] -- $APPEND_, [0.08,  7.14] -- $APPEND_in [0.02,  5.93]\n",
      "Entropy: 0.353568 | Label: the              | $KEEP [0.94,  9.89] -- $DELETE [0.02,  6.14] -- $REPLACE_to [0.01,  5.68]\n",
      "Entropy: 1.207834 | Label: bone             | $TRANSFORM_AGREEMENT_PLURAL [0.45,  9.22] -- $KEEP [0.41,  9.13] -- $TRANSFORM_VERB_VB_VBZ [0.12,  7.95]\n",
      "Entropy: 0.196409 | Label: .                | $KEEP [0.97,  9.73] -- $APPEND_\" [0.01,  5.28] -- $DELETE [0.00,  4.11]\n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 2  \n",
      "\u001b[37;1mRewards:\u001b[0m 4.000  \n",
      "\u001b[37;1mSource:\u001b[0m $START He said in other words that the more fluoride may create damage \u001b[32;1min\u001b[0m [\u001b[31;1m$REPLACE_to\u001b[0m] the human body , specifically the \u001b[32;1mbone\u001b[0m [\u001b[31;1m$TRANSFORM_AGREEMENT_PLURAL\u001b[0m] .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START He said in other words that the more fluoride may create damage to the human body , specifically the bones .  \n",
      "\n",
      "Entropy: 0.320033 | Label: $START           | $KEEP [0.96, 10.14] -- $APPEND_But [0.01,  5.20] -- $APPEND_The [0.01,  5.07]\n",
      "Entropy: 0.560606 | Label: He               | $KEEP [0.91,  9.54] -- $REPLACE_He [0.03,  6.25] -- $DELETE [0.01,  4.81]\n",
      "Entropy: 0.994222 | Label: said             | $KEEP [0.52,  9.34] -- $APPEND_, [0.43,  9.15] -- $REPLACE_, [0.02,  6.07]\n",
      "Entropy: 1.004716 | Label: in               | $KEEP [0.81,  8.70] -- $DELETE [0.04,  5.67] -- $REPLACE_in [0.04,  5.67]\n",
      "Entropy: 0.730489 | Label: other            | $KEEP [0.85,  9.22] -- $DELETE [0.09,  6.97] -- $REPLACE_other [0.01,  4.77]\n",
      "Entropy: 0.876338 | Label: words            | $KEEP [0.68,  9.43] -- $APPEND_, [0.28,  8.53] -- $DELETE [0.02,  6.12]\n",
      "Entropy: 0.742001 | Label: that             | $KEEP [0.82,  9.26] -- $DELETE [0.11,  7.25] -- $APPEND_, [0.03,  5.84]\n",
      "Entropy: 1.075520 | Label: the              | $KEEP [0.53,  8.03] -- $DELETE [0.43,  7.81] -- $APPEND_more [0.00,  2.89]\n",
      "Entropy: 0.779006 | Label: more             | $KEEP [0.87,  8.77] -- $DELETE [0.06,  6.13] -- $APPEND_of [0.01,  4.59]\n",
      "Entropy: 0.646254 | Label: fluoride         | $KEEP [0.91,  9.00] -- $APPEND_, [0.02,  5.38] -- $DELETE [0.01,  4.60]\n",
      "Entropy: 1.034205 | Label: may              | $KEEP [0.74,  9.02] -- $REPLACE_might [0.17,  7.54] -- $REPLACE_would [0.02,  5.54]\n",
      "Entropy: 1.137613 | Label: create           | $KEEP [0.82,  8.97] -- $REPLACE_cause [0.04,  6.06] -- $APPEND_more [0.03,  5.50]\n",
      "Entropy: 0.498967 | Label: damage           | $KEEP [0.94,  9.31] -- $DELETE [0.01,  5.11] -- $APPEND_to [0.01,  4.98]\n",
      "Entropy: 0.438135 | Label: to               | $KEEP [0.93,  9.90] -- $DELETE [0.02,  5.95] -- $REPLACE_to [0.01,  5.76]\n",
      "Entropy: 0.265505 | Label: the              | $KEEP [0.95,  9.92] -- $DELETE [0.04,  6.66] -- $APPEND_whole [0.00,  3.74]\n",
      "Entropy: 0.570896 | Label: human            | $KEEP [0.88,  9.58] -- $APPEND_'s [0.07,  7.10] -- $DELETE [0.03,  6.06]\n",
      "Entropy: 0.392099 | Label: body             | $KEEP [0.94,  9.78] -- $DELETE [0.01,  5.63] -- $TRANSFORM_VERB_VB_VBZ [0.01,  5.46]\n",
      "Entropy: 0.498970 | Label: ,                | $KEEP [0.91,  9.85] -- $APPEND_and [0.05,  6.88] -- $APPEND_, [0.01,  5.44]\n",
      "Entropy: 0.644223 | Label: specifically     | $KEEP [0.88,  9.42] -- $APPEND_, [0.08,  7.06] -- $APPEND_in [0.00,  4.11]\n",
      "Entropy: 0.480226 | Label: the              | $KEEP [0.91,  9.81] -- $DELETE [0.05,  6.91] -- $REPLACE_its [0.02,  5.84]\n",
      "Entropy: 0.398118 | Label: bones            | $KEEP [0.95,  9.03] -- $DELETE [0.01,  4.69] -- $TRANSFORM_AGREEMENT_SINGULAR [0.01,  4.62]\n",
      "Entropy: 0.195183 | Label: .                | $KEEP [0.97,  9.79] -- $APPEND_\" [0.01,  5.46] -- $DELETE [0.00,  3.97]\n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m \u001b[32;1m3\u001b[0m  \n",
      "\u001b[37;1mRewards:\u001b[0m 0.000  \n",
      "\u001b[37;1mSource:\u001b[0m $START He said in other words that the more fluoride may create damage to the human body , specifically the bones .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START He said in other words that the more fluoride may create damage to the human body , specifically the bones .  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_dict = dict(\n",
    "    text = \"he said in other words that the more fluoride may create damage in human body , specifically the bone .\",\n",
    "    references = [\n",
    "        \"He said in other words that the more fluoride may create damage in the human body , specifically the bone .\",\n",
    "        \"He said , in other words , that more fluoride may create damage in the human body , specifically the bone .\",\n",
    "        \"He said , in other words , that more fluoride may create damage to the human body , specifically the bones .\",\n",
    "        \"In other words , he said that more fluoride may damage the human body , specifically the bones .\"\n",
    "    ]\n",
    ")\n",
    "state = env.reset(data_dict=data_dict)\n",
    "done = False\n",
    "while not done:\n",
    "    action = greedy_action(rl_model, state, env.labels, verbose=True)\n",
    "    next_state, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    state = next_state\n",
    "    outputs = env.render()\n",
    "    for o in outputs:\n",
    "        print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef0b51f-fe31-4692-aa37-de76183337ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39a596d1-45be-4c6e-b653-d081fe0de809",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37;1mTimestep:\u001b[0m 0  \n",
      "\u001b[37;1mRewards:\u001b[0m 0.348  \n",
      "\u001b[37;1mSource:\u001b[0m $START Tigers \u001b[32;1mis\u001b[0m [\u001b[31;1m$REPLACE_are\u001b[0m] cold blooded animals .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START Tigers are cold blooded animals .  \n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 1  \n",
      "\u001b[37;1mRewards:\u001b[0m -0.007  \n",
      "\u001b[37;1mSource:\u001b[0m $START Tigers are \u001b[32;1mcold\u001b[0m [\u001b[31;1m$APPEND_-\u001b[0m] blooded animals .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START Tigers are cold - blooded animals .  \n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 2  \n",
      "\u001b[37;1mRewards:\u001b[0m -0.100  \n",
      "\u001b[37;1mSource:\u001b[0m $START Tigers are cold - blooded animals .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START Tigers are cold - blooded animals .  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"Tigers is cold blooded animals .\"\n",
    "references = [\n",
    "    \"Tigers are cold-blooded animals .\",\n",
    "    \"Tigers is a cold-blooded animal .\",\n",
    "]\n",
    "for i in range(3):\n",
    "    action = greedy_action(sl_model, state, env.labels, verbose=False)\n",
    "    labels = env.labels[action]\n",
    "    new_state = apply_labels(state, labels)\n",
    "    reward = env.compute_reward(state, new_state, references)\n",
    "    output = env.render_text(state, labels, reward, new_state, i)\n",
    "    state = new_state\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24090f68-fb9f-4a19-a951-83d704e87e89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37;1mTimestep:\u001b[0m 0  \n",
      "\u001b[37;1mRewards:\u001b[0m 0.139  \n",
      "\u001b[37;1mSource:\u001b[0m $START Tigers \u001b[32;1mis\u001b[0m [\u001b[31;1m$REPLACE_are\u001b[0m] \u001b[32;1mcold\u001b[0m [\u001b[31;1m$APPEND_-\u001b[0m] blooded animals .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START Tigers are cold - blooded animals .  \n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 1  \n",
      "\u001b[37;1mRewards:\u001b[0m -0.100  \n",
      "\u001b[37;1mSource:\u001b[0m $START Tigers are cold - blooded animals .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START Tigers are cold - blooded animals .  \n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 2  \n",
      "\u001b[37;1mRewards:\u001b[0m -0.100  \n",
      "\u001b[37;1mSource:\u001b[0m $START Tigers are cold - blooded animals .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START Tigers are cold - blooded animals .  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"Tigers is cold blooded animals .\"\n",
    "references = [\n",
    "    \"Tigers are cold-blooded animals .\",\n",
    "    \"Tigers is a cold-blooded animal .\",\n",
    "]\n",
    "for i in range(3):\n",
    "    action = greedy_action(rl_model, state, env.labels, verbose=False)\n",
    "    labels = env.labels[action]\n",
    "    new_state = apply_labels(state, labels)\n",
    "    reward = env.compute_reward(state, new_state, references)\n",
    "    output = env.render_text(state, labels, reward, new_state, i)\n",
    "    state = new_state\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab85280-e067-4699-b794-4f1f4f9e11a9",
   "metadata": {},
   "source": [
    "# Model scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cd11584-68d0-41ac-a14f-9bfdcc7b399a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b5740_row1_col2, #T_b5740_row1_col3, #T_b5740_row2_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b5740\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b5740_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_b5740_level0_col1\" class=\"col_heading level0 col1\" >Precision</th>\n",
       "      <th id=\"T_b5740_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_b5740_level0_col3\" class=\"col_heading level0 col3\" >F-0.5 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b5740_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b5740_row0_col0\" class=\"data row0 col0\" >Pretrain</td>\n",
       "      <td id=\"T_b5740_row0_col1\" class=\"data row0 col1\" >0.6074</td>\n",
       "      <td id=\"T_b5740_row0_col2\" class=\"data row0 col2\" >0.2958</td>\n",
       "      <td id=\"T_b5740_row0_col3\" class=\"data row0 col3\" >0.5017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5740_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b5740_row1_col0\" class=\"data row1 col0\" >Pretrain + SL Fine-Tune</td>\n",
       "      <td id=\"T_b5740_row1_col1\" class=\"data row1 col1\" >0.6561</td>\n",
       "      <td id=\"T_b5740_row1_col2\" class=\"data row1 col2\" >0.4372</td>\n",
       "      <td id=\"T_b5740_row1_col3\" class=\"data row1 col3\" >0.5964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5740_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b5740_row2_col0\" class=\"data row2 col0\" >Pretrain + RL Fine-Tune</td>\n",
       "      <td id=\"T_b5740_row2_col1\" class=\"data row2 col1\" >0.6890</td>\n",
       "      <td id=\"T_b5740_row2_col2\" class=\"data row2 col2\" >0.3784</td>\n",
       "      <td id=\"T_b5740_row2_col3\" class=\"data row2 col3\" >0.5918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5740_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_b5740_row3_col0\" class=\"data row3 col0\" >Pretrain + SL Fine-Tune + RL Fine-Tune</td>\n",
       "      <td id=\"T_b5740_row3_col1\" class=\"data row3 col1\" >0.6842</td>\n",
       "      <td id=\"T_b5740_row3_col2\" class=\"data row3 col2\" >0.3593</td>\n",
       "      <td id=\"T_b5740_row3_col3\" class=\"data row3 col3\" >0.5794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f2676798310>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict = {\n",
    "    \"Pretrain\": os.path.abspath(\"sl_logs/pretrain_synthetic_18:10:2022_13:59/\"),\n",
    "    \"Pretrain + SL Fine-Tune\": os.path.abspath(\"sl_logs/finetune_wi+locness_18:10:2022_21:42\"),\n",
    "    \"Pretrain + RL Fine-Tune\": os.path.abspath(\"pg_logs/finetune_rl_22_10_2022_01:15\"),\n",
    "    \"Pretrain + SL Fine-Tune + RL Fine-Tune\": os.path.abspath(\"pg_logs/finetune_rl_23_10_2022_00:33\"),\n",
    "}\n",
    "\n",
    "results = []\n",
    "for model_name, model_path in model_dict.items():\n",
    "    dataset_path = os.path.join(model_path, \"conll\", \"conll_test.score\")\n",
    "    data = load_text(dataset_path)\n",
    "    p, r, f = (line.split(\": \")[1] for line in data[-3:])\n",
    "    results.append({\"Model\": model_name, \"Precision\": p, \"Recall\": r, \"F-0.5 Score\": f})\n",
    "conll_df = pd.DataFrame(results)\n",
    "conll_df.style.highlight_max(subset=[\"Precision\", \"Recall\", \"F-0.5 Score\"], color='lightgreen', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acc9ef84-308c-4774-bbfe-0be4d505b397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_21c96_row1_col1, #T_21c96_row1_col2 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_21c96\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_21c96_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_21c96_level0_col1\" class=\"col_heading level0 col1\" >Dev Score</th>\n",
       "      <th id=\"T_21c96_level0_col2\" class=\"col_heading level0 col2\" >Test Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_21c96_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_21c96_row0_col0\" class=\"data row0 col0\" >Pretrain</td>\n",
       "      <td id=\"T_21c96_row0_col1\" class=\"data row0 col1\" >0.511410</td>\n",
       "      <td id=\"T_21c96_row0_col2\" class=\"data row0 col2\" >0.538118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_21c96_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_21c96_row1_col0\" class=\"data row1 col0\" >Pretrain + SL Fine-Tune</td>\n",
       "      <td id=\"T_21c96_row1_col1\" class=\"data row1 col1\" >0.543455</td>\n",
       "      <td id=\"T_21c96_row1_col2\" class=\"data row1 col2\" >0.590690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_21c96_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_21c96_row2_col0\" class=\"data row2 col0\" >Pretrain + RL Fine-Tune</td>\n",
       "      <td id=\"T_21c96_row2_col1\" class=\"data row2 col1\" >0.532699</td>\n",
       "      <td id=\"T_21c96_row2_col2\" class=\"data row2 col2\" >0.576475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_21c96_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_21c96_row3_col0\" class=\"data row3 col0\" >Pretrain + SL Fine-Tune + RL Fine-Tune</td>\n",
       "      <td id=\"T_21c96_row3_col1\" class=\"data row3 col1\" >0.528306</td>\n",
       "      <td id=\"T_21c96_row3_col2\" class=\"data row3 col2\" >0.575681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f277056ab80>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict = {\n",
    "    \"Pretrain\": os.path.abspath(\"sl_logs/pretrain_synthetic_18:10:2022_13:59/\"),\n",
    "    \"Pretrain + SL Fine-Tune\": os.path.abspath(\"sl_logs/finetune_wi+locness_18:10:2022_21:42\"),\n",
    "    \"Pretrain + RL Fine-Tune\": os.path.abspath(\"pg_logs/finetune_rl_22_10_2022_01:15\"),\n",
    "    \"Pretrain + SL Fine-Tune + RL Fine-Tune\": os.path.abspath(\"pg_logs/finetune_rl_23_10_2022_00:33\"),\n",
    "}\n",
    "\n",
    "results = []\n",
    "for model_name, model_path in model_dict.items():\n",
    "    model_dict = {\"Model\": model_name}\n",
    "    for score_type in (\"dev\", \"test\"):\n",
    "        dataset_path = os.path.join(model_path, \"jfleg\", f\"jfleg_{score_type}.score\")\n",
    "        data = load_text(dataset_path)\n",
    "        score_list = eval(data[-1])\n",
    "        model_dict[f\"{score_type.title()} Score\"] = score_list[0][0]\n",
    "    results.append(model_dict)\n",
    "jfleg_df = pd.DataFrame(results)\n",
    "jfleg_df.style.highlight_max(subset=[\"Dev Score\", \"Test Score\"], color='lightgreen', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b78ffb-84af-4df2-8fe6-bc9b594bb89a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drl-gec",
   "language": "python",
   "name": "drl-gec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
