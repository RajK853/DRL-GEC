{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c01e920-068e-46e2-a6c8-eecadfd63987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdd9fa98-d239-422c-9bcc-4f384f13cf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2edf823-39a1-43b6-ac3e-75942f368fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rajk/Machine_Learning/DRL-GEC\n",
      "/home/rajk/Machine_Learning/DRL-GEC/notebooks\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "from src import envs\n",
    "from src.sl.losses import FocalLoss\n",
    "from src.sl.dataset import GECDataset\n",
    "from src.sl.utils import process_data, collate_func\n",
    "from src.models.seq2labels import PretrainedEncoder, Seq2Labels\n",
    "from src.utils import load_text, write_json, freeze_params, is_gce_instance\n",
    "%cd notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9a87287-3b10-412a-a3db-f9fe8db5b07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29f1639-0284-467f-970d-bd9c37483731",
   "metadata": {},
   "source": [
    "# Local Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e2390b2-9339-49bf-b835-3a4d5c925cd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.cuda.amp.autocast()\n",
    "def evaluate(model, batch, criterion):\n",
    "    masks = torch.from_numpy(batch[\"masks\"]).to(device)\n",
    "    labels = torch.from_numpy(batch['labels']).to(device)\n",
    "    logits = model(tokens=batch['tokens'])\n",
    "    batch_size, seq_size, labels_size = logits.shape\n",
    "    loss = criterion(logits.view(-1, labels_size), labels.view(-1))\n",
    "    loss = loss.view(batch_size, seq_size).sum(dim=-1)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef892698-34d8-4e41-9d13-8c8cd752a8e3",
   "metadata": {},
   "source": [
    "# Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5941764f-acfa-4d42-93de-5a813a4b23b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cold_lr = 1e-3\n",
    "warm_lr = 1e-5\n",
    "lr = cold_lr\n",
    "dropout = 0.1\n",
    "num_epochs = 20\n",
    "cold_epochs = 0\n",
    "patience = 3\n",
    "batch_size = 64\n",
    "accumulation_size = 4\n",
    "weight_decay = 0\n",
    "data_limit = 500_000\n",
    "keep_corrects = True\n",
    "num_unfreeze_layers = 0\n",
    "train_datasets = [\"wi+locness\"]\n",
    "val_datasets = [\"wi+locness\"]\n",
    "current_datetime = datetime.now().strftime(\"%d:%m:%Y_%H:%M\")\n",
    "model_path = \"sl_logs/pretrain_synthetic_31:10:2022_09:39/model-best.pt\"\n",
    "train_type = \"pretrain\" if model_path is None else \"finetune\"\n",
    "log_dir = os.path.join(\"sl_logs\", f\"{train_type}_{'-'.join(train_datasets)}_{current_datetime}\")\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "meta_data = {\n",
    "    \"description\": \"\"\"\n",
    "    Finetune on WI+Locness data.\n",
    "    Use Focal Loss.\n",
    "    Use Unknown label\n",
    "    \"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52b1be0-19f0-4dcc-a626-f09b038454d3",
   "metadata": {},
   "source": [
    "# Load label vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f400ab5-4c30-4293-a25c-d5ade22bc887",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = \"../data/vocabs/labels.txt\"\n",
    "label_vocab = load_text(label_path)\n",
    "label2index = {label:i for i, label in enumerate(label_vocab)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2650cbc6-7d5a-4f3d-a98e-e069507633a8",
   "metadata": {},
   "source": [
    "# Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bf1337b-ed98-4cf7-81e7-88e4de6fa94d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31381765b82d42fe9a74d72273047487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading datasets:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sentences: 53864\n"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "for dataset in tqdm(train_datasets, desc=\"Loading datasets\", total=len(train_datasets)):\n",
    "    data_path = f\"../data/processed/{dataset}/data.gector\"\n",
    "    train_data.extend(load_text(data_path))\n",
    "if (data_limit > 0) and (len(train_data) > data_limit):\n",
    "    print(f\"Truncating amount of data from {len(train_data)} to {data_limit}\")\n",
    "    train_data = train_data[:data_limit]\n",
    "print(f\"Total number of sentences: {len(train_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa24a1f9-07ce-4510-aac9-0513ffed1b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a581437614b048e9ae582db3641fa276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading datasets:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sentences: 14392\n"
     ]
    }
   ],
   "source": [
    "dev_data = []\n",
    "for dataset in tqdm(val_datasets, desc=\"Loading datasets\", total=len(val_datasets)):\n",
    "    data_path = f\"../data/processed/{dataset}/dev.gector\"\n",
    "    dev_data.extend(load_text(data_path))\n",
    "print(f\"Total number of sentences: {len(dev_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8f4291-ca79-45be-a1cc-4d447d4bc0f7",
   "metadata": {},
   "source": [
    "# Extract tokens and labels from the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d8efd7c-a3e4-481b-82af-36780efdd260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11bd76729e9b41229a7ca4122e9650d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing data:   0%|          | 0/53864 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of data after filtering: 53864\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15dd191fefdf438e88ddad3904abb2ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing data:   0%|          | 0/14392 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of data after filtering: 14392\n"
     ]
    }
   ],
   "source": [
    "train_tokens, train_labels = process_data(train_data, label_vocab, keep_corrects=keep_corrects)\n",
    "dev_tokens, dev_labels = process_data(dev_data, label_vocab, keep_corrects=True)\n",
    "train_dataset = GECDataset(train_tokens, train_labels, label2index)\n",
    "dev_dataset = GECDataset(dev_tokens, dev_labels, label2index)\n",
    "train_loader = DataLoader(train_dataset, batch_size=int(batch_size/accumulation_size), shuffle=True, num_workers=4, collate_fn=collate_func)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False, num_workers=4, collate_fn=collate_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f4a8be0-5db7-480a-be00-6834e5cf8c16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_name = \"roberta-base\"\n",
    "tokenizer_config = {\"use_fast\": True}\n",
    "transformer_config = {\"output_attentions\": False}\n",
    "\n",
    "encoder = PretrainedEncoder(model_name, tokenizer_config, transformer_config).to(device)\n",
    "model = Seq2Labels(encoder_model=encoder, num_labels=len(label_vocab), dropout=dropout).to(device)\n",
    "if model_path:\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "criterion = FocalLoss(alpha=0.25, gamma=2.0, reduction=\"none\")\n",
    "# criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "grad_scaler = torch.cuda.amp.GradScaler()\n",
    "write_json(os.path.join(log_dir, \"meta.json\"), meta_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d39dff37-8de5-41fa-971c-55d2294685f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frozen parameters: 197/197\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93a3284cbbb94dd3915e0bb7519ef6f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frozen parameters: 0/197\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdc7ba09cb5741e0828850c593c24064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/3367 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44a1645aa766406fbc4b6aa1d4972bae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/3367 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "289274a85e344c8b8280afa574855a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/3367 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "783c32a105544091935e21cc1f2a3564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/3367 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebb4639833ee426380b7473f78accca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/3367 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping!\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "optim.zero_grad()\n",
    "N = len(train_loader)\n",
    "freeze_params(model.encoder, requires_grad=False)    # Freeze encoder model\n",
    "# Log hyperparameters\n",
    "writer.add_scalar(\"hyperparameters/dropout\", dropout, 0)\n",
    "writer.add_scalar(\"hyperparameters/patience\", patience, 0)\n",
    "writer.add_scalar(\"hyperparameters/batch_size\", batch_size, 0)\n",
    "writer.add_scalar(\"hyperparameters/cold_epochs\", cold_epochs, 0)\n",
    "writer.add_scalar(\"hyperparameters/weight_decay\", weight_decay, 0)\n",
    "writer.add_scalar(\"hyperparameters/keep_corrects\", int(keep_corrects), 0)\n",
    "writer.add_scalar(\"hyperparameters/accumulation_size\", accumulation_size, 0)\n",
    "writer.add_scalar(\"hyperparameters/num_unfreeze_layers\", num_unfreeze_layers, 0)\n",
    "writer.add_scalar(\"hyperparameters/uses_CE_loss\", int(isinstance(criterion, nn.CrossEntropyLoss)), 0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    dev_losses = [evaluate(model, batch, criterion) for batch in dev_loader]\n",
    "    dev_loss = torch.cat(dev_losses).mean()\n",
    "    writer.add_scalar(\"sl/validation_loss\", dev_loss, 0)\n",
    "\n",
    "epochs_since_improvement = 0\n",
    "best_dev_score = dev_loss\n",
    "for epoch in tqdm(range(num_epochs), desc=\"Training\", total=num_epochs):\n",
    "    if epoch == cold_epochs:                                                                                  # End of the cold epochs\n",
    "        lr = warm_lr\n",
    "        freeze_params(model.encoder, requires_grad=True, num_layers=num_unfreeze_layers, optim=optim, lr=lr)  # Unfreeze encoder model\n",
    "        if cold_epochs > 0:                                                                                   # Save model after the cold epochs\n",
    "            torch.save(model.state_dict(), os.path.join(log_dir, \"model-cold.pt\"))\n",
    "    \n",
    "    step_offset = epoch*N\n",
    "    for i, batch in tqdm(enumerate(train_loader), desc=f\"Epoch {epoch+1}\", total=len(train_loader)):\n",
    "        loss = evaluate(model, batch, criterion)\n",
    "        loss = loss.mean()\n",
    "        grad_scaler.scale(loss/accumulation_size).backward()\n",
    "        if ((i+1) % accumulation_size) == 0:\n",
    "            grad_scaler.step(optim)\n",
    "            grad_scaler.update()\n",
    "            optim.zero_grad()\n",
    "            torch.cuda.empty_cache()\n",
    "        writer.add_scalar(\"sl/lr\", lr, step_offset + i)\n",
    "        writer.add_scalar(\"sl/train_loss\", loss, step_offset + i)\n",
    "    with torch.no_grad():\n",
    "        dev_losses = [evaluate(model, batch, criterion) for batch in dev_loader]\n",
    "    dev_loss = torch.cat(dev_losses).mean()\n",
    "    writer.add_scalar(\"sl/validation_loss\", dev_loss, step_offset + i)\n",
    "    if dev_loss <= best_dev_score:\n",
    "        best_dev_score = dev_loss\n",
    "        epochs_since_improvement = 0\n",
    "        torch.save(model.state_dict(), os.path.join(log_dir, \"model-best.pt\"))     # Save best model \n",
    "    else:\n",
    "        epochs_since_improvement += 1\n",
    "        if epochs_since_improvement >= patience:\n",
    "            print(\"Early stopping!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0eefa210-1b3e-428a-9bc8-4d4863a2c162",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), os.path.join(log_dir, \"model-last.pt\"))                 # Save last model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34dce900-e82c-47b4-a879-86db15ed7b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd004af7-e6ed-4d39-ac76-911a517c1f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of data in wi+locness: 26815\n",
      "Number of data without correct sentences: 17494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajk/miniconda3/envs/drl-gec/lib/python3.8/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/rajk/miniconda3/envs/drl-gec/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"wi_locness_gec_lev_dist-v0\", correct_examples_percent=[0.0], repeat=1, min_num_refs=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "725e60cd-f01f-48f5-a711-bc395ebd4408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# References\n",
      "['$START', 'This', ',', 'unfortunately', ',', 'was', 'only', 'an', 'excuse', '.', 'He', 'was', 'only', 'pretending', 'to', 'retire', 'as', 'he', 'had', 'already', 'signed', 'a', 'contract', 'to', 'drive', 'Mercedes', '.']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajk/miniconda3/envs/drl-gec/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:133: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method should be an int or np.int64, actual type: <class 'list'>\u001b[0m\n",
      "  logger.warn(f\"{pre} should be an int or np.int64, actual type: {type(obs)}\")\n",
      "/home/rajk/miniconda3/envs/drl-gec/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:165: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$START          $KEEP     [12.29] --- $APPEND_But [ 7.25] --- $UNKNOWN  [ 6.80] --- $APPEND_On [ 5.61] --- $DELETE   [ 5.42]\n",
      "This            $APPEND_, [12.02] --- $KEEP     [10.32] --- $REPLACE_, [ 6.96] --- $REPLACE_That [ 5.10] --- $TRANSFORM_CASE_LOWER [ 4.99]\n",
      "unfortunately   $APPEND_, [12.21] --- $KEEP     [10.06] --- $REPLACE_, [ 7.38] --- $DELETE   [ 6.66] --- $TRANSFORM_CASE_CAPITAL [ 4.16]\n",
      "was             $KEEP     [ 9.65] --- $APPEND_, [ 6.49] --- $REPLACE_is [ 5.22] --- $REPLACE_, [ 4.77] --- $REPLACE_was [ 4.25]\n",
      "only            $KEEP     [10.10] --- $REPLACE_just [ 6.91] --- $DELETE   [ 6.48] --- $APPEND_only [ 4.04] --- $APPEND_to [ 3.68]\n",
      "an              $KEEP     [ 9.76] --- $DELETE   [ 5.37] --- $REPLACE_a [ 4.89] --- $UNKNOWN  [ 4.76] --- $REPLACE_one [ 4.23]\n",
      "excuse          $APPEND_. [13.74] --- $APPEND_, [10.10] --- $APPEND_; [ 9.23] --- $APPEND_: [ 9.00] --- $KEEP     [ 8.29]\n",
      "he              $TRANSFORM_CASE_CAPITAL [11.26] --- $KEEP     [ 9.09] --- $REPLACE_. [ 5.54] --- $APPEND_said [ 3.91] --- $REPLACE_, [ 3.29]\n",
      "was             $KEEP     [10.01] --- $REPLACE_was [ 5.45] --- $APPEND_only [ 3.99] --- $DELETE   [ 3.96] --- $REPLACE_were [ 3.43]\n",
      "only            $KEEP     [ 9.85] --- $REPLACE_just [ 5.45] --- $DELETE   [ 5.35] --- $APPEND_just [ 3.71] --- $APPEND_only [ 3.64]\n",
      "pretending      $KEEP     [ 9.19] --- $APPEND_to [ 6.86] --- $TRANSFORM_VERB_VBG_VB [ 4.90] --- $TRANSFORM_VERB_VBG_VBN [ 4.60] --- $UNKNOWN  [ 4.48]\n",
      "to              $KEEP     [ 9.43] --- $APPEND_be [ 8.34] --- $APPEND_have [ 7.00] --- $DELETE   [ 4.92] --- $UNKNOWN  [ 3.99]\n",
      "retired         $TRANSFORM_VERB_VBN_VB [11.60] --- $KEEP     [ 8.40] --- $TRANSFORM_VERB_VBN_VBG [ 6.35] --- $TRANSFORM_VERB_VBD_VB [ 6.07] --- $UNKNOWN  [ 5.36]\n",
      "as              $KEEP     [ 9.67] --- $APPEND_he [ 5.62] --- $APPEND_they [ 4.76] --- $APPEND_the [ 3.91] --- $APPEND_she [ 3.66]\n",
      "he              $APPEND_had [12.17] --- $KEEP     [10.61] --- $APPEND_has [ 7.25] --- $APPEND_was [ 6.35] --- $REPLACE_had [ 5.75]\n",
      "already         $KEEP     [ 9.90] --- $DELETE   [ 6.15] --- $APPEND_had [ 6.04] --- $REPLACE_had [ 5.05] --- $APPEND_been [ 4.21]\n",
      "signed          $KEEP     [ 9.40] --- $UNKNOWN  [ 5.52] --- $TRANSFORM_VERB_VBN_VBD [ 4.81] --- $REPLACE_had [ 4.19] --- $APPEND_in [ 3.95]\n",
      "a               $KEEP     [ 9.54] --- $UNKNOWN  [ 5.66] --- $DELETE   [ 4.62] --- $REPLACE_the [ 4.54] --- $REPLACE_an [ 4.30]\n",
      "contract        $KEEP     [ 9.06] --- $UNKNOWN  [ 5.59] --- $APPEND_, [ 4.24] --- $APPEND_with [ 3.77] --- $APPEND_to [ 3.59]\n",
      "to              $KEEP     [ 9.63] --- $UNKNOWN  [ 4.32] --- $DELETE   [ 3.90] --- $REPLACE_for [ 3.46] --- $APPEND_be [ 2.88]\n",
      "drive           $KEEP     [10.28] --- $APPEND_the [ 5.45] --- $UNKNOWN  [ 5.42] --- $APPEND_a [ 4.95] --- $APPEND_for [ 4.54]\n",
      "Mercedes        $KEEP     [ 8.52] --- $APPEND_, [ 4.52] --- $APPEND_'s [ 4.49] --- $APPEND_' [ 3.89] --- $DELETE   [ 3.06]\n",
      ".               $KEEP     [11.97] --- $UNKNOWN  [ 6.51] --- $APPEND_But [ 6.12] --- $DELETE   [ 5.99] --- $APPEND_\" [ 5.50]\n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 0  \n",
      "\u001b[37;1mRewards:\u001b[0m 0.000  \n",
      "\u001b[37;1mSource:\u001b[0m $START This unfortunately was only an excuse he was only pretending to retired as he already signed a contract to drive Mercedes .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START This unfortunately was only an excuse he was only pretending to retired as he already signed a contract to drive Mercedes .  \n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m 1  \n",
      "\u001b[37;1mRewards:\u001b[0m 0.694  \n",
      "\u001b[37;1mSource:\u001b[0m $START \u001b[32;1mThis\u001b[0m [\u001b[31;1m$APPEND_,\u001b[0m] \u001b[32;1munfortunately\u001b[0m [\u001b[31;1m$APPEND_,\u001b[0m] was only an \u001b[32;1mexcuse\u001b[0m [\u001b[31;1m$APPEND_.\u001b[0m] \u001b[32;1mhe\u001b[0m [\u001b[31;1m$TRANSFORM_CASE_CAPITAL\u001b[0m] was only pretending to \u001b[32;1mretired\u001b[0m [\u001b[31;1m$TRANSFORM_VERB_VBN_VB\u001b[0m] as \u001b[32;1mhe\u001b[0m [\u001b[31;1m$APPEND_had\u001b[0m] already signed a contract to drive Mercedes .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START This , unfortunately , was only an excuse . He was only pretending to retire as he had already signed a contract to drive Mercedes .  \n",
      "\n",
      "$START          $KEEP     [12.66] --- $APPEND_But [ 7.09] --- $APPEND_\" [ 6.04] --- $UNKNOWN  [ 6.00] --- $DELETE   [ 5.87]\n",
      "This            $KEEP     [10.22] --- $REPLACE_That [ 6.49] --- $REPLACE_This [ 5.28] --- $UNKNOWN  [ 4.65] --- $REPLACE_that [ 4.21]\n",
      ",               $KEEP     [ 9.81] --- $APPEND_, [ 4.98] --- $DELETE   [ 4.25] --- $UNKNOWN  [ 2.84] --- $APPEND_in [ 2.65]\n",
      "unfortunately   $KEEP     [ 9.61] --- $DELETE   [ 5.52] --- $APPEND_, [ 4.11] --- $TRANSFORM_CASE_CAPITAL [ 3.97] --- $REPLACE_however [ 3.26]\n",
      ",               $KEEP     [10.36] --- $APPEND_, [ 6.08] --- $DELETE   [ 5.94] --- $UNKNOWN  [ 4.30] --- $APPEND_the [ 2.96]\n",
      "was             $KEEP     [ 9.72] --- $REPLACE_is [ 6.27] --- $REPLACE_was [ 5.67] --- $APPEND_just [ 4.19] --- $APPEND_only [ 3.97]\n",
      "only            $KEEP     [10.35] --- $REPLACE_just [ 7.70] --- $DELETE   [ 6.39] --- $APPEND_only [ 4.35] --- $APPEND_just [ 4.34]\n",
      "an              $KEEP     [10.54] --- $REPLACE_an [ 5.63] --- $REPLACE_one [ 5.36] --- $DELETE   [ 4.71] --- $REPLACE_a [ 4.71]\n",
      "excuse          $KEEP     [ 9.28] --- $UNKNOWN  [ 5.19] --- $APPEND_to [ 3.54] --- $TRANSFORM_VERB_VB_VBZ [ 2.95] --- $APPEND_, [ 2.82]\n",
      ".               $KEEP     [ 9.22] --- $REPLACE_. [ 6.00] --- $REPLACE_; [ 4.30] --- $REPLACE_, [ 4.26] --- $REPLACE_: [ 3.92]\n",
      "He              $KEEP     [ 9.83] --- $TRANSFORM_CASE_LOWER [ 5.39] --- $REPLACE_He [ 3.94] --- $APPEND_also [ 3.27] --- $APPEND_, [ 3.12]\n",
      "was             $KEEP     [ 9.95] --- $REPLACE_was [ 5.05] --- $DELETE   [ 4.93] --- $APPEND_only [ 3.73] --- $APPEND_also [ 3.72]\n",
      "only            $KEEP     [10.03] --- $REPLACE_just [ 5.87] --- $DELETE   [ 5.23] --- $APPEND_just [ 3.98] --- $APPEND_only [ 3.87]\n",
      "pretending      $KEEP     [ 9.38] --- $REPLACE_trying [ 5.36] --- $APPEND_to [ 5.29] --- $UNKNOWN  [ 5.11] --- $TRANSFORM_VERB_VBG_VB [ 4.70]\n",
      "to              $KEEP     [ 9.70] --- $DELETE   [ 4.80] --- $APPEND_be [ 4.46] --- $APPEND_to [ 4.12] --- $UNKNOWN  [ 4.07]\n",
      "retire          $KEEP     [ 8.96] --- $APPEND_, [ 8.16] --- $REPLACE_, [ 3.61] --- $TRANSFORM_VERB_VBZ_VB [ 3.42] --- $UNKNOWN  [ 3.32]\n",
      "as              $KEEP     [ 9.55] --- $REPLACE_because [ 5.11] --- $REPLACE_, [ 4.23] --- $APPEND_the [ 3.92] --- $DELETE   [ 3.66]\n",
      "he              $KEEP     [ 9.96] --- $DELETE   [ 4.08] --- $APPEND_still [ 3.66] --- $APPEND_, [ 3.60] --- $TRANSFORM_CASE_CAPITAL [ 3.44]\n",
      "had             $KEEP     [10.01] --- $APPEND_already [ 6.03] --- $REPLACE_had [ 4.48] --- $APPEND_not [ 4.44] --- $APPEND_been [ 4.44]\n",
      "already         $KEEP     [ 9.38] --- $DELETE   [ 5.69] --- $APPEND_been [ 3.77] --- $APPEND_recently [ 3.76] --- $APPEND_already [ 3.67]\n",
      "signed          $KEEP     [ 9.33] --- $UNKNOWN  [ 5.88] --- $APPEND_up [ 4.67] --- $DELETE   [ 3.64] --- $APPEND_in [ 3.61]\n",
      "a               $KEEP     [ 9.62] --- $UNKNOWN  [ 5.86] --- $DELETE   [ 4.86] --- $REPLACE_the [ 4.77] --- $REPLACE_an [ 4.48]\n",
      "contract        $KEEP     [ 9.04] --- $UNKNOWN  [ 5.37] --- $APPEND_with [ 4.32] --- $APPEND_, [ 4.18] --- $APPEND_to [ 3.70]\n",
      "to              $KEEP     [ 9.70] --- $UNKNOWN  [ 4.09] --- $DELETE   [ 3.96] --- $REPLACE_for [ 3.92] --- $REPLACE_to [ 2.96]\n",
      "drive           $KEEP     [ 9.86] --- $APPEND_a [ 7.18] --- $APPEND_the [ 6.88] --- $UNKNOWN  [ 4.61] --- $APPEND_for [ 4.16]\n",
      "Mercedes        $KEEP     [ 8.43] --- $APPEND_'s [ 4.39] --- $APPEND_, [ 4.27] --- $APPEND_' [ 3.61] --- $APPEND_a [ 3.25]\n",
      ".               $KEEP     [12.41] --- $DELETE   [ 6.41] --- $APPEND_\" [ 6.31] --- $APPEND_But [ 5.94] --- $UNKNOWN  [ 5.85]\n",
      "\n",
      "\u001b[37;1mTimestep:\u001b[0m \u001b[32;1m2\u001b[0m  \n",
      "\u001b[37;1mRewards:\u001b[0m 1.000  \n",
      "\u001b[37;1mSource:\u001b[0m $START This , unfortunately , was only an excuse . He was only pretending to retire as he had already signed a contract to drive Mercedes .  \n",
      "\u001b[37;1mOutput:\u001b[0m $START This , unfortunately , was only an excuse . He was only pretending to retire as he had already signed a contract to drive Mercedes .  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajk/miniconda3/envs/drl-gec/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
      "  logger.deprecation(\n",
      "/home/rajk/miniconda3/envs/drl-gec/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:133: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method should be an int or np.int64, actual type: <class 'list'>\u001b[0m\n",
      "  logger.warn(f\"{pre} should be an int or np.int64, actual type: {type(obs)}\")\n",
      "/home/rajk/miniconda3/envs/drl-gec/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:165: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/home/rajk/miniconda3/envs/drl-gec/lib/python3.8/site-packages/gym/core.py:57: DeprecationWarning: \u001b[33mWARN: You are calling render method, but you didn't specified the argument render_mode at environment initialization. To maintain backward compatibility, the environment will render in human mode.\n",
      "If you want to render in human mode, initialize the environment in this way: gym.make('EnvName', render_mode='human') and don't call the render method.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n",
      "/home/rajk/miniconda3/envs/drl-gec/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:297: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "state = env.reset()\n",
    "print(\"# References\")\n",
    "for ref in env.reference_tokens_list:\n",
    "    print(ref)\n",
    "print()\n",
    "done = False\n",
    "while not done:\n",
    "    with torch.no_grad():\n",
    "        [logits] = model([state])\n",
    "        actions = logits.argmax(-1)\n",
    "        actions = actions.cpu().numpy()\n",
    "        v, i = logits.topk(5)\n",
    "        v = v.cpu().numpy()\n",
    "        i = i.cpu().numpy()\n",
    "        for s, lp in zip(state, zip(env.labels[i], v)):\n",
    "            print(f\"{s:15}\", \" --- \".join(f\"{l:9} [{p:5.2f}]\" for (l, p) in zip(*lp)))\n",
    "        print()\n",
    "    next_state, reward, done, info = env.step(actions)\n",
    "    state = next_state\n",
    "    outputs = env.render()\n",
    "    for o in outputs:\n",
    "        print(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623a8cb1-2b94-49e3-aff9-504ea19cef04",
   "metadata": {},
   "source": [
    "# Close Google Compute Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "983c1785-751e-468b-a77d-3aab03328941",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_gce_instance():\n",
    "    !gcloud compute instances stop drl-gec --zone us-west1-b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6ab31a-6f54-442b-9c09-6fd1ab01759e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drl-gec",
   "language": "python",
   "name": "drl-gec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
